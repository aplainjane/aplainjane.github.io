<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>一些杂七杂八的想法</title>
      <link href="/article/51cf0114.html"/>
      <url>/article/51cf0114.html</url>
      
        <content type="html"><![CDATA[<p>之所以会有历史厚重感以及最后文明继承者的苍凉感，正是由于一种即将消亡的迷茫导致的。</p><p>不知道怎么办。</p><p>不知道会怎么样。</p><p>但有的文明是幸运的，能继续延续。</p><p>但也有文明是不幸的，在人们发现它之前就已经沉寂了。</p><p>谁又能说伟大的文明，不会以悲剧收尾呢。（Marie’s Dictionary）</p><p><a href="https://weibo.com/2291996315/H2sWd9Mv4">https://weibo.com/2291996315/H2sWd9Mv4</a></p><p><a href="https://www.globalonenessproject.org/library/films/maries-dictionary">https://www.globalonenessproject.org/library/films/maries-dictionary</a></p><p>生活是一场电影，或许每个人都只会关心自己出演的那一部分，但大家都不知道，背景板的每一个人，也有属于自己的盛大而华丽的演出。</p><p>如果让你复述这一天你的日子过得怎么样，这一天你做了什么。</p><p>当你回忆一下后，你会发现，这一天我似乎过得像小学时候的日记，像流水账。</p><p>而在某一个时刻，你突然很想改变，想像别人一样发上一篇精彩的朋友圈。</p><p>而一趟心血来潮的旅行之后，你却发现，好像还是窝在家里更舒服一些。</p><p>除了懒，其实家里隐藏的那不容易被发现的温情，是比一切奔波与忙碌的生活体验，支撑着你生活下去的一切动力。</p><p>但其实这些流水账一样的日子背后，隐藏的是无数精彩人生所比不上的安稳与幸福。</p><p>生活，就是把流水账过得也一样的精彩。</p><p>噢不如说，生活它本身就是流水账，而我们自己的情绪，才是这本流水账里每个人所拥有的精彩与感动。</p><p>假如我是世界上最后一个说汉语的人。</p><p>现在是快要成长为大人的阶段，一直听说着大人的世界有多恐怖，多少欺诈，多少真诚，学校是最后的一处避风港，不知道当我走出这个地方，几年后的我是否还是现在的我能认出来的模样。已经在感觉自己的一些变化了，不知道是圆滑还是成长，但是却又变得很是真切。</p><p>如何把每一天都过得像是穿越回来的一样，发现所有未曾发现过的惊喜与隐藏着的感动。</p><p>你是否也对这个世界感到无力而难过，但其实生活一直都在拥抱你，只是你未曾留意</p><p>潜得下心来，但时间不一定会给你这样一个机会，但你总会有比你所以为的时间更多一些的时间</p><p>生活没有进度条，我们也不用为了一些表面荣誉而刻意让自己焦虑，因为我们做了些什么，我们自己都清楚。</p><p>假如我是世界的观察者</p><p>把爱鸟和冒险视作信仰，也许会是一件让生活更有意思的事情</p><p>关于城市记忆，或许你会说我们的城市记忆就是“想你的风吹到了哪哪哪”，但我感觉这并不是所谓的记忆，那些地震过后的纪念品，依然平静的躺在某处，这些才能触发某些人，某些事物，某些回忆，结绳记事记的永远不是鸡毛蒜皮的小事，每一个绳结，抚摸时都能感受到时光在这留下的巨大回声。</p><p>人文 和 自然 在旅行中都很重要</p><p>信仰的力量 在长大之后才会显现出来，虽然很玄乎，但你确实会感受到一股力量在支撑着你做每一个人生的决定</p><p>花火拖着长长的尾巴落入海中</p><p>注意好节奏</p><p>太过顺利的成功无法引爆这一路的曲折与结局的泪腺。</p><p>你说旅行这一路上出现过的许许多多，你说人生感悟也好，其实我并不会理解很多，毕竟我才20岁，但我总可以体会到这一路上的风景，不只是属于我一个人，每个人看到的都是自己故事的一部分。</p><p>关于胡同的故事，如果失去了这些见证，那什么证明这一段悠长的历史</p><p>有时候很多东西都是自我感动，没有真的付诸实践的，都是不为人知的，而自己也会很轻易的忘记。</p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 情绪 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>在雨天坐公交车到世界尽头</title>
      <link href="/article/8832a5b7.html"/>
      <url>/article/8832a5b7.html</url>
      
        <content type="html"><![CDATA[<p>“快走！要下大雨了！”</p><p>身旁在公交亭和我一样在等公交车的两个衣装正式的哥哥抄起公文包，像一枚炮弹一样直射刚好停靠的公交车，我倚靠在公交亭的一角，眼巴巴的看着路牌。</p><p>这灰蒙蒙的天，像是世界末日来临前恶魔揭示的漆黑未来的一角，闪电在肆虐，雨虽未至，却有刀光剑影，划破这寂静的黑暗，带来片刻的震耳欲聋，顷刻间风雷大作，像是战鼓敲响，时刻准备着让雨滴发起冲锋。</p><p>阴影笼罩下的马路上，车辆行驶得十分混乱，飞速逃窜着，似是想要离开这个星球。人们捂紧耳朵，步伐匆匆，加速逃向他们的庇护所。</p><p>在这片混乱的阴影下，我的内心却在欢呼雀跃！</p><p>太好啦！要下大雨啦！</p><p>因为我知道一个他们都不知道的秘密：</p><p>当雨水覆盖这条街道，从远方驶来的101路公交车将会开上水汽凝结而成的一座桥梁，抵达天空，开向世界的尽头。</p><p>嘘，你可别告诉别人呀，下次在雨天的公交亭上碰到我时，咱们悄悄相互微笑点头就可以啦，可不要让别人察觉呀。</p><p>只不过到底还要等多久呢，我踮起脚尖稍微往外望了望，希望能看到那熟悉的车牌号。</p><p>“小朋友，要下大雨啦，天这么黑，你不怕吗？”</p><p>身边一个提着雨伞的老爷爷带着和善的笑容看着我，脸上像绽开了一朵花，不过花瓣微皱，是时光流逝过的痕迹。</p><p>我把双手往裤兜里一插，骄傲的昂起头，朝着老爷爷大声说道：</p><p>“不怕不怕！要踏上一场更加精彩的旅途了呀！”</p><p>突然意识到好像说漏了点什么，我赶紧捂住自己的嘴。</p><p>但老爷爷好像没有察觉到什么，反而冲我竖了个大拇指，还夸了我几句，我不好意思地吐了吐舌头，心里却在庆幸秘密没有暴露。</p><p>就在谈笑间，一束暖黄的光芒穿过拥挤的车流，照到了我的心坎上。</p><p>来啦来啦！是101路公交车！</p><p>我回头朝老爷爷摆摆手，高高抬起左腿，踏上了公交车，嘿嘿，我可不会再在这个车门口摔倒咯！</p><p>“叔叔！去世界尽头！”</p><p>我将在口袋里捂得热热的两元钱拿了出来，投入投币箱，豪气地对司机叔叔说道。</p><p>“好嘞，坐好咯！这次又得坐好长一段时间哈！”</p><p>“嗯嗯没事！”</p><p>我慢慢扶着扶手，往车后走去。</p><p>果然，还是和以前一样没有人来坐这辆车啊。</p><p>车上座位满满当当，座位上却是空空如也，我看着这熟悉的景象，心里有一点小小的庆幸：看来这个秘密还没有暴露，太好啦！</p><p>司机叔叔回头看了我一眼，轻声提醒我赶紧找个位置坐下，他要启动啦。</p><p>我快步走到车的最后一排，跳到最靠窗的位置上，然后看着窗外的天空，等待着它降下迎接地上旅者的雨水。</p><p>它很快就响应了我的期待，在我目光望向它的时候，云层似乎无法承载雨水的重量，忽然撕开了一道裂口，无数雨滴倾泻而下，时不时听到几声尖叫声在人群中炸响，不过只是一刹，大家很快的就找好了避雨的地点，一起仰望着这厚重的天空。</p><p>雨下起来啦，接下来就是等待公交驶过天边，穿过云海，这一段漫长而又浪漫的旅途了，不过等公车驶到水桥到时间还有很长很长，现在窗外依然是熟悉的城市景象，昏暗夜色中，模糊的霓虹灯光，在雨水滑落的车窗外朦胧不见，像银河，恍惚间像是已经驶向了星空，为了保存一点精力去看天空之上的风景，就先偷偷的小憩一会吧！</p><p>我看着朦胧的车窗和窗外飞速掠过的各种色彩，上眼皮逐渐靠近下眼皮，接着紧紧依偎在一起，身体随着车子摇摇晃晃，像坐在摇篮里，晃悠晃悠，便进入了梦乡。</p><p>只有轰隆隆的马达声伴随着雨声，没有传说中的铁马冰河入梦来。</p><p>一阵突如其来的颠簸把我从美梦中摇醒，睁开眼一看，车窗外不知何时已经被绵软蓬松的白云所填满了，像白色的泡芙，稍微一挤压就会有稠滑的奶油漂浮在空中。</p><p>我擦了擦眼睛，从座椅的靠背上直直坐起，使出全身的力气，嘿呀一声，拉开公交车的窗户，伸出双手扯了一点白云，拿进车里观察。</p><p>在我扯下白云的那一瞬间，车外的白云开始急剧晃动，像一团被触碰的白色布丁，摇摇晃晃，像是刚学步的孩童。</p><p>我把那一团被我扯下的白云抱在膝盖上，暖暖的，糯糯的，甜甜的。</p><p>嗯，我尝了一口，很甜。</p><p>云朵层层叠叠，绵延千里，下面就是我们生活的小镇，在高空上看上去就像一座小小的模型，五颜六色，当然还有那一团正在下雨的乌云，它就覆盖在刚出发时的那一块区域。</p><p>我朝它做了个鬼脸，虽然下雨湿湿的很讨厌，但是还是得感谢它为我们架了一座桥梁呀。</p><p>云朵上还有一些小兔子，它们都是雪一样的白色，跳来跳去推动着天空上的云朵在天空之上移动，不知道陈与义先生知不知道当他在船上卧看满天云不动时，是否知道天空之上的云朵后面都是一群群绵软的白兔呀。因为兔子小小的，所以即使它们很努力了，可是云朵还是运动得很慢……不过只要时间足够，它们也能把云朵推动着走遍全世界的！</p><p>公车却在这时候突然停了下来，司机叔叔回头向我建议道：</p><p>“我们还要开好久好久，要不要先下车运动运动呀？久坐对身体不太好喔！”</p><p>“好！”</p><p>我早就在等着这句话啦！每次最期待的就是亲脚踏上这一片别人未曾踏足过的净土，去云朵里打滚！</p><p>嘎吱一声响，车门打开啦，下车回头看时，才意外的觉得这红色的公交车在蓝蓝的天空下，洁白的云朵上显得那么鲜艳而美丽。</p><p>“车门上好像有一小块地方生锈了耶。”</p><p>我低头看见经常被地上水溅湿的车身一块竟然生了一点小小的锈迹，还有一小块青青的青苔。</p><p>“云朵上面没有植物，兔子们要吃什么呢？”</p><p>我往前走了几步路，蹲下身子观察蹦蹦跳跳的兔子，嘴里轻声嘟囔道。</p><p>“吃彩虹。”</p><p>身后传来一个好听的女声。</p><p>我闻身惊讶地转过头去，看到一个身穿淡蓝连衣裙的姐姐正微笑着看着我。</p><p>她头上戴着一顶样式新奇的帽子，好像很久之前我听说过的渔夫帽。</p><p>“想不到还会有其他人到这里来呀，小朋友你也是坐公交车到这里来吗？”</p><p>姐姐蹲下来摸了摸我的头，轻轻的，让我有一点迷糊。</p><p>看着姐姐好看的脸，我心里突然有一点紧张，不过还是鼓起勇气回答了她。</p><p>“嗯嗯，我是坐着101路公交车到这里来的！”</p><p>“欸，好巧啊，我也是。不过可能不是同一个地方的101路公交车吧，我坐的那一辆车上只有我一个人喔！”</p><p>“还有司机叔叔！我这边还有！”</p><p>我抢着回答道，姐姐一愣，然后捂嘴一笑，说道：“嗯嗯，我怎么把司机叔叔给忘了。”</p><p>我有些不好意思，只好伸出自己的小手，轻轻地握住了她的手。</p><p>我看到她眼里有惊喜闪过。</p><p>“之前我和你一样很好奇这些兔子吃什么呢，在一次旅途中便带了几根胡萝卜，想来喂给它们，不过它们好像不敢兴趣呢。”</p><p>我瞪大了眼睛，居然有兔子不吃胡萝卜！好神奇！</p><p>“然后我就拼命地观察呀观察，然后！就让我发现了，它们为什么会将云朵推到下雨的地方，原来是因为下过雨的地方会出现彩虹！它们最喜欢吃的，就是彩虹！”</p><p>姐姐说到最后，脸上露出了和我一样的惊讶神情。</p><p>“不知道这次能不能观察到呢。”</p><p>于是我俩便趴在云朵上，边舒展着自己的身体，边往下细细观察。</p><p>虽然最后没有看到吃彩虹的兔子，但我们还是看到了很多有意思的景色。</p><p>姐姐指着云朵下的一些建筑，告诉我这里是金字塔，这里是珠穆朗玛峰，这里是长城，这些平时隔了我几万公里外的景物，在这里居然看得清清楚楚！</p><p>仰躺着看到的是星空，俯瞰着看到的是全世界。</p><p>我都有点不想从这里离开了。</p><p>“应该快到启程的时间啦，赶紧回车上去吧，待会才能早点到世界尽头！”</p><p>姐姐先站了起来，接着便拉起还躺在地上的我。</p><p>“待会下落时注意看车窗外，你所看到的流星其实是其他前往世界尽头的公车，待会世界尽头见咯！”</p><p>“嗯嗯，待会见！”</p><p>姐姐微微笑，便朝着远方走去。</p><p>我突然特别佩服她，她所说的这些，我来了这么多次居然都没有发现！</p><p>这里可真是一个好地方呀！</p><p>可能是平时我都会把自己更多的目光摆在了目的地了，结果竟然错过了沿途这么多的精彩，这可不行，以后不仅最后的目标，沿途的所有所有我都要好好品味！</p><p>坐上了属于我的101路公交车，发动机开始轰鸣，我开始向世界尽头出发！</p><p>穿过一道道彩虹构成的大门，我一路上一直在担心它们会不会很快就被吃掉，大门之后是一片宽阔无垠的大海！云海啊云海，云朵的背后就是一片蔚蓝的大海！</p><p>我知道，快要到世界尽头啦！</p><p>当云朵不再连绵，公车开始下坠，像流星，但不会燃烧。</p><p>我和司机叔叔因为系着安全带，所以可以尽情享受这一份突如其来的失重感。</p><p>当云朵全部散尽，海的所有展现在我们眼前——青绿色，像一块无边无际的大玛瑙。</p><p>下坠途中，有群群飞鸟陪伴着我们，我们就这样像流星一样，划过天际。</p><p>越来越多和我们一样的流星开始坠落，我赶紧凑到窗户旁，仔细观察。</p><p>“哇！原来真的是公交车欸！”</p><p>每一颗流星，都是一辆辆俯冲的公交车，车灯形成了拖尾，好像流星的小尾巴，姐姐说的是真的！</p><p>有红色、黄色、绿色、橙色、蓝色、紫色等等等等的颜色，真的，好漂亮！</p><p>我不知道要怎么和你形容，大概是，噢对了，就是一道慢慢展开的彩虹，从没有，慢慢，慢慢的被画出来，在天空这张淡蓝色的信纸上，一点一点被渲染出来。</p><p>好像在一辆公交车上，我看到姐姐再向我招手。</p><p>接着，我们就摔进了海里，摔出了一整个盛夏。</p><p>摔上去的那一块地方，是软软的，不是平常的海水，是果冻一般的海水，有一种玩具怎么说来着，噢噢，非牛顿流体！</p><p>然后我们就被大海像一块饼干一样吐了出来。</p><p>准确来说，是弹起来。</p><p>因为已经经历过好多次了，所以你看，我一点也不惊讶。</p><p>怎么可能，再经历多少次，还是会觉得很新奇！</p><p>等车子恢复平衡，我才小心翼翼地从车子上下来，我先伸出一只脚试了一下水面，嗯，是实的，然后就一整个跳下车，然后开始大口呼吸来自海洋之上的海风。</p><p>听说蝴蝶在大海上煽动一下翅膀，就会引起一个台风，那我不小心打了个喷嚏的话，那不也是会引起风暴吗。一想到这我赶紧停止大力吸气，开始变得十分谨慎。</p><p>你说海面什么也没有，倒也不是什么也没有，在海中央会有一个站台，这个站台是给经过的唯一一辆火车停靠的，这辆火车或许也是世界上唯一一辆通往世界尽头的火车，这也是或许是世界上唯一一条横卧在大海之上的铁轨，在大海上蜿蜒，一时间也望不到尽头，像一条慵懒的小蛇，因为与世无争而没有任何想运动的念头。</p><p>走在软软的海上，有一种别样的感受，好像身上所有压力与负面的情绪，都会被一点一点慢慢稀释，最后留在了这片安静的国度里。</p><p>还没走几步路，我就看到了远处站着的熟悉的身影。</p><p>是那位姐姐。</p><p>她正微笑着朝我招手。</p><p>我走了过去，脆生生的喊了一句：“姐姐好。”</p><p>她点点头，然后用飞鸟一般的声音问我：“要搭上这辆火车，和我去海的那一头看看吗，这辆车通往镰仓，是一个很美的地方，我每次生活感到疲惫时，就会搭上101路公车，再在这里搭上101号火车，去往那里走走，陶醉在异国他乡的风景里，暂时忘记现实世界的纷扰。”</p><p>原来这里的火车也是101号火车，难怪它会来到这么偏远的地方。</p><p>我犹豫了一下，因为快到家里的饭点了，也不能太晚回去，每次到这里来我也是稍作停留，因为我似乎总能在远方看见一个踮脚眺望的身影，好像是我的妈妈，在担忧地等待着我的回家。</p><p>“不啦，马上就要回家吃饭了。”</p><p>我露出一个笑脸，有点抱歉的拒绝了她的邀请。</p><p>姐姐也是面露微笑的回应我。</p><p>“那就等下次你有时间，我带你去好好玩玩。那边的车站里贴满了密密麻麻的便利贴，都是人们路过时祈求的心愿，也是一个很有特色的景点噢，每次我路过那里，也会留下自己的心愿。”</p><p>她像突然想到什么似的，低头在自己的口袋里掏出了一本便利贴和一支笔，递给了我。</p><p>“你有什么心愿可以写下来呀，这次虽然你没有过去，不过我也可以把你的愿望给捎过去哟。”</p><p>我欣喜地接过了纸笔，想了一想，然后在纸上写了四个字。</p><p>平安喜乐。</p><p>希望我们一家都能继续快快乐乐的生活下去。</p><p>也祝愿姐姐和所有素未谋面的人也都快快乐乐的生活下去。</p><p>然后，我歪着头，在空白的地方画上了一个大大的笑脸。</p><p>姐姐接过便签时，面露惊讶的表情，但是什么也没说，只是轻轻摸了摸我的小脑瓜，乘上了那辆从远方驶来的火车，驶向了远方，我看着火车慢慢远离，直到视野里只剩下清澈透明的海。</p><p>是时候回去啦，我乘上公交车，回归属于我自己的远方。</p><p>尾声：</p><p>母亲看着一旁熟睡着的孩子，孩子懂事得令她感到心疼，为了自己的收入能支撑起她和他的生活，母亲只能让孩子自己乘着公交车从城市的这头到那头去上学。早些年还有一些空余的时间时，母亲会在早上早早起来，牵着孩子的手在公交站台等候着101路公交车的到来，也会在晚上时，即使感到疲劳，依然一脸期待地坐公交车去接回自己的孩子。</p><p>她记得孩子还小时，因为疲倦，每次回家都会在自己的怀里安静的睡着，但只有某些时候突如其来的暴雨让她的怀抱失去魔力，偶尔从臂弯里传来的一阵哆嗦会让她有些无措。她曾经惆怅了很久，最后精心给孩子编了一个童话故事，是关于101路公交车的奇幻故事，她已经有些不记得故事的内容了，大概只记得故事里的101路公车会在雨天驶向云端，开往美丽的世界尽头。</p><p>自那以后，孩子就神奇的不再害怕雨天，而每次下雨，反而一脸期待的看着窗外。当然这股劲头并不能保证他坚持完这一趟漫长的旅途，但他却意外的在她怀里睡得香甜，似乎正做着一个奇幻而美丽的梦。</p><p>生活很艰辛，但看着怀里熟睡中露出笑脸的孩子，母亲总会得到片刻的慰藉，但又有一丝丝苦涩的无奈。</p><p>也许生活能继续下去，能给孩子一个美好的梦境，就已经是她能给出的所有了。</p><p>就这样过了几年，直至101路公交车逐渐冷清，稀稀疏疏只有那几个熟面孔，母亲的生活却忽然变得繁忙。庆幸的是，101路的公交车司机都很是关怀她们这对母子，得知了母亲不得不让孩子突然独立这件事后，都很乐意对孩子投注他们的关心。</p><p>孩子也很有礼貌，上车后也只是安安静静的坐着，从来没有给他们带来过麻烦，反而让他们很是喜欢这个在雨天就嚷嚷着要去世界尽头的孩子，他们也很小心翼翼地守护着孩子的这个小小的梦，在孩子上车后甜甜睡着时，他们会特别关注路况，防止突然的急刹车和颠簸惊醒了孩童好不容易得来的片刻休闲。</p><p>今天依然是下雨天呢，母亲在熟睡的孩子身边忽然想起了孩子进门时便嚷嚷“妈妈，今天我悄悄地在世界尽头许了个愿望噢！不过愿望不能说出来才会实现。”时神秘的表情，让她有些好奇孩子这次又梦见了些什么，不过她也只是笑笑，然后柔声说道：“那就不要告诉我啦，让它悄悄实现吧！快去洗洗手，咱们准备吃饭啦。”</p><p>只不过在她不知道的远方车站里，有一张写着“平安喜乐”淡黄色的便签，上面的一个随手涂鸦的笑脸在几缕阳光的渲染下，笑得更加灿烂了。</p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小说 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>山海不过壶酒间</title>
      <link href="/article/9185230b.html"/>
      <url>/article/9185230b.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>我的天哪，4月就写了一篇博客，然后一堆作品集和项目记录还没准备！我在干什么！</p><p>算了，事已至此，先把一些之前想保存的word都陆陆续续搬上来，撑一下……</p><p>这个是最长的一篇，慢慢更新但是疑似太监了的一篇长篇……</p><p>所有杂谈就用默认封面了……究极懒鬼</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>  连片雪花如飘飞的柳絮，在这灯火通明的小镇上空飘得十分温馨。</p><p>  少女手持着油纸伞，一步一步在雪地上认真地走着。</p><p>街上的行人有说有笑，晕染了这片平和的土地。但少女似乎什么也感受不到，就这样平和地走在石板路上。小巧的红鞋碰撞着青涩的雪壤，沙沙地响着，犹如一匹骆驼，茫然地行走在白色的沙漠中。</p><p>她的一头青黑的头发，划过时空，似乎带走了什么，又似乎什么也带不走。</p><p>“老板，借住一晚。”她抬头看着这间不起眼的旅馆。眼里却好似装不下一件事物，宛如濒临破碎的一扇窗户，只有略带一点樱桃色的浅唇给她带来一点生气。她很美，却美得让人心碎。</p><p>“可是我们已经打……”伙计嘟哝到一半，却被老板止住了。</p><p>“客官，劳驾二楼。”</p><p>她点点头，眼神洞穿老板，飘向渺茫的远方。</p><p>“诶？”伙计疑惑地望着她一步一步地走过，绾头的红绡飘浮着，划过店内污浊的空气。“难不成她是？”</p><p>老板郑重地点了点头，看着少女飘忽不定的身影消失在了玄关处。</p><p>“是尊大妖。”</p><p>回答老板的，是尽头油纸伞收起的声响。</p><p>“妈妈，妈妈，为什么我们的天空一直是黑色的呀？”</p><p>街头拐角处糖葫芦小摊前，束发小孩正牵着一名中年女子的手，边舔糖葫芦边问。</p><p>“很久很久以前，它其实是蓝色的。”</p><p>中年女子茫然地望着天空，回想起了过往，许久，她摇头叹息着，摸摸小孩的头。</p><p>“也许是太阳公公累了，想休息一会儿。等他哪天恢复了，天空就又会是天蓝色的了。”</p><p>中年女子微笑着，牵着小孩慢慢向着远方走去。</p><p>奇怪的是，似乎有一束光，照在了他们回家的路上，有一点温暖。</p><p>“也许是阳光吧。”中年女子轻声呢喃道。</p><p>少女跟随着二楼树妖的指引，走向了房间。</p><p>“原来是一间妖精开的旅馆吗。”</p><p>少女笑了，却带有一丝苍白。这意味着，也许会遇上不想见的妖。</p><p>“真打算一走了之？”</p><p>视野中突然出现一位玄色长袍的男子。</p><p>比如说这位。少女无奈地抬起头，眼里恢复了一点生机。</p><p>“那还能怎么办？”</p><p>男子笑笑。“这可不像以前的你啊。”随手摸了摸少女的丸子头。</p><p>“我可告诉你啊，你要走也赶紧走，别等什么时候你也被排挤了才知道后悔。比竟连太阳也能抛弃，更何况你这个耳目呢？”少女满脸写着疲倦，却依然安静注视着眼前的男子。男子轻笑一声，脸上斜起的嘴角，一时竟不知道是戏谑还是微笑。</p><p>“耳目，是一个很好的形容词呢。”</p><p>“门口那位是？”</p><p>“不愧是你，除了发光外，真是对世间的事漠不关心。”男子嘴角的弧度上扬得更夸张了。“连白泽开的旅馆都不知道，那你是怎么找到这里的。”</p><p>少女把伞负在身后，轻轻地微笑。“原来是白泽，怪不得这么熟悉。”</p><p>“你真不回去了？”男子的表情变得严肃起来。俊秀的五官变得十分凝重。</p><p>“不回去了。”少女摇摇头。</p><p>男子看着她脆弱的模样，心中不由升起了一丝怜意。“那你走吧，一路保重。”</p><p>少女一愣，似是没料到男子竟如此放过了自己。</p><p>“本来就和你没什么深仇大恨，他们剥夺你的神格已经下手够重了，真不知道还要叫我来做甚。”男子摇了摇眼前的几缕碎发。</p><p>“谢谢你，谛听。”少女如释重负。</p><p>“在这世间好好走走吧，也当是散散心，以你的本事，倒也没什么值得顾虑的。”谛听将双手负于身后，慢慢踱出了门外。“其实是因为我也不一定打得过你。”谛听笑着，消失了。</p><p>门外的掌柜，记账的笔许久未动，一滴墨水，滴在了手边纸上。</p><p>翌日，少女步过走廊，朝柜台里的掌柜笑笑。</p><p>白泽只觉得她变了许多。</p><p>她轻轻地坐在一桌木桌前，静静地注视着门外未曾停歇的雪。</p><p>果然他们还是没有找到合适的人选吗。</p><p>少女托着腮，注视着黑色的天空。</p><p>白泽不知什么时候在她身边坐下了。悄声道：“这天空，真是远不及九阳同升时好看啊。”</p><p>少女偏过头，只是笑。</p><p>她本名金乌，掌管太阳，万物生灵，以她为养分。位列仙班时，妖力竟充沛到能一连升起九个太阳。飒爽的身姿立于九阳之上，是天空的王。</p><p>“那已经是过去了。”她呼出一口气，在冰冷的空气中化作一团火苗。飘散而去。“你呢，不是因为你的博学被选上去整理史册了吗，怎么到这里开旅馆了？”</p><p>“不也和你一样嘛。”白泽褪去了普通中年男人的外表，恢复成了白泽的模样。“金乌，你打算怎么办。”白泽看向她如冰般冷峭的脸，问道。</p><p>“我已经不叫金乌啦。”少女从手中取出百妖册，交给白泽翻阅。“就下来就随便走走吧，反正已经无所谓了。”白泽在百妖册中翻找着，发现那曾为金乌的榜首，如今早已易主。而金乌这个名字，似乎已经被抹掉了。</p><p>“接下来，就好好享受一下身为‘人’的生活吧。”少女朝白泽摆摆手，走出了店外，从何而来，不知归处。白泽放下手上的百妖册，轻轻道：“连这个也不重视了吗，果然已经变了啊。”</p><p>一人一把伞一袭红衣。</p><p>就下来就走走这个世界吧。</p><p>她平复着内心些许失落，带着一颗平静的心，走向了未来。</p><p>少女沿着雪后初晴的道路行走着，严格来讲，并不是晴天。天依然是黑色的，宛如世界置身于混沌腹中。</p><p>也许是长久的永夜早已使人们习惯了这类的生活，三餐如常，烟火依旧。</p><p>但终归会有些不方便，比如日晷，这类依靠太阳的工具早已派不上用场，只有那角落里蒙尘已久的滴漏发挥着它许久未曾发挥的余热，一瓢水，滴答滴答，时间变得可感，却又格外漫长。</p><p>或许此时恰是清晨，街上只有稀稀疏疏的几盏灯火。</p><p>偶尔也是有几声街坊准备买卖的器物碰撞声。或许这也是繁盛的大唐少有的安静。</p><p>就近找了家早点铺，点了一碗阳春面，开始品味起这百味人间。</p><p>灯火陆陆续续地从城中蔓延开来，宛若一盏盏青莲于拂晓时分悄然绽放，直至城中高耸的灯塔，不甘示弱地点燃了这片无边的黑暗，依稀可见的，是无尽雾霭后绵延的城池中同样的星火。</p><p>灯火阑珊处，却是捧着热乎乎的面呆立的少女。灯火映入她的眸中，宛若一条银河。</p><p>“姑娘不是城中人吧。”卖面的老者笑呵呵地看着深受震撼的女孩，内心翻涌起无限的感慨。</p><p>“老夫当年进城的时候，也是这般光景啊。”老者笑着，满脸的皱纹化作一朵朵涟漪，泛在了时光的长河里。沉浸在回忆之中的脸颊晕开了年少的几许轻狂的红晕。</p><p>少女轻笑，搁下还揣在碗边的伞，就近找了个位置便坐了下来，边吃着面，边看着巷陌中穿行的士子佳人，她打了个响指，微风拂过，恰经霜雪的梨树却在此时开出了漫天缤纷梨花，掺在雪花里，晶莹如许。</p><p>人们不由得被这寒冬里的奇特景象所吸引，愣愣地驻足仰望，似是在回味刹那的生意迸发。不多时，寂寂寥寥的街道便盈满了吟诗的士子与惊叹的路人。</p><p>冷艳全欺雪，余香乍入衣。春风且莫定，吹向玉阶飞。</p><p>老者回过神来时，已是梨花雨满天。</p><p>“怎么会……”老者喃喃道。老者分明感受到，就在刚刚的瞬间，一股磅礴却又温柔的妖力拂过了这片天地。分明就在 刹那，他多年等待的梦，竟然成为了现实。</p><p>“这……分明是柱枯树啊……”</p><p>老者言罢，却已是热泪盈眶。</p><p>少女饶有兴致地看着浸漫在花雨中的游者。看到那风轻拂过的花瓣散进天空中某束通透的光路中，思绪也不由得顺着灯光而去。</p><p>早些年还在苍穹之上的时候，依稀记得每年八月十五月圆时，月娘总是格外的忙碌。虽然劳累，却也是她最开心的时候，人间烟火弥漫的，是团圆的美好愿景，还有一两丝共享天伦的甜蜜。</p><p>她总是这么说：“天天晚上都在月宫看着，看遍了闺妇的愁思，看惯了游子的心伤，更看厌了缝衣的慈母缝到一半时突然停下的手指，嘴角突然泛起的一丝欣慰，却又是眉头泛起的几缕忧愁。只叹妾身法力尚弱，不能多偏心地分袒出几缕月光，去安慰一下他们几进支离的心。”</p><p>往往站在高处，看到的是无限风光，可她看到的却是卑微者无力实现的心愿。大概这也是仙人们都喜欢到月宫去的原因吧。</p><p>月娘总是那么温柔多情。人间的人们也能感受到月亮上不一样的光，或许有时还有一点错觉，月亮是不是一直在跟着我？一直为我这游子照亮无法到达的故乡。提及这些，月娘总会轻轻摆手，嘴角一丝温柔的弧度却说明了一切。月宫外有一株月桂，或许是长久以来温柔的熏陶，树枝没有太多的旁逸斜出，只有敲到好处的几展臂弯。月娘喜欢在月桂下捣饼，人间的桂花饼，正是月娘未履仙阁时在人间发明的。月桂的花瓣晶莹而又充满馨香，掺在饼中，是不可掩盖的主调。</p><p>月娘在八月十四便会早早地做好桂花饼，在八月十五时便趁早上不用上班的当，给各家神仙送桂花饼。而金乌呢，在仙台上留下自己的一小撮羽毛来发光后，便大踏步地前往月宫，坐在月桂下，等待着月娘串完一天门后回来时发现自己时的惊喜神情。从金乌很小的时候起，这就成为了八月十五的固定节目。小金乌总爱用自己的气息吹着月桂上的花瓣，看漫天纷繁的花瓣，一瓣一瓣地数着，度过这漫长的白天。偶尔吹着花瓣汇成一条龙，在天空中盘旋，正威风凛凛时，会被一声略带严肃的咳嗽声吓得浑身一哆嗦。“啊乌！你怎么又在欺负我的桂树！？”此时金乌总会尴尬地挠挠头，操纵着自己独一无二的气息，使花瓣重新回附到树上。“嘿嘿没关系嘛，毕竟我的气息是时间嘛！”月娘总会无奈地叹口气，毕竟眼前这个女孩确实有着这样的能力。“过来吧。”月娘舒展着袅娜的身段走进了月宫，小金乌便兴冲冲地跟着跑了进去。月娘从殿中的朱色小阁里拿出一盒桂花饼递给金乌，轻抚着她的头发，轻声道：“喏，这盒是你最喜欢的双倍馅，以后要听话喔，这样才能有桂花饼吃。”金乌啊呜一口就吞下一块，鼓着嘟嘟的嘴含糊不清地答应着，心里却想着：虽然每次都是被这样威胁着，但结果无论自己怎么闹，都会有桂花饼吃。想着想着，嘴角不由自主弯出一个狡黠的弧度。月娘似乎看透了她的心思，掐了掐小金乌胖乎乎的小脸，道：“每次这样说你都不听，将来长大了那可还得了？！要是这么任性下去，迟早会被丢出苍穹之外的呀！”月娘看着这茫然的小眼神和略带几点碎屑的嘴角，却又不由自主地笑起来，“说你将来是尊大神，我才不信嘞，大神哪里会像你一样不听话，一样任性，还这么可爱？”</p><p>金乌至今仍非常钦佩月娘，月娘说的话，竟全部变成了现实。只是可爱这一点，不知道现在还是否成立。应该，还成立吧？少女吸溜着嘴里的面，遥遥地望向门前的梨树，梨树的枝干有一丝月桂的影子，一样温婉如绸，一时兴起，感触至深，便悄悄地扭转了一下时间，让她重新焕发生机。让她在冬日里突然变成曾经最好的模样。也算是对摧残月桂那么多年的一点点小小补偿吧。也许再也不会回去那片天地里了，不知月娘现在，又在看着哪一家的聚散和离别呢？</p><p>老者似是从漫长的回忆中醒来，他缓缓走向少女，驻足在她身侧看向门外的梨雪，缓声道：“真美啊。”</p><p>少女轻轻一笑，也说了一句：“真美啊。”</p><p>两人目光对视一秒，都看到了彼此心中尘封已久的某坛陈酿，许多年后启封的那一刻，醇厚的酒香渴望他人的品鉴。</p><p>金乌放下筷子，想着：也许人间，也是个有趣的地方呢！</p><p>茫茫的大海与天际相接，和风习习，在幽寂的长夜里如蛰伏的巨兽，偶有涛声，浪卷依旧。浩大的苍穹如倾覆的棋盘，笼罩在大地之上，黑压压一片，如无炬之室，无主之地。</p><p>但大海总能使人心安，无论阴晴。吞吐云雾于无穷的远方，温柔地抚摸着近岸的石滩。石滩偶有一两声呼唤出海远归丈夫的妇女声音，也偶有几声稚童戏水时的无邪笑声，此后长无日光，灯塔是唯一的光，远航的人儿心中被风浪侵蚀却永浇不熄的，是家的方向。</p><p>“啊雄！在这里<del>”妇女扯着嗓子在岸边呼唤。“欸！就来，就来！”渔人收起渔网，将船靠岸，便立马如飞燕般跃下渔舟，系好船锚，从黑暗中跃向光明的岸上，捧起妇人的脸，兴奋得直揉。“紫啊，俺这一趟打了可多鱼呢！待明日入城，定能卖个好价钱，再给买几盘月香斋的上好胭脂。”妇人似是被这粗糙的手弄疼了，轻轻掐了男子的手，却没有把头从他手上转移出来。“每天尽在海上浪，可知我和囡囡在家里有多担心，这海上风又大，又没有光，万一……唉，下次早点回来，饭可都煮好了啊，囡囡等不到你回来，可是吃不下饭的呀</del>”妇人顺着男子的臂弯便倚靠在他的肩上，嘴上虽是责备，脸上却是幸福的微笑。“嘿嘿，下次俺一定早点回来……”男子挠挠头，搂着妻子便顺着灯塔下的小道步行回家。“明天记得买胭脂哈。”妇人的话顺着她们的足迹，洒落在石滩上。他们不知道，在海岸上坐着一个头发斑白的老人，正慈祥地望着他们的背影。</p><p>“多好啊。”老人乐呵呵地抚了一把胡须，看向身边的年轻人。</p><p>谛听负手立于其旁，此刻内心平和而温暖。</p><p>“想不到你们执律司中竟还有你这般有闲情之人。”老人拄着木杖缓缓站起。一步一步地朝着海中走去。“这世间能陪老朽枉费一段亦似有亦似无时光的人不多了啊。年轻人，老朽还是挺欣赏你的。”</p><p>“不敢当。”谛听振袖，对老者行了个礼。本意速回苍穹复命，却不曾想为这人间浓浓的烟火味所吸引，这种简单而质朴的情感，已经很多年未在上面感受到了。他轻叹一口气，却又很快微笑着向老人再做一揖。“鲲前辈，有劳了。”</p><p>老人木杖一点地，若是无意，却是有形。海水如遇尊者般恭敬地往两边退下，让开了一条直通海天交接的路。“已无扶摇意，但做渡水人。”老人喃喃道。</p><p>“请。”老人微笑抚手让路。谛听再回一礼，便走入水中。见其再揖，老者只是微笑。</p><p>谛听身后的海水在他踏足过后便又再度聚拢，待他入苍穹，海面已愈合得光洁无瑕。鲲走回石滩，坐回了平时最爱坐的石头上，静静地望着初愈的海面，吹起了口哨。</p><p>“老庄啊，你走后这世间便打真是无趣啊。”老者打了个瞌睡，似是在想些什么，眉头微皱，“但今天是个意外啊哈。”老者似有些许舒缓，但亦是不久之后，他的语气却是愈加沉重，“这天，却是越来越黑了啊……”</p><p>不过数语，对面老者已是热泪盈眶。</p><p>还未完全吃完的面还在散发着余温，试图温暖这梨树飞舞的冬。</p><p>“入世百余年，不愿再经历失去的苦痛，才在与她相遇的梨树下守候多年，想着上元节那晚她在阳春面小摊前的惊鸿一瞥，烟雾弥漫了心头的春天。不过短短数十载，她已然随烟雾而去，终是人生泛起的一点涟漪，剩老朽一人，空看这不再新发的枯树，倒也安好。以先生这样的大神通，竟也了却了老朽的心结。先生当是一尊老朽无法触及的存在吧，这人间可值得您逛逛哟。千里江山，也有不尽去处，若您未曾有过目的地，到长安去吧，那里繁华烟火，歌舞升平，老朽此等小妖，误入尘世，竟也流连，亦留遗憾。”</p><p>老者仰面长息，倒却添了几分笑意。</p><p>“不知先生有何过往，但先生的故事，老朽倒也不敢过问。”</p><p>金乌笑笑，摇摇头，却只是盯着碗发呆。</p><p>回忆很长，却无从讲起，何时变天，只有帷幕遮蔽，而帷幕后，却无戏上演。</p><p>“就当是太阳陨落了吧。”</p><p>少女的声音突然响起，十分平静。</p><p>少女也只是笑，全无半点忧伤。</p><p>老者若有所思，喃喃道：</p><p>“常听人言，妖道之末即世仙道，仙道却又是规则，或许先生曾是掌管世间规则之人吧。”</p><p>还未等金乌有所反应，老者便深鞠一躬。</p><p>“唐突了，先生见谅。”</p><p>老者微笑，拭去眼角余泪。</p><p>“不开心的话，就到人间走走也好，毕竟您现在恰及笄，正是应当微笑的美好年华啊。”</p><p>老者这一次，是真正把眼前之人当作恰逢豆蔻年华的涉世少女了。</p><p>金乌点了点头，微微欠身，便起于雪中，抚起纸伞，与老者作别。</p><p>一阵清脆的铃声在雪中沿着街巷一深一浅地消散在风中，少女的身影就这样和远方的灯火融为一体，再不见踪迹。</p><p>老者依旧凝望，目送了很久很久。</p><p>大寒恰至，不过数日光景，人间的年便悄悄的到来了。</p><p>黑暗永远阻挡不了人类对光明的渴望，纵使是永夜，在张灯结彩的新春里依旧明亮得如同白昼。亦或者在无休止的黑夜中，年的到来更对人们有更深的意味。年复一年，希望从不熄灭。</p><p>平日的青莲灯也染上了年的气息，每一瓣花瓣都带上了剔透的碎光，舒展开的，是人们的笑脸。垂下的条条流苏，系着来来往往人们的新年愿景。</p><p>灯火辉煌，马踏留踪。</p><p>少女迈步在不知名的城镇中，感受到的，是人间无限的温情。</p><p>灯笼在各家各户间联结着，照亮了每一片周遭的雪花，留下它们晶莹剔透的剪影。马车缓缓驶过街头，引起一阵购置年货的人潮。每个人的脸上都洋溢着幸福的微笑。沿街簇拥的，是喜换新颜的客栈茶楼，新竹植于庭前，摇曳着旧岁的余波，春联置于门侧，欢迎着新岁的造访。</p><p>人潮时不时激起一声惊呼，是旧友忽逢的惊喜，是新友缔交的欢愉。</p><p>“给您拜年了……”</p><p>“新年好呀！”</p><p>“好久不见……”</p><p>少女行于熙熙然的人海中，也受到不少祝福，自然而然生出一股和乐与安宁的心绪。</p><p>她面带着微笑，朝着争相挤到她身边的来拜年的稚童与素未谋面的小生点了点头，轻声道声新年好，下一秒却消失在茫茫人海中，留下几个失去方向而茫然的脸。</p><p>少女只一个转身，玲珑小靴已踏上屋顶，她轻轻蹲下，把油纸伞放在屋架上，便抱膝而坐。</p><p>人间的画卷在鞭炮轰鸣中为她不动声色地揭开了一角，有山河涌动，有人潮汹涌，有误入画中人的一遭迷梦。</p><p>“原来已经有人了吗…”屋檐下传来一声清脆的少年音。</p><p>金乌低头却只看见双手正攀在屋角的少年清澈眼眸，少年尴尬笑笑，看见屋头上突然探出的少女的脸，微微一愣。</p><p>“那我另寻一处吧，也不扰姑娘雅兴。”少年微笑，就要放松好不容易费力拽紧的檐角。</p><p>虽说大唐盛世已是渐渐有了开放的性别观念，但沿袭几百年的礼，依然规范着少男少女的行为举止，男女授受不亲，依旧是男女相处，特别是独处时的行为规范。少年只是好奇，自己费力才攀上的屋檐，为何眼前的少女也能攻克。</p><p>得也是费了好些功夫吧，也不好意思扰人清净是吧。毕竟躲避喧嚣人潮，屋顶确实是个不错的选择。</p><p>少年心想着，右手已是松动，正回头寻找落脚点，忽觉手上一温，接着是如丝绸般顺滑的肌肤略过掌心，一双小手已是将他握住，轻轻往上一拖，恍惚间，人已是坐上了屋顶。</p><p>金乌毕竟非世人，从未有那么多规矩束缚，她想怎么做，便怎么做了。</p><p>少年回过神时，尚有几分讶异。</p><p>“这……这……”少年想了半天，不知道该说什么。</p><p>“咳咳……”</p><p>一腔尴尬只好化为万能的两声轻嗽。</p><p>“没事，我一个人坐着也空出来很大一片地方呢。”</p><p>金乌将纸伞抱在怀中，对不知如何是好的少年微笑。她对少年并不反感，少年十七八岁，或许恰及冠，眼神清澈，却好似藏着许多故事。</p><p>少年点点头，脸颊不知是灯笼照过来的光还是其他原因，映得有些许偏红。</p><p>从未与女子又如此之近的接触，他只能扭开头看向另一端街头，他怕再多看一眼，自己就会失了分寸。</p><p>“失礼了。”少年轻声道。</p><p>金乌也转头望向街道，脸上却依然残留着几分笑意。</p><p>两个人肩挨着肩，有人强装镇定，却脸颊发烫，有人浅笑依然，却平静安稳。</p><p>“呐，我说，你为什么想到上面来啊？”</p><p>金乌侧头，恰好对上少年偷偷打量自己的目光，少年发现偷窥被发现了，倒也不装了，把头转了过来看向金乌，却是略微失神。</p><p>少女明媚的眸子暖暖的，她的容貌在这双眸子映衬下，很好看。</p><p>嗯，很好看，少年已经找不到形容词了。</p><p>少女似乎因为得不到回应，有些许气馁，眼神黯淡几分。</p><p>果然还是不会在人间和人交流啊。</p><p>金乌正打算重复问一次问题，少年开口了。</p><p>“或许是本能？并不喜欢和人潮一起涌动。”</p><p>“有什么原因吗？”</p><p>“有时候一个人并不需要什么理由。”</p><p>少年说出这句话的时候，声音里带着几分不属于这个年纪的老成。</p><p>“毕竟也已经一个人走了这么久了，可能也成为了一种习惯。你呢，为什么不去和人们接触接触？”</p><p>“因为还没学会吧。”金乌冷而脆的声音少见的多了几分羞怯。</p><p>人间风味甚佳，不忍一口便囫囵吞下所有，慢慢品尝，一步一步来，或许才能更好地品尝所有。主动和少年谈话，何尝不是自己咬下的第一口。</p><p>少年似乎并不惊讶，却是失声大笑。</p><p>“好好好，还没学会，人事复杂，每一个人都是这其中的初学者罢了，只是少有人如你这般坦诚，敢于承认自身的不足。”</p><p>金乌微笑地看着少年，她看到的分明是脱离于稚嫩躯壳的纯净灵魂。</p><p>“敢问姑娘何方人氏？可有定居之所？”</p><p>少年停下大笑，大大方方地看着金乌那深邃却明亮的眸子。</p><p>“不知所来，亦不知所往。”</p><p>金乌浅笑，几缕发丝拂过脸颊，也拂乱少年心头的几根心弦。</p><p>“感情姑娘也是个流浪汉啊，哈哈哈哈。”</p><p>“或许是吧。”</p><p>“那不妨顺道而行，也好作伴？姑娘心中可有去处，亦或可想停下脚步？”</p><p>少年从未见过如此投缘之人，回过神来，才觉已是逾矩。</p><p>少女却是不觉轻佻，一字一字认真从嘴里吐出。</p><p>“长安。”</p><p>“我说，你为什么想去长安啊。”</p><p>马车随着地势起伏起起落落，少年的心也是时刻起落，他担忧着坐在车棚顶上的姑娘会一个不小心在某处地面忽然开出的玩笑处翻然跌落。</p><p>少女却是满不在乎地眺望着无边黑暗笼罩着的远方，远方偶尔闪动的几处灯火是她走过时雀跃的心。</p><p>“只是想去看看。”</p><p>少年在马上回首，看见这尊稳如观音的女菩萨依然安稳，悬着的心也逐渐放下了，毕竟人家也是曾发挥神勇，将自己从屋檐下拽上屋顶的大力金刚，应该也不是一般人吧。</p><p>少年看着微微欠身的少女，问道：“真不考虑和我一起下江南吗？”</p><p>“不了。”</p><p>少女虽然没有理由，但始终坚持。</p><p>“那就只能陪你走一段啦。”少年咧嘴，露出洁白的虎牙。</p><p>“嗯。”她盯着少年，也只是笑。</p><p>星垂平野阔，江入大荒流。</p><p>夜的延长，让人们有了更多时间仰望星辰，也让旅人的道路变得更加梦幻。</p><p>沿途尽是少年的聒噪和少女的微笑。</p><p>少年似是卖弄着自己的学识，遥指天上星，不言人间语。轻侃世间事，却扰梦中人。</p><p>而少女终究抵挡不住啰嗦繁琐的学识，成功的进入梦乡，只是低头瞌睡的她，依旧稳坐车棚。</p><p>“你可知，我为何独身出游？”少年似求回应，却不闻少女出声。</p><p>“或许正是还学不会……”少年回头，只见挣扎于朦胧与现实中的少女闭合的双眼。睫毛很长，在灯火映照下有莫名的闪烁。</p><p>“睡了啊……”少年回身，嘴上却是多了几分惋惜的弧度。</p><p>仰躺而下，背靠马背，有一股温热传进身体里。</p><p>“也罢，或许缘本该如此。”</p><p>少年忍不住又偷偷看了少女一眼。夜色衬托下，她依旧是那么温暖，眉眼间，尽是不知何处的芳华。</p><p>颠簸依旧，只是天明。</p><p>马车突然停下，拦在前面的是几个身影。 </p><p>少女微微睁开眼，前面是四个魁梧男子，面罩遮住了他们的整个脸庞，眼角透露出几丝微寒的余光。</p><p>是打劫的吗。</p><p>不，不是。</p><p>如若为财，透露的应当是贪婪，而非是冷冽。</p><p>这几个人的目光，没有一点烟火气，倒像是无情的猎手。</p><p>或许正处在城与城联系较为微弱的地方，灯光的余晖无法普及至此，唯有一点昏昏暗暗的灯影。而黑暗与朦胧却又加重了不安的感觉。</p><p>她看见底下的少年似是有些许慌张，但他的冷静让他的面容上很快便掩饰得很好。唯独微颤的指尖暴露出了少年的心虚。</p><p>“几位大哥是需要一点过路费吗，刚好我这里有点可以接济接济你们。”少年努力让自己的声音听上去真诚，似乎是想以钱消灾，这熟络的口气，让人不难想象他已经不止一次面对这种情况了。而或许这次的境况，比他经历过的以往的任何情形都要糟，以往只有他一个人，他可以不顾一切的逃走，而这次，马车上还有一位姑娘，如若他不顾一切开溜，她或许会经历难以想象的危险。这次只能尝试能否正面化解危机了，而且，光线在这里明显不足，或许他们并没有注意到马车顶上还坐着一人。</p><p>但很可惜，这次的目的显然不是为财。</p><p>他们的身上，似乎有一股玄乎的气息在翻涌。</p><p>下一秒，便是疾行而来的飞刀。</p><p>不动则已，一动便是杀招，不置退路的杀招。武器离手，只为敌首。</p><p>这种自信，看起来并不是一般毛贼。</p><p>少年完全没想到对方一上来就已是杀手，愣神间，刀尖已在咫尺。</p><p>完蛋了！</p><p>少年眼睛已经闭上，感觉冰冷的飞刀已经将自己洞穿，或许自己的路途，到这里就结束了……</p><p>但在一瞬，他感觉到鼻尖似乎有发丝略过，再睁眼，刀身突滞，却以惊人的速度回头疾射而出！他满脸疑惑地盯着这柄来而覆去的刀，但觉两鬓冷汗已如豆大，身上衣裳在这一霎已是冰凉贴身。</p><p>刀去，猝不及防。</p><p>蒙面男子始料未及，仓促往旁一让，堪堪躲过与他相伴数十载的飞刀一击，半边面具已是擦毁，半张脸血迹斑斑。</p><p>同行三人皆是一愣，意识到发生了什么后，眼角里的寒光转为愤怒，握住手中刀，便要往少年扑来。</p><p>此人，绝非善类！</p><p>三人周身突然有气机汹涌，紧握着刀柄，逐步逼近少年。</p><p>金乌微微抬起头来，她感知到了熟悉的气息。</p><p>“果然，是妖吗。”</p><p>少年是否有大神通，她早已了然。文气缭绕于他身，或许未来不凡，但绝不是当下，当下，不过是文弱书生罢了。</p><p>或许只是萍水相逢，倒也不许初识之友身陷险境。</p><p>至少在金乌这里，待客之道是这样的。</p><p>刹那，伞开，犹如怒目圆睁。</p><p>少女坐在车棚外围晃荡双腿，伞内对准了提刀而来的三人，似乎是猎人时刻紧盯着猎物。</p><p>三人察觉到一股强大的威压，不由抬头，澎湃汹涌的妖力绵绵不绝，抬头一霎，如见修罗。</p><p>“诸友如此行事，可有原因？”</p><p>少女语气并不柔和，眼神冷冽，让这小雪纷飞的夜，似乎冻霜。</p><p>对三人本是如临大敌的境象，却是让他们心头一松。</p><p>噗。</p><p>佩刀皆深插入地。</p><p>四人共同拱手。</p><p>“吾等不识妖友，失敬了。”</p><p>身体不知紧张还是寒冷而颤抖的少年忽而侧转回头，望向车上少女，却见冷峭的脸上却是同样的浮现了疑惑的神色。</p><p>少女纵然一跃，平稳落地。</p><p>这突然一转的场景让她无法放下内心的警惕。</p><p> 最先负伤的半蒙面男子却在此时开口了：“妖友实力定当不俗，又为何与此似隐瞒实力的道者同行？可知修道者，皆是人面兽心的鼠辈。”</p><p>语罢，同行其他三人本低着的头同时抬起，视线共同汇聚在少女身上。</p><p>原来是因为自己刹那显现的神通引起了他们的反感与仇视，并以为刹那规则的流露，来自同行的少年。</p><p>规则，不过是仙力的一种体现罢了，与妖力是两种互斥的存在。小时候自己不懂事时，喜欢将仙道与妖道的神通与气息统称为气息，毕竟自己是妖嘛。不过在苍穹顶生活多年，也早已习惯妖力与仙力的不同运作方式，妖能力从不同的运作方式中，大概分为玄、神、通三系，恰与仙力运作方式中的规则、精神、物理三者对应。自己由妖蜕神后，掌管的规则为时间，虽然已经被剥离神格，依旧可以用妖力按仙力的运转规律运转出类似规则的形态，或许是模拟出的方式过于像仙力，所以刚刚片刻凝滞时间调转刀头的所散发出的，恰是仙力的体现，使得被四妖误解了。</p><p>少女若有所思，不过一般对待仙者与妖者，不同仙与妖都有不同的想法。有认同共存者，亦有仇视者，而故天下冲突频频，这是她登神前世界的大体样子。看来几千年过去，世间仇恨仍是未息啊。纵是如此，妖与仙虽偶有摩擦，也从未显露于凡人眼前，早先抛刀此举又是为何。</p><p>“吾友非是仙者，而诸位可否向我解释一下，为何在未曾确认吾友身份之时，便已下杀手。”少女声音冰冷，却充满不容置疑的语气。</p><p>半蒙面男冷哼一声，眼角跳动不知名的怒火。</p><p>“妖友可知此地为何地？此地为最为贴近吾龙族栖身腹地的前哨站，能在不惊动各巡逻队，轻易至此的，岂可能为善类。妖友又是何故至此？”</p><p>少女一愣，或许是自身出城时便已散发出的屏蔽场隔绝了各妖的感知，而少年又是肆意而行，故而无意间至此地。鲜衣怒马少年时，肆意而行无所知，却是在自己的助力下陷于险地。如此看来，或许还是自己的无意之失。</p><p>少女却是一笑。</p><p>“路过。”</p><p>四下无言。</p><p>“唔啊……”</p><p>女孩申了一个懒腰，从睡梦中醒来。</p><p>“哎呀……又咯到头啦！”</p><p>女孩摸着头上的两个犄角一瞬间睡意全无。</p><p>“没办法咯，那就起床吧！”</p><p>女孩咕噜一下，挺直了腰板，小手攥着被子的一角，如鲤鱼打挺般坐了起来。</p><p>本应盘在耳朵上的碎发掩住了眼睛，炯炯发光的眼神从碎发的缝隙中投射出来，女孩晃晃头，把头发晃到一旁，接着就迫不及待地跳下床，拖着宽松的大衣，光着脚丫吧嗒吧嗒的在地板上走了起来。</p><p>“好像有点凉耶！”</p><p>女孩每一次将脚踏在地板都会立刻迈出下一步，收回先前接触到地面的脚，急促又摇摇晃晃地走到了梳妆台。</p><p>女孩将脸颊的碎发束成一缕，手指上不知何时凝结出一颗水珠，晶莹剔透，倒映出一张笑眯眯的脸。水珠顺着女孩的手指与头发融为一体，将原本桀骜不驯的头发驯服得服服帖帖，两颊的头发长长的下垂，女孩拎住两串头发的发尾，如舞绫缎般将身体微微一旋，拎着的发尾再往上一提，就共同会合在后脑勺啦。</p><p>女孩嘴里叼着一个发簪，红唇微启，微露玉齿，一手拎住两个发尾，空出一手就迅速往嘴边靠，取下轻咬的簪子，发簪尾部划过红唇，轻轻留下一点凹陷的痕迹，簪尖离唇，红唇如果冻般回弹，旋即化为一抹微扬的丹霞。</p><p>两个犄角在浓厚的黑发中只露出一点锋芒，像是她眼眸中忽明忽现的流星。长睫毛在她脸上留下童真的印记，却又不喧宾夺主，不肯轻易遮挡她忽闪忽闪星辰般的双眼。脸颊或许是被偷偷亲过，留下了两朵害羞的粉红。眉间突然泛出几许欢欣，点起几圈涟漪微荡在眼里的星河。</p><p>微微打扮过后，如出水芙蓉般的女孩从椅子上滑溜，蹦蹦跳跳地走向窗台，看向窗外，窗外不是碧海蓝天，却是水底下波光粼粼的美妙世界。看了一会儿随水摇曳的珊瑚群，女孩忽觉无趣，却是突然想起什么，她将椅子搬了过来，一点点小心思从心里偷偷跑到了脸上，一点点小小的坏笑出现在了她嘴角。她摇摇晃晃地爬上了椅子，将双手往前轻轻一推，窗户便被打开了，打开了的还有她的奇妙心情。</p><p>女孩急切地将身子往窗外探，努力全写在小小的脸上。</p><p>就差最后一点啦！</p><p>她往前送着身子，最后闭上双眼，往身后椅子一蹬，像是飞翔般飞出窗户，却撞上了一坨软软的东西。</p><p>她缓缓睁开眼，眼前赫然是——</p><p>一张脸，父亲的脸。</p><p>一张拉得老长的龙脸。</p><p>父亲盘踞在海底，龙身环绕着这座宫殿，此时微扬龙首，正对着她的窗户。</p><p>哎呀，好像不太妙……</p><p>好像……又被发现了……</p><p>女孩看向前方威严的龙首，露出了一个鬼脸。</p><p>父亲长长的龙身在霎那间化为白光，凝成如她般的人形，脸上露出满脸的不快。</p><p>然后……</p><p>然后她就被拎着后衣领，丢回了自己的房间，窗户也被锁上了。</p><p>龙族小公主的禁闭生活，又开始了新的一天……</p><p>“啊啊啊啊啊啊……好想出去玩啊！”</p><p>躺在房间地板上的女孩，如同乌龟般滑动四肢，宣泄着自己的不满……</p><p>“王，为何对公主的保护依旧如此严密，公主已经快成年了吧，这个年纪正是渴望外面世界的年纪啊。”</p><p>“时候未至。”</p><p>龙王淡淡道，眉尖紧锁却透露出他的矛盾与纠结。</p><p>或许旁人看来，落星湖主宰，统领一片龙族领地的龙王——应龙，百妖谱前三的神兽，理应有充足的底气，去庇佑子子孙孙在这个世界上无拘无束的生活着。但所谓站得越高，看得就越远，他深知在他头顶之上的天空，存在着一个更为广阔的世界，那个天神一怒，可毁一世的世界。</p><p>拥有足以傲世群雄的绝对力量，本可选择逍遥行于世，来去无所顾念，他却选择了庇佑一方，为一方的安危思虑，为族群的未来而落子。或许正是因此，他不是偏安一隅的井底之蛙，他的眼里是更为广阔的远方。</p><p>他看着身侧仍未蜕化的蛟龙丞相，以及这广阔落星湖数以万计仍未蜕化的蛟龙，心里十分清楚，或许之于得道成神者，自己一族不过莽苍世间的沧海一粟。自己已经到达世间的顶点，但他仍在准备着，突破这世间的桎梏。而天上那些家伙，对于这世间荣登的异客不甚欢迎，于近百年来，无数将登神的祥兽凶兽，本立于世间顶点，却被抹杀于无声间，或只因他们萌生登神之念，触犯苍穹上诸位的既得利益了吧。</p><p>他对此报之以嗤笑，登神者，不因自身实力强厚而承当应有之职，护佑一方，降世间以恩泽，反而排斥异己，将新起之人弑杀于摇篮中。</p><p>如若登神失败，这一族命运怕不是也已到头。</p><p>成王败寇，败寇的所谓余孽，岂不会为世间以正道之名屠灭殆尽。</p><p>应龙早已看透所谓神者的伪善，而修道的仙者，正是苍穹上人数最为庞大的群体。</p><p>四海各兽，曾登神者，惠及山海，共成大道，如今却是杳无音讯，或许这一轮没有余烬不再复升的落日，带来的黑暗，远没有那么简单……</p><p>龙鳞幻化而成的甲胄，在这个中年男人的身上格外的合身，或许是他这一生从未退缩于任何挑战前的英气，以及无数血水的浸润，让他的肃杀与威严甲胄融为一体，一夫当关，万夫莫开，他的身后，是万丈蔚蓝的世界，进入者，格杀勿论。而他为此奔波背后的支撑，正是他的女儿，即将成年的龙族公主。</p><p>“王，似乎有两个未明来意的来客已经闯进了我族腹地！”</p><p>门被打开，有匆忙的侍卫来报。</p><p>“腹地吗，已经很少有人能闯至此处了……是仙是妖，可知？”</p><p>“似是一仙一妖……”</p><p>应龙眼中闪过一分杀意，水下洞天亦是一寒。</p><p>“吾往会之。”</p><p>甲胄摩擦着，发出嘎嘎之声，似乎刀过骨头留下的恐怖声响。龙王提起自己的尾鳍化成的尖刀，大步迈出了水下城堡。</p><p>仍为蛟龙隐露龙鳞的丞相立于王座旁，望着远去的背影，心中泛起一丝敬佩。他是一个好父亲，亦是一族最好的王，永远亲力亲为，而对仙者，他亦是从不留情的杀手。</p><p>“所以说，你们十分仇视仙者咯。”</p><p>金乌的伞仍未收起，立于少年身侧。</p><p>而好不容易摆脱自己仙者身份的少年倒是和四位蒙面来者唠上了。</p><p>少年本一无所知，但危机下显出的急智，让他从蒙面者的口中得知了许多他本不知道，本不该知道的见闻。</p><p>经历漫长的一次谈话，她了解到这是一支脱离市井，独自生活的龙族，或许是对仙道的排斥，使得他们不染烟火，仇视仙者。</p><p>而少女却是很能体会他们的心情，这一族的领袖应当是一位相当有见识的人了，一步一步从天际步往人间的她，见识到了各式各样仙神的嘴脸。</p><p>但已经无所谓了，一切皆是过往。</p><p>负担一切的领袖，真是辛苦啊，特别是仇恨这么沉重的东西。</p><p>少女嘴角平缓，似是同情着这位领袖，知道的越多，承担越多，这世间，痛苦的往往是身处浑水的清醒者。</p><p>而空气中若有若无的一股气息让她有些在意。</p><p>已经很久了。</p><p>遍地雪花飘，漆黑不见的周围潜藏着未知的风险。</p><p>真是讨厌啊，这种感觉。</p><p>或许该让漆黑中的猎人知道，谁才是猎物。</p><p>少年靠自己的语言技巧与四位蒙面男人已经逐渐熟络。</p><p>也不是没碰见过生死一瞬的场景，只不过这次的遭遇确实让他见识到了自己的渺小，在这种未知的力量面前。</p><p>虽然很好奇，但他只能为了自己活下去的希望，不断用自己的语言周旋，甚至诱使对方放下防备。</p><p>也许让他们卸下防备的不是自己的语言，而是身边的这位不知何处神仙的少女与他们展现出来的同源力量，但自己亦只能是尽人事，听天命，他只想争得片刻松懈的时机，然后逃走，像以前一样，这就是紧急避险，这就是孤身一人行万里积累下来的宝贵经验。</p><p>未知，是最他最大的恐惧。</p><p>而他只能依据现下的情景，选择应对未知的最佳办法。</p><p>他选择相信自己的经验，或许身边的少女也是可以相信的对象，但她一样，源于未知。</p><p>“我说四位大哥，你们这份仇恨到底来自何处啊。”</p><p>少年佯装镇定，故作深沉问道。</p><p>失去半边面具的男子突然一怔，似是陷入沉思，三位同行蒙面人望向他，似乎在等待他的回应。</p><p>少女忽觉空气中那股气息渐凝，似乎是心情出现波动。</p><p>于是她开始收伞。</p><p>几乎是同时，她和少年内心都涌现出一个想法。</p><p>“机会！”</p><p>少年刚要翻身下马，趁对方注意力不集中之时，撒腿开溜！</p><p>不过身遭突然迸发的一股狂野的力量让他下意识产生了恐惧。</p><p>源于巨大巨大未知所唤醒灵魂中最深处的恐惧……</p><p>身边少女的伞，突然如箭般割裂时间，化作浓稠的一线黑暗，疾射至远方，似乎是其远而无所至极，而残留下来的残影汇成黑暗，似乎是割碎时间留下来的黑洞。暗影延伸的方向，突破视野所见，最终被阻挡。</p><p>漫天雪花为黑线让路，或许说成洞穿更为准确，黑线所在的范围内不见片雪。</p><p>透过这不被雪花遮挡的通路，少年隐隐约约看到有人在阻挡这把伞。</p><p>并不是主动，而是被动的无奈之举。</p><p>伞带来的狂野能量让挡伞之人人生第一次，产生惊诧。</p><p>无论何种生物，面对未知时，总会是这般，产生无力感，而当未知带来后果不可估量时，担忧死亡的恐惧就会一步一步爬上内心，把好不容易聚集的勇气驱逐。</p><p>四位蒙面男子在这瞬间相信了少女的话，或许真的是路过，如若真抱有其他的目的，又哪会与他们出言交谈，一照面，这世间便不再有他们存在过的痕迹。</p><p>少女低声呢喃：“好久没打架了呢。”</p><p>刹那，便是磅礴妖力如大潮至，如若蝼蚁仰观百丈之台，崩塌瞬间带来的汹涌冲击。</p><p>挡伞人已经意识到了，这是大陆上少有能撼动他的存在之一。</p><p>不，应当是碾压了。</p><p>试探性的一击竟将他逼迫到如此地步。</p><p>但他依旧提刀而上，即使甲胄上斑斑裂痕在延伸。</p><p>风雪过后，他抵着黑线，逐渐一步，一步，显现在这一击带来的凌乱中。</p><p>“王！”</p><p>蒙面人看清来者后，纷纷跪拜在地。</p><p>一身甲胄早已凌乱，嘴角隐隐约约有一丝暗红显现。</p><p>但他依旧是王，眼里的王者气息与威严不损分毫。</p><p>“远道而来的客人，招待不周，见谅了。”</p><p>话音刚落，他紧执刀的手握得更紧了。</p><p>“无妨，但请。”</p><p>少女将伞搁置在肩上，微微偏头，垂下发丝缭绕在耳畔。</p><p>她在笑，不是轻蔑的笑，而或许是欣赏的笑？</p><p>应龙不知道是否是自己的错觉，但眼下已经无法去想那么多了，他提起刀，略过雪地留下一道痕迹，向着少女的方向冲锋，脚下的战靴每踏出一步，就会使地面多出几条裂缝，恰似步步生莲，但这莲，却是埋下死亡的伏笔，他的力量，已经到达一种非常夸张的地步，气势澎湃，而坚硬的龙鳞化成的战甲，在妖力的蔓延下开始复原如初，此刻甲胄相碰发出的咔呲声，就是他吹响的反攻号角。</p><p>不过数息，他的大刀便劈砍而下，对着少女娇小玲珑的身躯，便是丝毫没有保留的一击，抡着大刀在空气中画出一道半月，散发森森杀气。</p><p>少女却是翩翩而动。</p><p>应龙还未回过神来，只觉大刀从侧面遭受一击，角度发生了细微的偏移，下一秒，少女就只是轻掂脚尖，身子一旋，从大刀的攻击范围中翩然而出，她的伞恰好抵在大刀的受击处。</p><p>速度好快。</p><p>应龙微微一惊，在这一劈砍中，他嗅到了身侧点到为止的杀意。</p><p>或许这短短一照面间，少女的应对动作并不止他所看到的那么多。</p><p>但他依旧想要探个究竟，少女身上那股玄妙的气息令他着迷，或许是未知的深渊，但凝视着深渊本身的他，这只会更吸引他。</p><p>“有意思。”</p><p>他轻哼一声，嘴角开始上扬，他渴望的，正是这种能让他得窥大道的战斗。</p><p>他将身体往侧面一让，挥刀侧旋，迅速追击，他是通系，唯有不断贴近对手，他才能发挥出自己的长处——力量，唯有逼迫对手不得已露出破绽，他才会有胜算。</p><p>往往依靠力量带来的高速攻防，他在各种战斗中便能够胜出，而在今天的对手面前，他感觉自己似乎被彻底洞悉了一般，不过侧旋挥砍起手，刀还没有割碎空气发出爆裂音浪，他的刀就已然无法再动分毫。</p><p>又是那一把伞，在他还未发力时，便已精准预判到这把刀将往的方向，结结实实阻挡在劈砍的路上，使得这一招所蓄的力量全数褪尽。</p><p>“可恶。”</p><p>他迫不得已，只能迅速将刀下沉，刀刃逆向发力，回插到地面勉强支撑住自己的平衡。</p><p>与此同时，他的双脚往雪地上倒画出一个半弧，扯着身体回旋到刀后，与刀，少女形成三点一线，做好了防护以应对少女突然袭击。</p><p>可是少女只是站在那里，什么也没有做。</p><p>“啧，看不起我吗。”</p><p>应龙察觉到少女似乎没有出手的打算，即使很不想承认，但对方似乎并没有把他当成值得出手的对象。残破的披风在风雪里飘动，原本鲜艳的红在漆黑的雪影里只剩下不再张扬的暗红，唯有偶尔甲胄反射微弱光芒透过披风，方能看见其本来肆意的鲜红。</p><p>少年依旧在车上，一切发生得是那样迅速。在他眼睛里，不过是刀光剑影，电光火石的一瞬，他便看见那个他们口中高傲的王，从出现，到威严，再到残破不堪，都只是一瞬。玄之又玄，无迹可寻。</p><p>“打算蜕而登神了吗。”</p><p>少女在交手了几回后，隐隐约约感受到眼前人身上的气息似乎已是十分敦实，恰似孕育于厚厚种皮里顽强的嫩苗在本能的追求突破，成为参天之树。不过，蜕变时是脆弱的，如若没有周全保障，嫩芽也会夭折在坚实的土壤中。</p><p>即使是碾压之势，金乌还是能感受到单纯作为妖，对手带来的磅礴气势。</p><p>应龙闻声却是一笑，他已然明了少女与他的差距。</p><p>莽莽大陆，明白天外有天的妖兽不多，即使是窥视苍穹，亦不会有几许人把登神当成如平常小事般提及。大部分妖兽碌碌一生，或许只是在追求大陆上的极致，而抬头望天者，彼此互留几分敬畏，这分敬畏，却为少女平静的语气所打破。</p><p>“那里现在可不是很欢迎我们啊……”</p><p>少女眼里多了几分同情。</p><p>“没事，总是要去那里走一走的。早晚都要。”</p><p>应龙却是挺直了身子，眼里回以热忱与坚定。</p><p>刀回旋上提，架在了肩上。</p><p>他已明了，眼前的并非敌人。</p><p>“那只能祝好运了。”</p><p>少女将伞撑开，偏头一笑。</p><p>两人中间隔着些许距离，彼此对视，落雪依旧。</p><p>“不妨同行？”</p><p>“不想了。”</p><p>少女摇头，轻轻巧巧地跳回了车棚上。</p><p>应龙凝视着车顶的少女。</p><p>“或许你有非去不可的理由，但我只想驻足于此。”</p><p>少女摩挲着伞骨，轻声道。</p><p>“既是如此，也不强人所难。如若不急着赶路，不妨进我族栖息之地，稍作休整，顺便也做个见证。”</p><p>应龙侧身让路，请来者入湖。</p><p>少女将腰往前一低，将头探下车棚，与少年对视。</p><p>少年正发着呆，突然被少女倒挂着的脸吓了一跳。</p><p>“可急着赶路？如若不急，暂且同去？”</p><p>少年虽是有些后怕，但少女温和的语气让他有些许安定。</p><p>那便去吧，反正自己出来也只是四处闲逛，江南就当做最后的目的地吧。</p><p>“嗯。”</p><p>马车渐远，消失在了暮雪招摇处。</p><p>只剩越来越稀薄的马蹄声偶尔回荡在这寂静的长夜里。</p><p>道路在延伸，从黑暗到光明，只有须臾的跨越。</p><p>一行人逐渐把风雪带来的冰寒与黑夜带来的悄怆留在了背后。</p><p>波光粼粼的湖泊呈现在眼前。</p><p>群山连绵犹如拱月般把这个湖泊捧在掌心，也犹如栅栏般将湖与外界隔绝。</p><p>行于群山中的小道，却无半点海拔的拔升，恰如穿行在由山组成的丛林中，复行数十步，豁然开朗。掰开一瓣一瓣的山，里面露出的是落星湖，湖泊上方停滞着一个巨大的天灯，在水中映出另一个自己，是湖泊灿若星辰的眼眸。</p><p>天灯的灯光蔓延到了岸边，这一带都笼罩在一种温馨的光线下。群山的内侧也受到宠幸，染成金黄，变成了半面金黄，半面靛蓝的玉璧状，向内的一面的暖黄，是对湖泊献出的殷勤。</p><p>恰如应对人们应对黑暗而做的青莲灯，妖们也为自己点亮了生命之光。</p><p>金乌有些许感慨，在失去了自己光芒普照后的世界，依然用他们自己的方式去追寻光明，而他们的光明却是同样震撼人心。</p><p>金乌开始想起很久很久以前，有个人曾摸着自己用还很笨拙的手法扎成的丸子头，问自己是否愿意给这个世间饱受寒冷的生灵带去点点温暖。她很喜欢她手的温度，她也很想把这份温暖带给其他生灵，于是她毫不犹豫地跟着她走了。</p><p>也是很久以前的事啦。</p><p>只还记得她的名字，和她那温暖的掌心的温度。</p><p>羲和，他们都叫她日母呢。和月娘也是一对很好很好的姐妹呀。</p><p>“前面差不多到了，不过陆地上的朋友们到我族栖息地还需要一些小小的帮助。”</p><p>金乌的回忆被应龙那雄浑的声音打断了。</p><p>在天灯照耀下，他浑身战甲都反射出灿烂的光芒，而他那略带一点沧桑的脸颊也顺带着被点亮了几分，可以看出棱角分明的脸上英气依旧逼人。</p><p>或许这大叔再年轻几百岁，风光应当也是无限了。</p><p>早些年时候，自己还在苍穹顶时，也肯定不会拒绝有这么一个威风堂堂的帅哥登神作伴啦。</p><p>金乌收起嘴角偷偷溜出的笑意，轻声回答道：“我应该就不用了，他可能需要重点关照一下。”</p><p>少年不情愿地撇了撇嘴。</p><p>不过他也不得不承认，或许在场的各位，只有他是最为普通的陆地上的朋友。</p><p>应龙那威严的目光看向少年，却是感受到少年身上一股莫名的气息，有些让人亲近，又有些许像他讨厌的味道。</p><p>但至少少年看上去还是那么淳朴无害。</p><p>希望他不会成为我族的敌人吧。</p><p>“还未知晓各位朋友的名字，虽然对于妖而言，名字并非要紧之物，但此次相会多少有些亏待了这位人类朋友，就按人类认识新朋友时的礼节来吧。在下应龙，请多担待了。”</p><p>应龙洒脱一笑，作了一揖。</p><p>少年一愣，随即却是一恭。</p><p>“在下太白，小人物而已，不足挂齿。”</p><p>旋即抬头一笑，张扬而又有分寸，举手投足间尽是年少自信。</p><p>或许未知的事物，也没有那么可怕嘛。</p><p>少年对此次萍水相逢之人，当作了好友。</p><p>“好吧，”少女虽然不是很想提及那个名字，但气氛到了，不说也不合适，毕竟现在自己也只是平凡人间的一员罢了，自然要循这世间礼节。“金乌。”</p><p>在场两人差点石化，难以置信的眼光看向了少女。</p><p>少女说完吐吐舌头，眨巴了下眼睛，不好意思的笑了。</p><p>果然还是不说本名比较好啊。</p><p>少年在少女说完的一霎，思绪已是飘回到许久之前他曾接触到某一本书，曾经少年心气的他从不会吧古人记载在山海经中的神鬼怪谈当作真实存在过的事物，而今接二连三的奇妙事件却是让他明白了些许什么，少女这个存在于莽荒久远时代的名字，或许是那个时代对他揭露的冰山一角。</p><p>他望向应龙，应龙也似乎想起了什么。</p><p>应龙在稍一失神后，洒然一笑。</p><p>“难怪你我差距是如此之大……毕竟敢于逆天道而存妖道入神的，千百年来就只有你一个啊。”</p><p>少女摆摆手，不好意思的笑笑。</p><p>“太白，吾先予你我族之佑，便于你可无所顾忌的入访落星湖。”</p><p>应龙随即便是随手一挥，凝结出一颗水珠，悬浮于半空，透亮而玄妙莫测。</p><p>水珠缓缓移动，若在空游无所依。</p><p>移至少年身侧，悄然与少年相融，成为少年身体的一部分。</p><p>少年感觉到身体中有一股玄妙的感觉在奔涌，指引着他与周围的环境融合在一起。</p><p>呼吸，吐纳，似乎是自然不经意间穿梭于他的身体。</p><p>“准备好了，那就走吧。”</p><p>披甲身影略一轻踏，便是掠出，在天灯照耀下如旭日初升，又缓缓落于湖中，隐于平静。</p><p>“准备好了吗？”</p><p>少年听闻耳畔少女的轻语，即使是有几分犹豫，他还是轻轻点了点头。</p><p>“那我们也跟上去吧。”</p><p>少女飘然而往，若非群玉山头见，会向瑶台月下逢。</p><p>空中她转了个身，对岸上的少年展露一个如花笑靥。</p><p>少年也是微微一笑，虽然是不可置信，而且不识水性，但他平生何时不曾像这样放肆洒脱过？</p><p>只是鞋湿了的话，会很麻烦吧。</p><p>不过也是，这一跃，怕不是衣裳也要全部湿透了。</p><p>也罢，且随心意而动吧。</p><p>少年感觉身体犹如飞舞的蝶，十分轻盈，轻轻一蹬，便向着天灯下的落星湖飘然而去，在这一瞬间他甚至有登仙之感。</p><p>这个感觉，他用了一生寻找，最终在酒中得到，或许这也是世人为何称他为醉诗仙吧。</p><p>而这一夜，这一跃，是少年在生命的最后一个夜晚，那一壶酒，那一方潭水，褪去鞋履，纵然而往极乐，醉酒之中的最后一段回忆在播放……</p><p>少年始终不敢睁开眼，不只是身体上的阻碍，心灵上也有一层奇怪的障壁，似乎是只要睁开了眼，他所见人间，便会不及眼前他所想象的世界，致使自己流连而往返。</p><p>“可以睁开眼看看。”</p><p>他感觉到身侧有人经过，帮他调整方向。</p><p>奇怪的是，即使未曾睁眼，他能感觉厚厚眼睑前方，并非漆黑一片，而是隐约闪动着光，似是霓虹，似是琉璃。</p><p>他尝试将眼睛睁开一点，发现没有半点湖水阻碍，而呼吸也是畅通无阻，便开始放松，眼睛缓缓睁开，而此时他发现自己似乎是在“云层之上”，俯瞰着“地底”的一切事物。而缓缓向地面靠近的过程，却是像极了一次下凡的经历。</p><p>这感觉，有点玄妙。</p><p>虽然是在海底，但这座海底城邦并不局促而显得小气，而是宽阔而恢弘，肃穆而庄严。</p><p>不可思议。</p><p>粼粼波光在头顶交错闪映着，而湖面之上的天灯发出的光，在湖水过滤后纯净而温馨，似乎是……另一个太阳？湖底不同于陆地之上，总有些从未见过的玄妙生物浮动在水层的各个地方，有梦幻般闪烁奇异光彩的水母，缓缓在蓝色的湖里蠕动，从湖底到湖面，再从湖面到湖底，像蓝色梦境的点缀，若把湖水比作天空，它们似乎便是另一种星辰。</p><p>湖底是一座朴素而宏大的城池，万家灯火，烟火寻常。中央矗立一座宫殿，宫殿的门窗透露几许幽蓝，是来自深水的灯光。城池的脉络清晰可见，自北向南是一条长长的主干道，沿途挂满小灯。以主干道为直径延伸出了一个圆，排排矗立着小城居民的房屋。</p><p>“这就是……龙生活的地方吗。”</p><p>“准确来说，应该是蛟龙，龙可不是那么常见的。”</p><p>前方的应龙回头应道。</p><p>一行三人从水面向水底深入，留下一道长长的拖尾在水中，像是坠落的流星。</p><p>水里空间的阻隔比较小，在深度上的运动比较自由，所以偶尔能看到一些嬉戏的稚童或少男少女在不同水层遨游，共同留下的痕迹在“天空”上绘制出一幅幅画。</p><p>一直处于深水中，未曾面世的那一座城，就这样缓缓在少年眼前展开。</p><p>慢慢的，慢慢的，少年逐渐接近这座城池的大门，很快就要离开他所熟悉的一个世界，去往另一个他未曾了解过的世界。</p><p>怒目圆睁的龙头在他眼前逐渐变得清晰，那是用未知材质雕刻而成的城门，城门很难说清有几丈高，它的威严已不是用高度能够丈量的了。</p><p>少年的脚已经可以接触到地面了，但他依旧沉浸在龙头城门带给他的震撼之中，许久未曾踏上这一方土地。</p><p>少女在一旁看着少年这一路来的惶恐，惊诧，沉浸在自我世界时表情的变化。</p><p>她是理解的。</p><p>毕竟总会有一些时刻，这个世界不经意间向你透露出了它曾未从展示给你的隐秘部分。而这个过程是迷茫，却又令人惊喜的，这也能解释这世上为何有那么多人喜欢探索未知的远方。</p><p>“你还真是下了苦功夫啊。”</p><p>趁少年还在愣神，少女慢慢往前几步，走到了应龙身侧。</p><p>“但这也不能确保我族长长久久不受侵扰，威胁总是来自于未知与心胸狭隘的某些鼠辈。所以吾也在尽力迈出那一步。”</p><p>“如若失败了呢，怕是动静不小，引来的不怀好意的人或妖或许都不会太少。”</p><p>“我族从未有人尝试踏出过那一步，都是在担忧你所说的情况发生，但与其一辈子苟存于此，与世无争，何不如勇敢一步，让我族选择自己所爱的生存方式。”</p><p>“还是那个问题，如若失败了呢？”金乌十分认真的问道。</p><p>这并不是一个简单的问题。</p><p>如若失败，失去的不仅是庇护这么简单。</p><p>覆巢之下，焉有完卵。</p><p>“如若不为，千千万万世后依旧有人需要为这个问题而煎熬，何不如让我负起这个责任，成了，那便是成了，败了，历史的罪过皆为吾一人之责。”</p><p>应龙站在他所深爱的这一方水土之上，却是肩负着这一方水土的一切，无论悲喜。</p><p>“而，他们也信吾。”</p><p>金乌从他的眼中看到的，却分明是不会失败的未来。</p><p>登神，成王败寇，成功是对勇敢者，心怀大爱者的奖赏。</p><p>“我向星辰下令，我停泊属望。我让自己登基，做风的君王。”</p><p>正如同某本书所记载。</p><p>“或许你真的可以做到。”</p><p>金乌向他展露微笑。</p><p>“登神后，再战一场，那将不再是没有悬念的战斗了。”</p><p>应龙笑道。</p><p>“一定。”</p><p>身后少年回过神来，踏上这一方土地，却只见身前的两人不知为何，都露出了释然的微笑。</p><p>“你们也会过节日吗。”</p><p>“虽然是在地平线以下，但我们的生活与寻常人间也没有什么太大区别。”</p><p>“这么说也是哦，过几日就到上元节了。”</p><p>少年一边逛着这座城池，一边惊讶于它的繁华与盛大。</p><p>“是呀，一个盛大节日。”</p><p>金乌眼里难得有星星在闪。</p><p>进入城门后，是一眼望不到边的大道，而两旁的屋舍像是夹道欢迎般展开。</p><p>也许是元宵快到了，家家户户门前都挂着灯笼与各式新奇的灯。</p><p>少年想伸手去触碰一盏未曾见过的灯，感受一下它的材质，在伸手的过程中随口问了一句：“这是什么做的？”</p><p>金乌笑笑，问道：</p><p>“可曾见过鮟鱇鱼？”</p><p>少年的手停住了，有些不知所措。</p><p>鮟鱇鱼？</p><p>不会是那种长得很可怕的那种吧？</p><p>少年悻悻然将手缩了回来。</p><p>“不错，正是鮟鱇鱼。能在海里发光的灯芯可不多，而恰好又有安康二字，便断章取义，且祝安康，一晃这么多年，也就成了习俗了。”</p><p>应龙回答道。</p><p>“那不会就叫做安康灯吧？”</p><p>若是以此为名，感觉有点配不上这幽邃玄妙的蓝灯。</p><p>“仍是命为天灯。不过是换了种形式，在哪里出现，它的本质还是依旧如前。”</p><p>恰似回应，突然一阵水流涌动，这一条街的天灯都轻轻摇曳了一下，像是点缀在深海里随风摇曳的薰衣草。</p><p>“不同于这些只在上元前后才拿出来的小天灯，那盏湖面上的，是长久不灭，恒久悬挂在人间，护佑我族安康的长源天灯。”</p><p>三人抬头，透过缠缠绵绵的静水，天灯恰似暖阳普照这一方小天地的每一个角落。</p><p>粼粼波光与偶有的几串气泡，与光线交错，铺就了这梦幻的水世界。</p><p>“水底居然也能铺上青石板！真了不起！”</p><p>少年像一个充满好奇心的小孩，每走一步，都会迸发惊奇的叫声。</p><p>当然，他的声音也引来不少路上行人的目光，所以一路都是万众瞩目。</p><p>这让本是便装出行的龙王很是苦恼，再这样下去或许迟早会被自己的子民认出，而又难以脱身了。</p><p>“我们走快点吧，很快就到王宫了。”</p><p>靴子落在青石板上的哒哒声变得十分紧凑，开始提速了。</p><p>“王。”</p><p>宫殿前的士兵略微鞠躬，打开了宫门。</p><p>“免礼。”</p><p>应龙对他们略微点头，接着便带领同行两人迈进真正处于这湖底中心的宫殿。</p><p>不知道是什么原因，金乌总觉得这座宫殿似乎是略显朴素了一点，并没有想象中那般外表豪华而屋檐棱角分明。</p><p>甚至于楼阁间各抱地势，勾心斗角的布局也没有。</p><p>而内部的装修却是很精致，并不能算是奢华，而是简洁却大方。</p><p>进入宫殿后，可以从大门处直直望向正殿，两边各有席位，似是平时办公处。</p><p>之所以能一眼认出是正殿，是因为殿厅虽远，却可以看清其布局陈列都是围绕中央尽头高耸的红色座椅展开的。一轮一轮像涟漪般往外延伸，只在半圆中间留出一条小道供人员进出。而且这种布局有种开门见山之感，对于上朝之人也能起到很好的指引作用。以众星拱月之势进行排列，也有一种突出主座威严之感，对于宾座施以统领。</p><p>龙王似是并不打算在此做过多停留，往右侧迈步，从狭长的长廊中向宫殿深处走去。</p><p>少女少年跟随其后，一路上长廊的灯影摇曳，渲染出暖黄的色调。</p><p>“抱歉，有件要紧事要办，吾便不过多介绍了。”</p><p>应龙略带歉意的笑笑。</p><p>“无妨。”</p><p>本就是不速之客，得以窥见异世，便已是很大的收获了。</p><p>于是很快的，三人就走到了宫殿深处，掀开珠帘，眼前赫然是陈设十分温馨的房间。</p><p>“父亲！你终于回来啦！我好想你啊！”</p><p>应龙刚一迈过门槛，就有一团小小的东西扑了过来。</p><p>然后就挂在了应龙脖子上，两侧发丝垂落，才露出了一个红扑扑的小脸蛋。</p><p>发丝垂落的瞬间，一双盈盈琥珀色眼睛恰巧与金乌对上了视线。</p><p>“咦，是有客人来了吗。”</p><p>女孩鼓鼓的两颊一颤一颤，小红唇里嘟哝着。</p><p>“嗯，是刚认识的新朋友。”</p><p>应龙将女孩抱起，轻轻地放在地上。</p><p>女孩的脚刚一接触地面，便急不可耐地吧嗒起来。</p><p>“父亲父亲！这个姐姐好好看呀，是从天上来的吗？”</p><p>说着，就伸出自己的小手，想去拉金乌的手。</p><p>女孩眼里有一股奇妙的光彩，是纯净的云彩。</p><p>“姐姐，姐姐，可以带我去天上玩吗。”</p><p>金乌将伞轻轻放在一旁，慢慢蹲下握住了女孩的手，像握住了一团棉花糖，还带着一点余温，另一只手顺着发丝轻轻抚摸着女孩头顶小小的犄角。</p><p>“姐姐可能要问问你爸爸同不同意喔~”</p><p>金乌看着女孩美丽的眼睛，露出一个灿烂如春的笑容。</p><p>女孩眼里的色彩在流转，轻轻吸了一口气，她好喜欢眼前这个美如天仙的姐姐。</p><p>金乌与应龙交换了一下眼神，龙王眼里满是歉意，似是为女儿的冒犯而道歉。金乌却是笑笑，给了小女孩一个拥抱。</p><p>“嗯嗯！但是爸爸平时管得好严，啊璃真的好想出去玩呢。”</p><p> 小女孩将水汪汪的大眼看向面容严肃的父亲。</p><p> 父亲的眼里似乎还是满是严厉的拒绝，还有几分对她的责怪。</p><p> 她眨巴眨巴眼睛，好想得到父亲的同意呢。</p><p> 以前，虽然父亲对她看护十分严格，但在手头事情解决得差不多之后，都会带她去逛逛城市，走走大街小巷，只不过好像已经好久没有出游过了。虽然很理解父亲或许最近很忙，但她就是很想出去逛逛，看看除了这座宫殿外的世界，看看外面的蓝天。</p><p> 可以吗，让好漂亮好漂亮的姐姐带着自己出去走走，虽然很麻烦人家啦。</p><p> 应龙不为人知地叹了一口气，眼神缓缓变得柔和。</p><p>“过几天就是你最喜欢的上元节了，那让姐姐带你出去逛逛吧。”</p><p>“好！”</p><p> 女孩高兴地跳了起来，落地时发出一声脆响。</p><p>金乌眼里满是笑意，她想起了一些以前以前的欢愉日子。</p><p>正月十五。</p><p>上元佳节。</p><p>家家户户，老老少少，男男女女，熙熙攘攘。</p><p>满城欢庆。</p><p>自永夜以来，青莲灯已经是寻常事物，上元佳节，自然多些许与日常不同的灯光华彩。</p><p>  亦或者说，寻常上元盛况，不过是永夜以来的白昼现状。</p><p>雪迹未消，少女们平日禁锢于庭院，楼阁中无处寄托的情思与向往自由的心灵已经飞出窗棂，在雪地上留下漫步而过的足迹。</p><p>盛唐以来，男女往来一改以往拘束而刻板的形式，少男少女们得以携手同游，沿途桂花同载酒，却不逾矩。少年情思得以满城纷飞，但少女们寻常日子里并不会刻意打扮，而且也不会离家太远，却似在卯足了劲，期待着上元这一天的到来，百花齐放。平日打扮素朴的姑娘们在这一天如换了一个人般，少年街头上穿行时，时常感觉恍若蓬莱，寻日女伴在这一天变得是如此不凡，两个人面对面，两脸赧然，红扑扑的，支支吾吾半天，却是无法如往日般自然聊天。</p><p>最令人期待的，莫过于寂静夜空下突然绽放的火树银花，将这盛大的晚会推向高潮。或伫立在桥头的行人，或潺潺小溪边的坐对赏月的小情人，或如往日般静坐楼阁的忧恼少女，抬头时，恰逢烟花遍生，一个点，慢慢蔓延开来，如同闪电般迅捷，长出了枝桠，一分二，二分四，四分无穷，浩瀚天际在这一瞬间，被烟花匠人的手艺征服，被这一株光影交错的参天大树占据，短暂却永恒地印在了人们的脑海里。每一个热爱生活的人，都会在这一瞬间感慨，人生真是太美好了。</p><p>而这只是晚会的开幕。</p><p>在烟花燃尽后，每一个人都会点燃一盏属于自己的长明灯，点上一盏能与上天对话的天灯，将自己心里平凡而又真挚的心愿诉予天听。</p><p>这个夜晚在一盏盏缓慢而坚定向上爬升的天灯映衬下，渲染上一层暖黄的色调。</p><p>一盏盏载着长明灯灯青莲，随着溪水流向远方，承载着不同于盛大节日的一丝丝哀伤与思念，消失在天际尽头。</p><p>“走吧，人生总是要往前的啊。”</p><p>凝视着远去莲灯的某人被同伴拉起，渐渐远行，只是频频回首，眺望即将消失在水天交接处的摇曳烛火。</p><p>莲灯顺流而下。</p><p>而泛起的层层涟漪下的上元佳节亦是同样盛大而美好。</p><p>或许是自然本出于同源，群妖栖息之处，即使环境不同，所进行的庆祝却是如此相似。</p><p>天灯乘风而起，而水中的天灯借水的浮力而起，出水而止，最终成为水下居民抬头仰望的一颗星星。</p><p>水上水下的世界同时欢腾，共迎着属于此刻的安宁。</p><p>金乌坐在宫殿最高的地方，俯视着歌舞升平的这一方土地，她有点理解了为什么龙王并没有将宫殿建得十分豪华而威严，因为过多的雕饰与流华只会纷繁了眼前的百味人间，万家灯火通明，显示着安定与快乐，就是这座宫殿最好的装饰。</p><p>因为对睡眠质量要求并不是很高，她喜欢一个人呆在高处，稍稍打盹，就像倦鸟归巢，在高处的树丛中偷偷露出双眼，窥视着这个世界。</p><p>而随行的少年也是在龙王安排下，住在了这座宫殿的一角。</p><p>偶尔他也会走上顶楼，和金乌并排而坐，即使相对无言，却也是十分闲适。</p><p>少年并不是没有话说，相反，他有许多问题想问，但他也明白这本就不是他所应该知道的，一路仰仗着少女的帮助，再去打扰人家也有些不太好意思。</p><p>但上元节的到来，打破了这份默契的安静。</p><p>“姐姐，姐姐，今天带啊璃去走走好吗？平时爹爹不让我上来，让我好久都没见到姐姐啦。今天是上元节！我们一起出去玩玩好吗？”</p><p>金乌刚一回头，就有一团糯糯的小团子扑了过来，她刚好伸手就抱了个满怀。</p><p>怀里是女孩充满期待的眼睛和抿得紧紧的小嘴。</p><p>金乌温柔的抚了抚她柔顺的头发，轻轻微笑着问她：“告诉你爸爸了没有啊。”</p><p>“爹爹已经同意啦！”</p><p>“那走吧。”</p><p>金乌话音未落，便已是起身一手将女孩抱在怀中，另一手撑起伞，华丽的回旋着。</p><p>“你也一起去逛逛吗？”</p><p>她看着少年，发出了邀请。</p><p>“可以吗，可以的话我也一起。”</p><p>少年起身，朝金乌走来，金乌将手中的伞递给他，轻声道。</p><p>“拿稳咯。”</p><p>少年触及伞柄那一瞬间，便感觉自己如柳絮，随着伞翩然起飞。金乌抱着女孩，轻点双脚，纵身一跃，便是从宫殿之上跳了出去，怀中的女孩兴奋地拍起了双手，欢呼道：</p><p>“起飞啦！啊璃要出去玩咯！”</p><p>少年跟随着翩翩而动的少女，在伞下犹如壁画中的飞天，一起在水中缓缓下降。</p><p>补设定：妖能力可分为玄 神 通（气息） 三系相当于规则 精神 物理（神通）三系</p><p>发光：妖力强大充沛程度不同自身羽毛光亮不同 金乌喜欢把神通叫为气息</p><p>太阳：以为能力是通系 光 但其实是妖力过于强大尤其是神格化之后对于仙力与妖力共存的过分强大（月娘是神系，她的光是精神世界的投影，从中可以随心意所动，这也是神界两大光源无可替代的原因，从不是普通的光，妖力所化的光狂野，念力所化的光温婉，月娘本体是兔子：玉兔或犰狳（凶兽））</p><p>规则是时间 时间是比光更快的存在 故只要她想要利用时间捕获光 光是无法散播出来的</p><p>仙人脱妖成仙一般会将自身妖性全蜕，但金乌保留了，并且承受了其中的无限痛苦，因此成为仙妖两力通使的强大存在，剥夺神格之后剩余妖力依旧强大而没有成为无神力者。（但依旧懂得仙力的运转规则）</p><p>妖不爱起名字，往往以种族相称。</p><p>先生，又要出远门啊。金乌笑笑，阖门而去，屋里的女孩托腮，踢踏着双腿。那个湖 落星 鳞片 成人礼</p><p>金乌是跟着（夸父？）（祝融？）（羲和？）上去的</p><p>羲和吧 不过是女的（传承？）羲和是早于庄周的 羲和山海经也有记载</p><p>幻想着环游世界</p><p>如果人生是一本书，你打算怎么写接下来的章节？</p><p>靠自己的想象力，为自己续写新的篇章。</p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 小说 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试</title>
      <link href="/article/8257d2b5.html"/>
      <url>/article/8257d2b5.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这个是针对于知识工程的学习与进一步实践，个人感觉难度挺高的，前后花费了大概有三周的时间，第一周主要是解决依赖的各种报错问题，第二周主要用在数据集的裁切和平台迁移上（这个主要受制于gpu的内存不够），第三周主要用在调优思路的探索和实践上，花了这么长时间感觉还是跟学校的课程安排有关，以及现在已经快接近五月了，保研人应该都懂……各种夏令营的事情和课程大作业搞得有点晕头撞向的，因此只能尽自己最大努力利用时间来完成这个课程实践，最后嘛还是有许多遗憾，但只能止步于此了……</p><h1 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h1><h2 id="使用model-art平台"><a href="#使用model-art平台" class="headerlink" title="使用model art平台"></a>使用model art平台</h2><p>模型链接：</p><p><a href="https://github.com/OpenDriveLab/ViDAR">https://github.com/OpenDriveLab/ViDAR</a></p><p>前置：</p><p>配置model art镜像</p><p><img src="/article/8257d2b5/fc91c387a9f5fa96a87e8662028e0c8.png" alt="fc91c387a9f5fa96a87e8662028e0c8"></p><p><img src="/article/8257d2b5/image-20250401153203321.png" alt="image-20250401153203321"></p><p><img src="/article/8257d2b5/image-20250401153223717.png" alt="image-20250401153223717"></p><p><img src="/article/8257d2b5/image-20250401153259882.png" alt="image-20250401153259882"></p><p><img src="/article/8257d2b5/image-20250401153426317.png" alt="image-20250401153426317"></p><p>通过以上步骤进行镜像配置，就不过多赘述了，当时的解释md文件被我删除了……</p><h2 id="遇到的问题以及解决方法"><a href="#遇到的问题以及解决方法" class="headerlink" title="遇到的问题以及解决方法"></a>遇到的问题以及解决方法</h2><ol><li><p>依赖报错问题：主要集中在numpy的版本上，因为model art本身要求的numpy版本较高，但是ViDAR又需要较低版本导致冲突，后面配置了一个脚本用于解决大部分问题：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim install_deps.sh</span><br></pre></td></tr></table></figure><p>然后：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置清华源</span></span><br><span class="line">PIP_SOURCE=<span class="string">&quot;-i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 临时移除 ModelArts SDK 以避免干扰</span></span><br><span class="line"><span class="built_in">export</span> ORIGINAL_PYTHONPATH=<span class="variable">$PYTHONPATH</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=$(<span class="built_in">echo</span> <span class="variable">$PYTHONPATH</span> | sed <span class="string">&#x27;s|/home/ma-user/modelarts-dev/modelarts-sdk||g&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印环境信息</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Checking Python and PyTorch versions...&quot;</span></span><br><span class="line">python -c <span class="string">&quot;import sys, torch; print(&#x27;Python:&#x27;, sys.version); print(&#x27;PyTorch:&#x27;, torch.__version__, &#x27;CUDA:&#x27;, torch.cuda.is_available())&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 1：修复依赖冲突</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Fixing dependency conflicts...&quot;</span></span><br><span class="line">pip install numpy==1.23.5 --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install networkx==2.2 --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install pyasn1==0.6.1 --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install pandas==1.2.5 --force-reinstall <span class="variable">$PIP_SOURCE</span>  <span class="comment"># 确保 pandas 版本</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 2：处理“平台不支持”包，降级到兼容版本</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Fixing platform compatibility issues...&quot;</span></span><br><span class="line">pip install mmengine</span><br><span class="line">pip install PyYAML==6.0 charset-normalizer==3.3.2 fonttools==4.38.0 kiwisolver==1.4.5 \</span><br><span class="line">    lxml==4.9.3 matplotlib==3.5.2 simplejson==3.19.2 MarkupSafe==2.1.5 \</span><br><span class="line">    cffi==1.16.0 greenlet==3.0.3 ijson==3.2.4 SQLAlchemy==2.0.30 \</span><br><span class="line">    --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 3：安装 mmcv-full==1.4.0</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing mmcv-full==1.4.0...&quot;</span></span><br><span class="line">pip install mmcv-full==1.4.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 4：安装 mmdet3d 剩余依赖</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing mmdet3d dependencies...&quot;</span></span><br><span class="line">pip install lyft_dataset_sdk nuscenes-devkit plyfile tensorboard numba==0.48.0 scikit-image==0.19.3 <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install numpy==1.23.5 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install mmcv-full==1.4.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 5：安装 mmdet==2.14.0 和 mmsegmentation==0.14.1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing mmdet==2.14.0 and mmsegmentation==0.14.1...&quot;</span></span><br><span class="line">pip install mmdet==2.14.0 <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install mmsegmentation==0.14.1 <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/open-mmlab/mmdetection3d.git</span><br><span class="line"><span class="built_in">cd</span> mmdetection3d</span><br><span class="line">git checkout v0.17.1 <span class="comment"># Other versions may not be compatible.</span></span><br><span class="line">python setup.py install</span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 6：安装 detectron2 和其他依赖</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing detectron2 and other dependencies...&quot;</span></span><br><span class="line">pip install einops fvcore seaborn iopath==0.1.9 timm==0.6.13 typing-extensions==4.5.0 \</span><br><span class="line">    pylint ipython==8.12 matplotlib==3.5.2 numba==0.48.0 setuptools==59.5.0 <span class="variable">$PIP_SOURCE</span></span><br><span class="line">python -m pip install <span class="string">&#x27;git+https://github.com/facebookresearch/detectron2.git&#x27;</span> <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 7：安装 ViDAR 和 chamferdistance</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing ViDAR and chamferdistance...&quot;</span></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="string">&quot;ViDAR&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    git <span class="built_in">clone</span> https://github.com/OpenDriveLab/ViDAR</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">cd</span> ViDAR</span><br><span class="line"><span class="built_in">mkdir</span> -p pretrained</span><br><span class="line"><span class="built_in">cd</span> pretrained</span><br><span class="line">wget https://github.com/zhiqi-li/storage/releases/download/v1.0/r101_dcn_fcos3d_pretrain.pth || <span class="built_in">echo</span> <span class="string">&quot;Pretrained model download failed, continuing...&quot;</span></span><br><span class="line"><span class="built_in">cd</span> ../third_lib/chamfer_dist/chamferdist/</span><br><span class="line">pip install . <span class="variable">$PIP_SOURCE</span></span><br><span class="line"><span class="built_in">cd</span> ../../..</span><br><span class="line">pip install matplotlib==3.5.3 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install pyparsing==2.4.7 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install kiwisolver==1.3.2 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install --user prettytable==3.7.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提示完成</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installation complete. If errors occurred, check logs above.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可选：隔离环境（注释掉，需手动启用</span></span><br><span class="line"><span class="comment"># echo &quot;If conflicts persist, consider creating a clean environment:&quot;</span></span><br><span class="line"><span class="comment"># echo &quot;conda create -n vidar_clean python=3.8&quot;</span></span><br><span class="line"><span class="comment"># echo &quot;conda activate vidar_clean&quot;</span></span><br><span class="line"><span class="comment"># echo &quot;Then rerun this script.&quot;</span></span><br></pre></td></tr></table></figure><p>然后就是喜闻乐见的一键解决问题了</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x install_deps.sh</span><br><span class="line">./install_deps.sh</span><br></pre></td></tr></table></figure><p>然后有两个地方需要修改：</p><p><img src="/article/8257d2b5/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_2025-04-15_210139_539.png" alt="微信图片_2025-04-15_210139_539"></p><p><img src="/article/8257d2b5/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_2025-04-15_210556_226.png" alt="微信图片_2025-04-15_210556_226"></p><p>之后到达vidar目录下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CONFIG=ViDAR/projects/configs/vidar_pretrain/OpenScene/vidar_OpenScene_train_1_8_3future.py GPU_NUM=1</span><br><span class="line"></span><br><span class="line">CONFIG=projects/configs/vidar_pretrain/OpenScene/vidar_OpenScene_mini_1_8_3future.py</span><br><span class="line"></span><br><span class="line">GPU_NUM=1</span><br><span class="line"></span><br><span class="line">./tools/dist_train.sh <span class="variable">$&#123;CONFIG&#125;</span> <span class="variable">$&#123;GPU_NUM&#125;</span>  </span><br></pre></td></tr></table></figure></li><li><p>数据集</p><p>使用openxlab软件包。注：最高版本openxlab需要python≥3.8，因此需要创建一个虚拟环境安装</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n openxlab python=3.9</span><br><span class="line">pip install openxlab</span><br><span class="line">openxlab login <span class="comment"># 需要创建openxlab账号之后，创建access key再在这里登录</span></span><br><span class="line"><span class="comment">#我的AK/SK放在代码块外面</span></span><br><span class="line">openxlab dataset download --dataset-repo OpenDriveLab/OpenScene --source-path /openscene-v1.1/openscene_sensor_mini_camera.tgz  --target-path .</span><br><span class="line">openxlab dataset download --dataset-repo OpenDriveLab/OpenScene --source-path /openscene-v1.1/openscene_sensor_mini_lidar.tgz  --target-path .</span><br></pre></td></tr></table></figure><p>Access Key: wgakjbrzyyxljprb1b2z Secret Key: rnyq568lwdpayblrb744qdmxyg4xz19vo3b0azog</p><p>然后用上面的指令解压。大概占据硬盘空间170GB左右，因为要解压所以硬盘建议大概250-300GB</p><p>数据集解压后自动移动 MergedPointCloud 到目标路径：</p><p>可以运行脚本vim fix_mergedpointcloud.py</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根目录路径（根据你实际目录修改）</span></span><br><span class="line">bad_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/OpenDriveLab___OpenScene/openscene-v1.1/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line">correct_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有 subdir</span></span><br><span class="line"><span class="keyword">for</span> subdir <span class="keyword">in</span> os.listdir(bad_root):</span><br><span class="line">    full_bad_path = os.path.join(bad_root, subdir, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line">    full_target_dir = os.path.join(correct_root, subdir)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(full_bad_path):</span><br><span class="line">        target_path = os.path.join(full_target_dir, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Moving <span class="subst">&#123;full_bad_path&#125;</span> --&gt; <span class="subst">&#123;target_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        os.makedirs(full_target_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(target_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  - Skipping <span class="subst">&#123;target_path&#125;</span> (already exists)&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            shutil.move(full_bad_path, target_path)</span><br></pre></td></tr></table></figure><p>执行：python fix_mergedpointcloud.py</p><p>或者创建软连接</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">bad_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/OpenDriveLab___OpenScene/openscene-v1.1/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line">correct_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sequence <span class="keyword">in</span> os.listdir(bad_root):</span><br><span class="line">    bad_mp = os.path.join(bad_root, sequence, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line">    correct_target_dir = os.path.join(correct_root, sequence)</span><br><span class="line">    correct_link_path = os.path.join(correct_target_dir, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(bad_mp):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(correct_target_dir):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;路径不存在，创建中：<span class="subst">&#123;correct_target_dir&#125;</span>&quot;</span>)</span><br><span class="line">            os.makedirs(correct_target_dir)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(correct_link_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;创建软链接：<span class="subst">&#123;correct_link_path&#125;</span> -&gt; <span class="subst">&#123;bad_mp&#125;</span>&quot;</span>)</span><br><span class="line">            os.symlink(os.path.abspath(bad_mp), correct_link_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;已存在：<span class="subst">&#123;correct_link_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>openscene_metadata_mini.tgz可以下载本地再直接上传</p><p>最后： <code>python tools/collect_nuplan_data.py mini</code></p></li><li><p>训练的一些报错</p><p><strong>ninja报错</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">RuntimeError: Ninja is required to load C++</span><br></pre></td></tr></table></figure><p>解决：从源码构建并本地安装</p><ol><li><p>下载和构建 Ninja：</p><ul><li><p>克隆 Ninja 官方仓库：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">git clone &lt;https://github.com/ninja-build/ninja.git&gt;</span><br><span class="line">cd ninja</span><br><span class="line">python configure.py --bootstrap</span><br></pre></td></tr></table></figure></li><li><p>这会生成 <code>ninja</code> 二进制文件。</p></li></ul></li><li><p>创建本地目录并移动文件：</p><ul><li><p>创建 <code>~/bin</code> 目录（如果不存在）：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">mkdir -p ~/bin</span><br></pre></td></tr></table></figure></li><li><p>将 <code>ninja</code> 二进制文件移动到 <code>~/bin</code>：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">mv ninja ~/bin/</span><br></pre></td></tr></table></figure></li></ul></li><li><p>更新 PATH 环境变量：</p><ul><li><p>临时添加至当前会话：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">export PATH=~/bin:$PATH</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>验证安装</strong>：</p><ul><li>运行 <code>ninja --version</code> 检查是否成功。</li></ul></li></ol><p><strong><code>crypt.h</code>报错</strong></p><p>解决：</p><ul><li><p>步骤 1：确认 glibc-2.27 源码</p><ul><li><p>确保你已从 <a href="https://ftp.gnu.org/gnu/glibc/glibc-2.27.tar.xz">GNU FTP 服务器</a> 下载并解压了 glibc-2.27.tar.xz 文件。如果未下载，使用以下命令：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ruby</span><br><span class="line">wget &lt;https://ftp.gnu.org/gnu/glibc/glibc-2.27.tar.xz&gt;</span><br><span class="line">tar -xJf glibc-2.27.tar.xz</span><br></pre></td></tr></table></figure></li><li><p>确认解压后生成了 <code>glibc-2.27</code> 目录，并包含 <code>include</code> 子目录。</p></li></ul><p>步骤 2：复制所有头文件</p><ul><li><p>将 glibc-2.27&#x2F;include 目录下的所有头文件复制到你的本地 ~&#x2F;include 目录，以确保所有依赖头文件（如 <code>features.h</code>、<code>stdint.h</code> 等）都可用：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">mkdir -p ~/include</span><br><span class="line">cp -r glibc-2.27/include/* ~/include/</span><br></pre></td></tr></table></figure></li><li><p>这将复制包括 <code>crypt.h</code> 在内的所有头文件到 ~&#x2F;include，确保编译器能找到所有必需的依赖。</p></li></ul><p>步骤 3：设置包含路径</p><ul><li><p>设置 <code>CPLUS_INCLUDE_PATH</code> 环境变量，确保编译器优先搜索 ~&#x2F;include 目录：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">export CPLUS_INCLUDE_PATH=~/include:$CPLUS_INCLUDE_PATH</span><br></pre></td></tr></table></figure></li><li><p>验证环境变量设置：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">echo $CPLUS_INCLUDE_PATH</span><br></pre></td></tr></table></figure><p>应包含 <code>~/include</code>。</p></li></ul><p>步骤 4：检查系统头文件</p><p>首先，检查你的环境中是否已有必要的头文件：</p><ul><li><p>运行 </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ls /usr/include/crypt.h</span><br></pre></td></tr></table></figure><p> 查看是否已有 </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">crypt.h</span><br></pre></td></tr></table></figure><p>。如果存在，尝试使用系统编译器：</p><ul><li>运行 <code>export CC=/usr/bin/gcc</code> 和 <code>export CXX=/usr/bin/g++</code>。</li><li>然后取消设置 <code>CPLUS_INCLUDE_PATH</code>：<code>unset CPLUS_INCLUDE_PATH</code>。</li><li>重新运行训练脚本：<code>./tools/dist_train.sh $&#123;CONFIG&#125; $&#123;GPU_NUM&#125;</code>。</li></ul></li></ul></li></ul><p><strong>GLIBCXX_3.4.29报错</strong></p><p>参考：</p><p>[如何解决version &#96;GLIBCXX_3.4.29‘ not found的问题_glibcxx not found-CSDN博客](<a href="https://blog.csdn.net/weixin_39379635/article/details/129159713">https://blog.csdn.net/weixin_39379635/article/details/129159713</a>)</p><p><strong>解决：</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ImportError: /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6: version `GLIBCXX_3.4.29&#x27; not found</span><br></pre></td></tr></table></figure><p>1、使用指令先看下系统目前都有哪些版本的</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strings /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6 | grep GLIBCXX</span><br></pre></td></tr></table></figure><p>发现只到3.4.22</p><p>2、来查看当前系统中其它的同类型文件，</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo find / -name &quot;libstdc++.so.6*&quot;</span><br></pre></td></tr></table></figure><p>找到一个版本比较高的 &#x2F;home&#x2F;ma-user&#x2F;anaconda3&#x2F;envs&#x2F;vidar&#x2F;lib&#x2F;libstdc++.so.6.0.29</p><p>查看</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strings /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6.0.29 | grep GLIBCXX</span><br></pre></td></tr></table></figure><p>有了3.4.29</p><p>3、复制到指定目录并建立新的链接</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">复制</span><br><span class="line">sudo cp /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6.0.29 /home/ma-user/anaconda3/envs/vidar/lib/</span><br><span class="line"></span><br><span class="line">删除之前链接</span><br><span class="line">sudo rm /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6</span><br><span class="line"></span><br><span class="line">创建新的链接</span><br><span class="line">sudo ln -s /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6.0.29 /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6</span><br></pre></td></tr></table></figure><p>验证</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strings /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6 | grep GLIBCXX</span><br></pre></td></tr></table></figure><p>有了3.4.29</p><p><strong>另：如果是&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libstdc++.so.6报错，使用：</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure><p><strong>GPU爆内存</strong></p><p>cuda out of memory</p><p>只训练mini数据集的一部分，注意留的数据meta_datas里的文件夹名字和sensor_blobs里文件夹名对应</p><p><strong>fsspec 与 Python 3.8 兼容性问题</strong></p><p>TypeError: ‘type’ object is not subscriptable</p><p>解决方法：降低到fsspec可以兼容3.8的版本</p><p>pip install fsspec&#x3D;&#x3D;2025.3.0</p></li></ol><h2 id="ViDAR模型实现分析"><a href="#ViDAR模型实现分析" class="headerlink" title="ViDAR模型实现分析"></a>ViDAR模型实现分析</h2><h3 id="模型架构概述"><a href="#模型架构概述" class="headerlink" title="模型架构概述"></a>模型架构概述</h3><p>ViDAR（Visual Point Cloud Forecasting enables Scalable Autonomous Driving）是一个基于BEVFormer架构的模型，专注于自动驾驶场景中的视觉点云预测。从 <code>vidar_transformer.py</code> 文件可以看出，它主要实现了一个预测变换器（PredictionTransformer）。</p><h3 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h3><ol><li>PredictionTransformer ：<ul><li>这是ViDAR的核心组件，用于从多帧BEV特征预测下一帧的BEV特征</li><li>使用了自定义的解码器来处理时序信息</li></ul></li><li>注意力机制 ：<ul><li>时间自注意力（TemporalSelfAttention）：处理时间维度上的信息</li><li>空间交叉注意力（MSDeformableAttention3D）：处理3D空间中的信息</li><li>自定义可变形注意力（CustomMSDeformableAttention）：用于处理特征对齐</li></ul></li></ol><h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><p>项目结构显示ViDAR是基于BEVFormer进行扩展的：</p><p>projects&#x2F;<br>├── configs&#x2F;<br>│   ├── <em>base</em>&#x2F;<br>│   ├── bevformer&#x2F;<br>│   ├── vidar_finetune&#x2F;    # ViDAR微调配置<br>│   └── vidar_pretrain&#x2F;    # ViDAR预训练配置<br>└── mmdet3d_plugin&#x2F;<br>    ├── bevformer&#x2F;         # BEVFormer相关模块<br>    ├── core&#x2F;              # 核心评估和功能模块<br>    ├── datasets&#x2F;          # 数据集处理<br>    ├── dd3d&#x2F;              # 3D检测相关模块<br>    └── models&#x2F;            # 模型定义</p><h3 id="与BEVFormer的关系"><a href="#与BEVFormer的关系" class="headerlink" title="与BEVFormer的关系"></a>与BEVFormer的关系</h3><p>ViDAR似乎是在BEVFormer基础上的扩展，专注于未来帧预测：</p><ul><li>BEVFormer主要关注多视角图像到BEV表示的转换</li><li>ViDAR则进一步关注BEV表示的时序预测，实现对未来场景的预测</li></ul><h2 id="调优思路"><a href="#调优思路" class="headerlink" title="调优思路"></a>调优思路</h2><h3 id="融合Nskg"><a href="#融合Nskg" class="headerlink" title="融合Nskg"></a>融合Nskg</h3><p>写在前面：</p><p>这个项目其实没有想象的复杂，大概如下：</p><p>ViDAR模型似乎是一个基于BEVFormer架构的3D检测&#x2F;分割模型，它利用MMDetection3D框架实现，支持多视角图像到BEV表示的转换。该模型具有灵活的配置系统、插件扩展能力和完善的训练功能。</p><p>那么有了以上信息就好做了，首先学习下MMDetection3D的使用方法，Vidar只不过在上面多封装了一层，那么这一层应该也可以写插件进行拓展</p><p>核心目录：</p><ol><li>模型定义文件（可能在 projects&#x2F;mmdet3d_plugin&#x2F;bevformer&#x2F; 目录下）</li><li>配置文件（通过命令行参数 config 指定）</li><li>自定义训练函数 custom_train_model 的实现</li></ol><ul><li><p>论文1：nuScenes Knowledge Graph (nSKG)</p><p><strong>nuScenes Knowledge Graph (nSKG)</strong> 文章的内容可以很好地融入对 <strong>ViDAR: Visual Point Cloud Forecasting</strong> 模型的理解和调优中，尤其是在以下几个方面：</p><ol><li><strong>丰富场景表示</strong>：nSKG 提供了 nuScenes 数据集的综合语义表示，包含交通场景中的实体（如车辆、行人、车道、交通信号灯）和它们之间的语义与空间关系。这可以增强 ViDAR 的输入数据，改善其点云预测和下游任务（如感知、规划）的性能。</li><li><strong>数据处理改进</strong>：nSKG 的结构化数据（以知识图谱和 PyTorch Geometric 格式提供）可以直接用于 ViDAR 的数据管道，减少数据预处理的工程负担。</li><li><strong>模型架构增强</strong>：nSKG 的异构图表示可以与 ViDAR 的 Transformer 或 BEVFormer 模块结合，引入图神经网络（GNN）来处理语义关系，提升预测的鲁棒性和可解释性。</li><li><strong>调优方向</strong>：利用 nSKG 的丰富上下文（如车道拓扑、代理关系），可以优化 ViDAR 的超参数、数据增强策略和损失函数，特别是在处理复杂交通场景时。</li></ol></li></ul><p>实际修改：</p><p><img src="/article/8257d2b5/e879ac0c92d040202e3ba7450e5459b.png" alt="e879ac0c92d040202e3ba7450e5459b"></p><h1 id="ViDAR项目集成nSTP的工作总结"><a href="#ViDAR项目集成nSTP的工作总结" class="headerlink" title="ViDAR项目集成nSTP的工作总结"></a>ViDAR项目集成nSTP的工作总结</h1><p>根据当前代码库，我将总结从初始状态到现在为止，为了集成nSTP（Neural Scene-Time Priors）所做的工作。</p><h2 id="1-核心文件创建"><a href="#1-核心文件创建" class="headerlink" title="1. 核心文件创建"></a>1. 核心文件创建</h2><h3 id="1-1-nSTP编码器模块"><a href="#1-1-nSTP编码器模块" class="headerlink" title="1.1 nSTP编码器模块"></a>1.1 nSTP编码器模块</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\bevformer\modules\nstp_encoder.py</code></p><p><strong>主要功能</strong>:</p><ul><li>创建了<code>NSTPEncoder</code>类：使用图神经网络（GraphSAGE或GAT）处理nSTP图数据</li><li>创建了<code>NSTPEnhancer</code>类：将nSTP特征与BEV特征融合，通过注意力机制增强BEV特征</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GraphSAGE, GATConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NSTPEncoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;nSTP图数据编码器&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, hidden_channels, out_channels, num_layers=<span class="number">3</span>, </span></span><br><span class="line"><span class="params">                 gnn_type=<span class="string">&#x27;graphsage&#x27;</span>, dropout=<span class="number">0.1</span>, aggr=<span class="string">&#x27;mean&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.in_channels = in_channels</span><br><span class="line">        <span class="variable language_">self</span>.hidden_channels = hidden_channels</span><br><span class="line">        <span class="variable language_">self</span>.out_channels = out_channels</span><br><span class="line">        <span class="variable language_">self</span>.num_layers = num_layers</span><br><span class="line">        <span class="variable language_">self</span>.gnn_type = gnn_type</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输入特征投影</span></span><br><span class="line">        <span class="variable language_">self</span>.input_proj = nn.Linear(in_channels, hidden_channels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 图神经网络</span></span><br><span class="line">        <span class="keyword">if</span> gnn_type == <span class="string">&#x27;graphsage&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.gnn = GraphSAGE(</span><br><span class="line">                in_channels=hidden_channels,</span><br><span class="line">                hidden_channels=hidden_channels,</span><br><span class="line">                num_layers=num_layers,</span><br><span class="line">                out_channels=out_channels,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                aggr=aggr</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">elif</span> gnn_type == <span class="string">&#x27;gat&#x27;</span>:</span><br><span class="line">            <span class="comment"># 简化版GAT实现</span></span><br><span class="line">            <span class="variable language_">self</span>.gnn_layers = nn.ModuleList()</span><br><span class="line">            <span class="variable language_">self</span>.gnn_layers.append(GATConv(hidden_channels, hidden_channels))</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_layers - <span class="number">2</span>):</span><br><span class="line">                <span class="variable language_">self</span>.gnn_layers.append(GATConv(hidden_channels, hidden_channels))</span><br><span class="line">            <span class="variable language_">self</span>.gnn_layers.append(GATConv(hidden_channels, out_channels))</span><br><span class="line">            <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;不支持的GNN类型: <span class="subst">&#123;gnn_type&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            data: PyG Data对象或包含x和edge_index的字典</span></span><br><span class="line"><span class="string">                </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            torch.Tensor: 节点特征</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 添加对None的处理</span></span><br><span class="line">        <span class="keyword">if</span> data <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 返回一个空的特征张量</span></span><br><span class="line">            <span class="keyword">return</span> torch.zeros((<span class="number">1</span>, <span class="variable language_">self</span>.out_channels), device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(data, <span class="string">&#x27;x&#x27;</span>) <span class="keyword">and</span> <span class="built_in">hasattr</span>(data, <span class="string">&#x27;edge_index&#x27;</span>):</span><br><span class="line">            x, edge_index = data.x, data.edge_index</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&#x27;x&#x27;</span> <span class="keyword">in</span> data <span class="keyword">and</span> <span class="string">&#x27;edge_index&#x27;</span> <span class="keyword">in</span> data:</span><br><span class="line">            x, edge_index = data[<span class="string">&#x27;x&#x27;</span>], data[<span class="string">&#x27;edge_index&#x27;</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;警告: 输入数据格式不正确: <span class="subst">&#123;<span class="built_in">type</span>(data)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="comment"># 返回一个空的特征张量</span></span><br><span class="line">            <span class="keyword">return</span> torch.zeros((<span class="number">1</span>, <span class="variable language_">self</span>.out_channels), device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 确保x和edge_index是张量</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, torch.Tensor):</span><br><span class="line">            x = torch.tensor(x, dtype=torch.<span class="built_in">float</span>, device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(edge_index, torch.Tensor):</span><br><span class="line">            edge_index = torch.tensor(edge_index, dtype=torch.long, device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># 特征投影</span></span><br><span class="line">        x = <span class="variable language_">self</span>.input_proj(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 图神经网络处理</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.gnn_type == <span class="string">&#x27;graphsage&#x27;</span>:</span><br><span class="line">            x = <span class="variable language_">self</span>.gnn(x, edge_index)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># gat</span></span><br><span class="line">            <span class="keyword">for</span> i, layer <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.gnn_layers):</span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(<span class="variable language_">self</span>.gnn_layers) - <span class="number">1</span>:</span><br><span class="line">                    x = layer(x, edge_index)</span><br><span class="line">                    x = torch.relu(x)</span><br><span class="line">                    x = <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    x = layer(x, edge_index)</span><br><span class="line">                    </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NSTPEnhancer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;nSTP特征增强器，用于增强BEV特征&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, bev_channels, nstp_channels, hidden_channels, bev_h, bev_w, use_attention=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.bev_channels = bev_channels</span><br><span class="line">        <span class="variable language_">self</span>.nstp_channels = nstp_channels</span><br><span class="line">        <span class="variable language_">self</span>.hidden_channels = hidden_channels</span><br><span class="line">        <span class="variable language_">self</span>.bev_h = bev_h</span><br><span class="line">        <span class="variable language_">self</span>.bev_w = bev_w</span><br><span class="line">        <span class="variable language_">self</span>.use_attention = use_attention</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征融合层</span></span><br><span class="line">        <span class="variable language_">self</span>.nstp_proj = nn.Linear(nstp_channels, hidden_channels)</span><br><span class="line">        <span class="variable language_">self</span>.bev_proj = nn.Linear(bev_channels, hidden_channels)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> use_attention:</span><br><span class="line">            <span class="comment"># 注意力机制</span></span><br><span class="line">            <span class="variable language_">self</span>.query_proj = nn.Linear(hidden_channels, hidden_channels)</span><br><span class="line">            <span class="variable language_">self</span>.key_proj = nn.Linear(hidden_channels, hidden_channels)</span><br><span class="line">            <span class="variable language_">self</span>.value_proj = nn.Linear(hidden_channels, hidden_channels)</span><br><span class="line">            <span class="variable language_">self</span>.attention_scale = hidden_channels ** -<span class="number">0.5</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 输出投影</span></span><br><span class="line">        <span class="variable language_">self</span>.output_proj = nn.Linear(hidden_channels, bev_channels)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, bev_feat, nstp_feat, nstp_pos=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            bev_feat (torch.Tensor): BEV特征 [B, C, H, W]</span></span><br><span class="line"><span class="string">            nstp_feat (torch.Tensor): nSTP节点特征 [B, N, C]</span></span><br><span class="line"><span class="string">            nstp_pos (torch.Tensor, optional): nSTP节点位置 [B, N, 2]</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            torch.Tensor: 增强后的BEV特征 [B, C, H, W]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, C, H, W = bev_feat.shape</span><br><span class="line">        bev_feat_flat = bev_feat.flatten(<span class="number">2</span>).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># [B, H*W, C]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征投影</span></span><br><span class="line">        bev_feat_proj = <span class="variable language_">self</span>.bev_proj(bev_feat_flat)  <span class="comment"># [B, H*W, hidden]</span></span><br><span class="line">        nstp_feat_proj = <span class="variable language_">self</span>.nstp_proj(nstp_feat)  <span class="comment"># [B, N, hidden]</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_attention:</span><br><span class="line">            <span class="comment"># 计算注意力</span></span><br><span class="line">            query = <span class="variable language_">self</span>.query_proj(bev_feat_proj)  <span class="comment"># [B, H*W, hidden]</span></span><br><span class="line">            key = <span class="variable language_">self</span>.key_proj(nstp_feat_proj)  <span class="comment"># [B, N, hidden]</span></span><br><span class="line">            value = <span class="variable language_">self</span>.value_proj(nstp_feat_proj)  <span class="comment"># [B, N, hidden]</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 注意力分数</span></span><br><span class="line">            attn = torch.bmm(query, key.transpose(<span class="number">1</span>, <span class="number">2</span>)) * <span class="variable language_">self</span>.attention_scale  <span class="comment"># [B, H*W, N]</span></span><br><span class="line">            attn = torch.softmax(attn, dim=-<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 加权特征</span></span><br><span class="line">            context = torch.bmm(attn, value)  <span class="comment"># [B, H*W, hidden]</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 融合特征</span></span><br><span class="line">            enhanced_feat = context + bev_feat_proj</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 简单平均</span></span><br><span class="line">            nstp_feat_expanded = nstp_feat_proj.mean(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>).expand(-<span class="number">1</span>, H*W, -<span class="number">1</span>)</span><br><span class="line">            enhanced_feat = bev_feat_proj + nstp_feat_expanded</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 输出投影</span></span><br><span class="line">        enhanced_feat = <span class="variable language_">self</span>.output_proj(enhanced_feat)  <span class="comment"># [B, H*W, C]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 重塑为BEV特征</span></span><br><span class="line">        enhanced_feat = enhanced_feat.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>).reshape(B, C, H, W)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> enhanced_feat</span><br></pre></td></tr></table></figure><h3 id="1-2-nSTP数据处理组件"><a href="#1-2-nSTP数据处理组件" class="headerlink" title="1.2 nSTP数据处理组件"></a>1.2 nSTP数据处理组件</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\datasets\pipelines\nstp_transform.py</code></p><p><strong>主要功能</strong>:</p><ul><li>创建了<code>ProcessNSTPGraph</code>类：处理nSTP图数据，确保格式正确并转换为PyTorch张量</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mmdet.datasets.builder <span class="keyword">import</span> PIPELINES</span><br><span class="line"></span><br><span class="line"><span class="meta">@PIPELINES.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProcessNSTPGraph</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;处理nSTP图数据的转换组件&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, graph_feat_dim=<span class="number">64</span>, with_agent_type=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.graph_feat_dim = graph_feat_dim</span><br><span class="line">        <span class="variable language_">self</span>.with_agent_type = with_agent_type</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, results</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;处理nSTP图数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;nstp_graph&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> results:</span><br><span class="line">            <span class="keyword">return</span> results</span><br><span class="line">            </span><br><span class="line">        graph_data = results[<span class="string">&#x27;nstp_graph&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 处理PyG Data对象</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(graph_data, <span class="string">&#x27;x&#x27;</span>) <span class="keyword">and</span> <span class="built_in">hasattr</span>(graph_data, <span class="string">&#x27;edge_index&#x27;</span>):</span><br><span class="line">            <span class="comment"># 已经是PyG Data对象，确保张量类型正确</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(graph_data.x, torch.Tensor):</span><br><span class="line">                graph_data.x = torch.tensor(graph_data.x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(graph_data.edge_index, torch.Tensor):</span><br><span class="line">                graph_data.edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hasattr</span>(graph_data, <span class="string">&#x27;edge_attr&#x27;</span>) <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(graph_data.edge_attr, torch.Tensor):</span><br><span class="line">                graph_data.edge_attr = torch.tensor(graph_data.edge_attr, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># 处理字典格式的图数据</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(graph_data, <span class="built_in">dict</span>):</span><br><span class="line">            <span class="comment"># 处理节点特征</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;x&#x27;</span> <span class="keyword">in</span> graph_data:</span><br><span class="line">                x = graph_data[<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, np.ndarray):</span><br><span class="line">                    x = torch.from_numpy(x).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(x, <span class="built_in">list</span>):</span><br><span class="line">                    x = torch.tensor(x).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, torch.Tensor):</span><br><span class="line">                    x = torch.tensor(x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">                graph_data[<span class="string">&#x27;x&#x27;</span>] = x</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 处理边索引</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;edge_index&#x27;</span> <span class="keyword">in</span> graph_data:</span><br><span class="line">                edge_index = graph_data[<span class="string">&#x27;edge_index&#x27;</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(edge_index, np.ndarray):</span><br><span class="line">                    edge_index = torch.from_numpy(edge_index).long()</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(edge_index, <span class="built_in">list</span>):</span><br><span class="line">                    edge_index = torch.tensor(edge_index).long()</span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(edge_index, torch.Tensor):</span><br><span class="line">                    edge_index = torch.tensor(edge_index, dtype=torch.long)</span><br><span class="line">                graph_data[<span class="string">&#x27;edge_index&#x27;</span>] = edge_index</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 处理边属性</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;edge_attr&#x27;</span> <span class="keyword">in</span> graph_data:</span><br><span class="line">                edge_attr = graph_data[<span class="string">&#x27;edge_attr&#x27;</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(edge_attr, np.ndarray):</span><br><span class="line">                    edge_attr = torch.from_numpy(edge_attr).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(edge_attr, <span class="built_in">list</span>):</span><br><span class="line">                    edge_attr = torch.tensor(edge_attr).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(edge_attr, torch.Tensor):</span><br><span class="line">                    edge_attr = torch.tensor(edge_attr, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">                graph_data[<span class="string">&#x27;edge_attr&#x27;</span>] = edge_attr</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新结果</span></span><br><span class="line">        results[<span class="string">&#x27;nstp_graph&#x27;</span>] = graph_data</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><h2 id="2-现有文件修改"><a href="#2-现有文件修改" class="headerlink" title="2. 现有文件修改"></a>2. 现有文件修改</h2><h3 id="2-1-数据集类修改"><a href="#2-1-数据集类修改" class="headerlink" title="2.1 数据集类修改"></a>2.1 数据集类修改</h3><h4 id="2-1-1-NuScenes数据集"><a href="#2-1-1-NuScenes数据集" class="headerlink" title="2.1.1 NuScenes数据集"></a>2.1.1 NuScenes数据集</h4><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\datasets\nuscenes_vidar_dataset_v1.py</code></p><p><strong>主要修改</strong>:</p><ul><li>添加了nSTP相关参数：<code>use_nstp</code>, <code>nstp_path</code></li><li>实现了<code>_load_nstp_data</code>方法：加载nSTP图数据文件</li><li>修改了<code>get_data_info</code>方法：将nSTP数据添加到样本信息中</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"><span class="comment"># Visual Point Cloud Forecasting enables Scalable Autonomous Driving              #</span></span><br><span class="line"><span class="comment"># Copyright (c) OpenDriveLab. All rights reserved.                                #</span></span><br><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入rdflib</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> rdflib <span class="keyword">import</span> Graph</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;警告: 未安装rdflib库，无法加载.ttl格式的nSKG数据&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mmdet.datasets <span class="keyword">import</span> DATASETS</span><br><span class="line"><span class="keyword">from</span> nuscenes.<span class="built_in">eval</span>.common.utils <span class="keyword">import</span> quaternion_yaw, Quaternion</span><br><span class="line"><span class="keyword">from</span> nuscenes.utils.geometry_utils <span class="keyword">import</span> transform_matrix</span><br><span class="line"><span class="keyword">from</span> mmcv.parallel <span class="keyword">import</span> DataContainer <span class="keyword">as</span> DC</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> .nuscenes_vidar_dataset_template <span class="keyword">import</span> NuScenesViDARDatasetTemplate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@DATASETS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NuScenesViDARDatasetV1</span>(<span class="title class_ inherited__">NuScenesViDARDatasetTemplate</span>):  <span class="comment"># 确保类名为NuScenesViDARDatasetV1</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;NuScenes visual point cloud forecasting dataset.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 ann_file,</span></span><br><span class="line"><span class="params">                 pipeline=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 data_root=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 classes=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 load_interval=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 modality=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 box_type_3d=<span class="string">&#x27;LiDAR&#x27;</span>,</span></span><br><span class="line"><span class="params">                 filter_empty_gt=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 test_mode=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 use_valid_flag=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 history_queue_length=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 pred_history_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 pred_future_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 per_frame_loss_weight=(<span class="params"><span class="number">1.0</span>,</span>),</span></span><br><span class="line"><span class="params">                 use_nskg=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 nskg_path=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 nskg_ontology_path=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 use_nstp=<span class="literal">False</span>,  <span class="comment"># 添加nSTP支持参数</span></span></span><br><span class="line"><span class="params">                 nstp_path=<span class="literal">None</span>,  <span class="comment"># 添加nSTP数据路径参数</span></span></span><br><span class="line"><span class="params">                 **kwargs</span>):</span><br><span class="line">        <span class="comment"># 保存history_queue_length参数，但不传递给父类</span></span><br><span class="line">        <span class="variable language_">self</span>.history_queue_length = history_queue_length</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 调用父类初始化方法，移除history_queue_length参数</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            ann_file=ann_file,</span><br><span class="line">            pipeline=pipeline,</span><br><span class="line">            data_root=data_root,</span><br><span class="line">            classes=classes,</span><br><span class="line">            load_interval=load_interval,</span><br><span class="line">            modality=modality,</span><br><span class="line">            box_type_3d=box_type_3d,</span><br><span class="line">            filter_empty_gt=filter_empty_gt,</span><br><span class="line">            test_mode=test_mode,</span><br><span class="line">            use_valid_flag=use_valid_flag,</span><br><span class="line">            **kwargs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存nSKG相关参数</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nskg = use_nskg</span><br><span class="line">        <span class="variable language_">self</span>.nskg_path = nskg_path</span><br><span class="line">        <span class="variable language_">self</span>.nskg_ontology_path = nskg_ontology_path</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存nSTP相关参数</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nstp = use_nstp</span><br><span class="line">        <span class="variable language_">self</span>.nstp_path = nstp_path</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存预测帧数相关参数</span></span><br><span class="line">        <span class="variable language_">self</span>.pred_history_frame_num = pred_history_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.pred_future_frame_num = pred_future_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.per_frame_loss_weight = per_frame_loss_weight</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSKG，加载相关数据</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="variable language_">self</span>._load_nskg_data()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_load_nskg_data</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载nSKG数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.nskg_data = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="variable language_">self</span>.nskg_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;警告: nSKG数据路径 <span class="subst">&#123;self.nskg_path&#125;</span> 不存在&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nskg = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.nskg_path.endswith(<span class="string">&#x27;.ttl&#x27;</span>) <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_ontology_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                g = Graph()</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    g.parse(<span class="variable language_">self</span>.nskg_path, <span class="built_in">format</span>=<span class="string">&#x27;turtle&#x27;</span>)</span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;警告: TTL文件解析失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="variable language_">self</span>.use_nskg = <span class="literal">False</span></span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 加载本体文件</span></span><br><span class="line">                <span class="keyword">if</span> os.path.exists(<span class="variable language_">self</span>.nskg_ontology_path):</span><br><span class="line">                    <span class="keyword">for</span> onto_file <span class="keyword">in</span> os.listdir(<span class="variable language_">self</span>.nskg_ontology_path):</span><br><span class="line">                        <span class="keyword">if</span> onto_file.endswith(<span class="string">&#x27;.ttl&#x27;</span>):</span><br><span class="line">                            onto_path = os.path.join(<span class="variable language_">self</span>.nskg_ontology_path, onto_file)</span><br><span class="line">                            <span class="keyword">try</span>:</span><br><span class="line">                                g.parse(onto_path, <span class="built_in">format</span>=<span class="string">&#x27;turtle&#x27;</span>)</span><br><span class="line">                            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                                <span class="built_in">print</span>(<span class="string">f&quot;警告: 本体文件 <span class="subst">&#123;onto_file&#125;</span> 解析失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;成功加载nSKG数据，共 <span class="subst">&#123;<span class="built_in">len</span>(g)&#125;</span> 个三元组&quot;</span>)</span><br><span class="line">                <span class="variable language_">self</span>.nskg_data = <span class="variable language_">self</span>._convert_rdf_to_pyg(g)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">import</span> pickle</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(<span class="variable language_">self</span>.nskg_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    <span class="variable language_">self</span>.nskg_data = pickle.load(f)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;成功加载nSKG数据，共 <span class="subst">&#123;<span class="built_in">len</span>(self.nskg_data)&#125;</span> 条记录&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;加载nSKG数据失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;继续训练，但不使用nSKG数据&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nskg = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_convert_rdf_to_pyg</span>(<span class="params">self, graph</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;将RDF图转换为PyG格式</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            graph: RDF图对象</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            转换后的数据字典，键为sample_token</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result = &#123;&#125;</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">import</span> torch_geometric <span class="keyword">as</span> pyg</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 查询所有场景</span></span><br><span class="line">            scenes = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> s, p, o <span class="keyword">in</span> graph.triples((<span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>)):</span><br><span class="line">                <span class="comment"># 假设每个场景都有一个token属性</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">str</span>(p).endswith(<span class="string">&#x27;hasToken&#x27;</span>):</span><br><span class="line">                    scene_uri = <span class="built_in">str</span>(s)</span><br><span class="line">                    token = <span class="built_in">str</span>(o)</span><br><span class="line">                    scenes[scene_uri] = token</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 为每个场景构建图</span></span><br><span class="line">            <span class="keyword">for</span> scene_uri, token <span class="keyword">in</span> scenes.items():</span><br><span class="line">                <span class="comment"># 收集节点</span></span><br><span class="line">                nodes = &#123;&#125;</span><br><span class="line">                node_types = &#123;&#125;</span><br><span class="line">                node_features = &#123;&#125;</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 收集边</span></span><br><span class="line">                edges = &#123;&#125;</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 查询与场景相关的所有三元组</span></span><br><span class="line">                <span class="keyword">for</span> s, p, o <span class="keyword">in</span> graph.triples((<span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>)):</span><br><span class="line">                    <span class="comment"># 处理节点和边的逻辑...</span></span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 构建PyG数据对象</span></span><br><span class="line">                data = &#123;</span><br><span class="line">                    <span class="string">&#x27;x&#x27;</span>: node_features,</span><br><span class="line">                    <span class="string">&#x27;edge_index&#x27;</span>: edges,</span><br><span class="line">                    <span class="string">&#x27;node_type&#x27;</span>: node_types</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                result[token] = data</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">except</span> ImportError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;警告: 未安装PyTorch Geometric库，无法转换RDF数据为图格式&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_data_info</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;获取数据信息，添加nSKG或nSTP数据&quot;&quot;&quot;</span></span><br><span class="line">        info = <span class="built_in">super</span>().get_data_info(index)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取当前样本的标识符</span></span><br><span class="line">        sample_token = info.get(<span class="string">&#x27;sample_token&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSKG，添加nSKG数据到info中</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg <span class="keyword">and</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>, <span class="string">&#x27;nskg_data&#x27;</span>) <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_data <span class="keyword">and</span> sample_token <span class="keyword">in</span> <span class="variable language_">self</span>.nskg_data:</span><br><span class="line">            info[<span class="string">&#x27;nskg_graph&#x27;</span>] = <span class="variable language_">self</span>.nskg_data[sample_token]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSTP，添加nSTP数据到info中（优先使用nSTP）</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nstp <span class="keyword">and</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>, <span class="string">&#x27;nstp_data&#x27;</span>) <span class="keyword">and</span> <span class="variable language_">self</span>.nstp_data <span class="keyword">and</span> sample_token <span class="keyword">in</span> <span class="variable language_">self</span>.nstp_data:</span><br><span class="line">            info[<span class="string">&#x27;nstp_graph&#x27;</span>] = <span class="variable language_">self</span>.nstp_data[sample_token]</span><br><span class="line">            <span class="comment"># 如果同时存在nSKG和nSTP，使用nSTP替代nSKG</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;nskg_graph&#x27;</span> <span class="keyword">in</span> info:</span><br><span class="line">                <span class="keyword">del</span> info[<span class="string">&#x27;nskg_graph&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> info</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_mask_points</span>(<span class="params">self, pts_list</span>):</span><br><span class="line">        <span class="keyword">assert</span> <span class="variable language_">self</span>.ego_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">        <span class="comment"># remove points belonging to ego vehicle.</span></span><br><span class="line">        masked_pts_list = []</span><br><span class="line">        <span class="keyword">for</span> pts <span class="keyword">in</span> pts_list:</span><br><span class="line">            ego_mask = np.logical_and(</span><br><span class="line">                np.logical_and(<span class="variable language_">self</span>.ego_mask[<span class="number">0</span>] &lt;= pts[:, <span class="number">0</span>],</span><br><span class="line">                               <span class="variable language_">self</span>.ego_mask[<span class="number">2</span>] &gt;= pts[:, <span class="number">0</span>]),</span><br><span class="line">                np.logical_and(<span class="variable language_">self</span>.ego_mask[<span class="number">1</span>] &lt;= pts[:, <span class="number">1</span>],</span><br><span class="line">                               <span class="variable language_">self</span>.ego_mask[<span class="number">3</span>] &gt;= pts[:, <span class="number">1</span>]),</span><br><span class="line">            )</span><br><span class="line">            pts = pts[np.logical_not(ego_mask)]</span><br><span class="line">            masked_pts_list.append(pts)</span><br><span class="line">        pts_list = masked_pts_list</span><br><span class="line">        <span class="keyword">return</span> pts_list</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">union2one</span>(<span class="params">self, previous_queue, future_queue</span>):</span><br><span class="line">        <span class="comment"># 1. get transformation from all frames to current (reference) frame</span></span><br><span class="line">        ref_meta = previous_queue[-<span class="number">1</span>][<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line">        valid_scene_token = ref_meta[<span class="string">&#x27;scene_token&#x27;</span>]</span><br><span class="line">        <span class="comment"># compute reference e2g_transform and g2e_transform.</span></span><br><span class="line">        ref_e2g_translation = ref_meta[<span class="string">&#x27;ego2global_translation&#x27;</span>]</span><br><span class="line">        ref_e2g_rotation = ref_meta[<span class="string">&#x27;ego2global_rotation&#x27;</span>]</span><br><span class="line">        ref_e2g_transform = transform_matrix(</span><br><span class="line">            ref_e2g_translation, Quaternion(ref_e2g_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">        ref_g2e_transform = transform_matrix(</span><br><span class="line">            ref_e2g_translation, Quaternion(ref_e2g_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line">        ref_l2e_translation = ref_meta[<span class="string">&#x27;lidar2ego_translation&#x27;</span>]</span><br><span class="line">        ref_l2e_rotation = ref_meta[<span class="string">&#x27;lidar2ego_rotation&#x27;</span>]</span><br><span class="line">        ref_l2e_transform = transform_matrix(</span><br><span class="line">            ref_l2e_translation, Quaternion(ref_l2e_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">        ref_e2l_transform = transform_matrix(</span><br><span class="line">            ref_l2e_translation, Quaternion(ref_l2e_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        queue = previous_queue[:-<span class="number">1</span>] + future_queue</span><br><span class="line">        pts_list = [each[<span class="string">&#x27;points&#x27;</span>].data <span class="keyword">for</span> each <span class="keyword">in</span> queue]</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.ego_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            pts_list = <span class="variable language_">self</span>._mask_points(pts_list)</span><br><span class="line">        total_cur2ref_lidar_transform = []</span><br><span class="line">        total_ref2cur_lidar_transform = []</span><br><span class="line">        total_pts_list = []</span><br><span class="line">        <span class="keyword">for</span> i, each <span class="keyword">in</span> <span class="built_in">enumerate</span>(queue):</span><br><span class="line">            meta = each[<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line"></span><br><span class="line">            <span class="comment"># store points in the current frame.</span></span><br><span class="line">            cur_pts = pts_list[i].cpu().numpy().copy()</span><br><span class="line">            cur_pts[:, -<span class="number">1</span>] = i</span><br><span class="line">            total_pts_list.append(cur_pts)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># store the transformation from current frame to reference frame.</span></span><br><span class="line">            curr_e2g_translation = meta[<span class="string">&#x27;ego2global_translation&#x27;</span>]</span><br><span class="line">            curr_e2g_rotation = meta[<span class="string">&#x27;ego2global_rotation&#x27;</span>]</span><br><span class="line">            curr_e2g_transform = transform_matrix(</span><br><span class="line">                curr_e2g_translation, Quaternion(curr_e2g_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">            curr_g2e_transform = transform_matrix(</span><br><span class="line">                curr_e2g_translation, Quaternion(curr_e2g_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            curr_l2e_translation = meta[<span class="string">&#x27;lidar2ego_translation&#x27;</span>]</span><br><span class="line">            curr_l2e_rotation = meta[<span class="string">&#x27;lidar2ego_rotation&#x27;</span>]</span><br><span class="line">            curr_l2e_transform = transform_matrix(</span><br><span class="line">                curr_l2e_translation, Quaternion(curr_l2e_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">            curr_e2l_transform = transform_matrix(</span><br><span class="line">                curr_l2e_translation, Quaternion(curr_l2e_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute future to reference matrix.</span></span><br><span class="line">            cur_lidar_to_ref_lidar = (curr_l2e_transform.T @</span><br><span class="line">                                      curr_e2g_transform.T @</span><br><span class="line">                                      ref_g2e_transform.T @</span><br><span class="line">                                      ref_e2l_transform.T)</span><br><span class="line">            total_cur2ref_lidar_transform.append(cur_lidar_to_ref_lidar)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute reference to future matrix.</span></span><br><span class="line">            ref_lidar_to_cur_lidar = (ref_l2e_transform.T @</span><br><span class="line">                                      ref_e2g_transform.T @</span><br><span class="line">                                      curr_g2e_transform.T @</span><br><span class="line">                                      curr_e2l_transform.T)</span><br><span class="line">            total_ref2cur_lidar_transform.append(ref_lidar_to_cur_lidar)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. Parse previous and future can_bus information.</span></span><br><span class="line">        imgs_list = [each[<span class="string">&#x27;img&#x27;</span>].data <span class="keyword">for</span> each <span class="keyword">in</span> previous_queue]</span><br><span class="line">        metas_map = &#123;&#125;</span><br><span class="line">        prev_scene_token = <span class="literal">None</span></span><br><span class="line">        prev_pos = <span class="literal">None</span></span><br><span class="line">        prev_angle = <span class="literal">None</span></span><br><span class="line">        ref_meta = previous_queue[-<span class="number">1</span>][<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.2. Previous</span></span><br><span class="line">        <span class="keyword">for</span> i, each <span class="keyword">in</span> <span class="built_in">enumerate</span>(previous_queue):</span><br><span class="line">            metas_map[i] = each[<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;aug_param&#x27;</span> <span class="keyword">in</span> each:</span><br><span class="line">                metas_map[i][<span class="string">&#x27;aug_param&#x27;</span>] = each[<span class="string">&#x27;aug_param&#x27;</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> metas_map[i][<span class="string">&#x27;scene_token&#x27;</span>] != prev_scene_token:</span><br><span class="line">                metas_map[i][<span class="string">&#x27;prev_bev_exists&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">                prev_scene_token = metas_map[i][<span class="string">&#x27;scene_token&#x27;</span>]</span><br><span class="line">                prev_pos = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][:<span class="number">3</span>])</span><br><span class="line">                prev_angle = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][-<span class="number">1</span>])</span><br><span class="line">                <span class="comment"># Set the original point of this motion.</span></span><br><span class="line">                new_can_bus = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = <span class="number">0</span></span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">                metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>] = new_can_bus</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                metas_map[i][<span class="string">&#x27;prev_bev_exists&#x27;</span>] = <span class="literal">True</span></span><br><span class="line">                tmp_pos = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][:<span class="number">3</span>])</span><br><span class="line">                tmp_angle = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][-<span class="number">1</span>])</span><br><span class="line">                <span class="comment"># Compute the later waypoint.</span></span><br><span class="line">                <span class="comment"># To align the shift and rotate difference due to the BEV.</span></span><br><span class="line">                new_can_bus = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = tmp_pos - prev_pos</span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = tmp_angle - prev_angle</span><br><span class="line">                metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>] = new_can_bus</span><br><span class="line">                prev_pos = copy.deepcopy(tmp_pos)</span><br><span class="line">                prev_angle = copy.deepcopy(tmp_angle)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute cur_lidar_to_ref_lidar transformation matrix for quickly align generated</span></span><br><span class="line">            <span class="comment">#  bev features to the reference frame.</span></span><br><span class="line">            metas_map[i][<span class="string">&#x27;ref_lidar_to_cur_lidar&#x27;</span>] = total_ref2cur_lidar_transform[i]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.3. Future</span></span><br><span class="line">        current_scene_token = ref_meta[<span class="string">&#x27;scene_token&#x27;</span>]</span><br><span class="line">        ref_can_bus = <span class="literal">None</span></span><br><span class="line">        future_can_bus = []</span><br><span class="line">        future2ref_lidar_transform = []</span><br><span class="line">        ref2future_lidar_transform = []</span><br><span class="line">        <span class="keyword">for</span> i, each <span class="keyword">in</span> <span class="built_in">enumerate</span>(future_queue):</span><br><span class="line">            future_meta = each[<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line">            <span class="keyword">if</span> future_meta[<span class="string">&#x27;scene_token&#x27;</span>] != current_scene_token:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># store the transformation:</span></span><br><span class="line">            future2ref_lidar_transform.append(</span><br><span class="line">                total_cur2ref_lidar_transform[i + <span class="built_in">len</span>(previous_queue) - <span class="number">1</span>]</span><br><span class="line">            )  <span class="comment"># current -&gt; reference.</span></span><br><span class="line">            ref2future_lidar_transform.append(</span><br><span class="line">                total_ref2cur_lidar_transform[i + <span class="built_in">len</span>(previous_queue) - <span class="number">1</span>]</span><br><span class="line">            )  <span class="comment"># reference -&gt; current.</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># can_bus information.</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                new_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = <span class="number">0</span></span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">                future_can_bus.append(new_can_bus)</span><br><span class="line">                ref_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                new_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line"></span><br><span class="line">                new_can_bus_pos = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]).reshape(<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">                ref2prev_lidar_transform = ref2future_lidar_transform[-<span class="number">2</span>]</span><br><span class="line">                cur2ref_lidar_transform = future2ref_lidar_transform[-<span class="number">1</span>]</span><br><span class="line">                new_can_bus_pos = new_can_bus_pos @ cur2ref_lidar_transform @ ref2prev_lidar_transform</span><br><span class="line"></span><br><span class="line">                new_can_bus_angle = new_can_bus[-<span class="number">1</span>] - ref_can_bus[-<span class="number">1</span>]</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = new_can_bus_pos[:, :<span class="number">3</span>]</span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = new_can_bus_angle</span><br><span class="line">                future_can_bus.append(new_can_bus)</span><br><span class="line">                ref_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        ret_queue = previous_queue[-<span class="number">1</span>]</span><br><span class="line">        ret_queue[<span class="string">&#x27;img&#x27;</span>] = DC(torch.stack(imgs_list), cpu_only=<span class="literal">False</span>, stack=<span class="literal">True</span>)</span><br><span class="line">        ret_queue.pop(<span class="string">&#x27;aug_param&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;future_can_bus&#x27;</span>] = np.array(future_can_bus)</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;future2ref_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(future2ref_lidar_transform))</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;ref2future_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(ref2future_lidar_transform))</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;total_cur2ref_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(total_cur2ref_lidar_transform))</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;total_ref2cur_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(total_ref2cur_lidar_transform))</span><br><span class="line"></span><br><span class="line">        ret_queue[<span class="string">&#x27;img_metas&#x27;</span>] = DC(metas_map, cpu_only=<span class="literal">True</span>)</span><br><span class="line">        ret_queue.pop(<span class="string">&#x27;points&#x27;</span>)</span><br><span class="line">        ret_queue[<span class="string">&#x27;gt_points&#x27;</span>] = DC(</span><br><span class="line">            torch.from_numpy(np.concatenate(total_pts_list, <span class="number">0</span>)), cpu_only=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(future_can_bus) &lt; <span class="number">1</span> + <span class="variable language_">self</span>.future_length:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> ret_queue</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_load_nstp_data</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载nSTP数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.nstp_data = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="variable language_">self</span>.nstp_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;警告: nSTP数据路径 <span class="subst">&#123;self.nstp_path&#125;</span> 不存在&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nstp = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">import</span> torch</span><br><span class="line">            <span class="keyword">import</span> glob</span><br><span class="line">            <span class="keyword">import</span> os.path <span class="keyword">as</span> osp</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 获取目录中所有的.pt文件</span></span><br><span class="line">            pt_files = glob.glob(osp.join(<span class="variable language_">self</span>.nstp_path, <span class="string">&quot;*.pt&quot;</span>))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> pt_files:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;警告: 在 <span class="subst">&#123;self.nstp_path&#125;</span> 中未找到.pt文件&quot;</span>)</span><br><span class="line">                <span class="variable language_">self</span>.use_nstp = <span class="literal">False</span></span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">                </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;找到 <span class="subst">&#123;<span class="built_in">len</span>(pt_files)&#125;</span> 个nSTP数据文件&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 加载每个.pt文件</span></span><br><span class="line">            <span class="keyword">for</span> pt_file <span class="keyword">in</span> pt_files:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="comment"># 从文件名获取样本ID</span></span><br><span class="line">                    sample_id = osp.splitext(osp.basename(pt_file))[<span class="number">0</span>]</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 加载PyTorch张量</span></span><br><span class="line">                    graph_data = torch.load(pt_file)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 将数据添加到字典中</span></span><br><span class="line">                    <span class="variable language_">self</span>.nstp_data[sample_id] = graph_data</span><br><span class="line">                    </span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;加载文件 <span class="subst">&#123;pt_file&#125;</span> 失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">                    </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;成功加载 <span class="subst">&#123;<span class="built_in">len</span>(self.nstp_data)&#125;</span> 个nSTP样本&quot;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;加载nSTP数据失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;继续训练，但不使用nSTP数据&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nstp = <span class="literal">False</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="2-1-2-NuPlan数据集"><a href="#2-1-2-NuPlan数据集" class="headerlink" title="2.1.2 NuPlan数据集"></a>2.1.2 NuPlan数据集</h4><p><strong>文件路径</strong>: <code>d:\git_clone\ViDAR\projects\mmdet3d_plugin\datasets\nuplan_vidar_dataset_v1.py</code></p><p><strong>主要修改</strong>:</p><ul><li>与NuScenes数据集类似，添加了nSTP支持</li><li>实现了特定于NuPlan数据集的nSTP数据加载和处理逻辑</li></ul><h3 id="2-2-模型头部修改"><a href="#2-2-模型头部修改" class="headerlink" title="2.2 模型头部修改"></a>2.2 模型头部修改</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\bevformer\dense_heads\vidar_head_v1.py</code></p><p><strong>主要修改</strong>:</p><ul><li>添加了nSTP相关参数：<code>use_nstp</code>, <code>nstp_encoder_cfg</code>, <code>nstp_enhancer_cfg</code></li><li>集成了nSTP编码器和增强器到模型头部</li><li>修改了前向传播逻辑，处理nSTP特征</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"><span class="comment"># Visual Point Cloud Forecasting enables Scalable Autonomous Driving              #</span></span><br><span class="line"><span class="comment"># Copyright (c) OpenDriveLab. All rights reserved.                                #</span></span><br><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;V1.multiframe&gt; of ViDAR future prediction head:</span></span><br><span class="line"><span class="string">    * Predict future &amp; history frames simultaneously.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mmdet.models <span class="keyword">import</span> HEADS, build_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mmcv.runner <span class="keyword">import</span> force_fp32, auto_fp16</span><br><span class="line"><span class="keyword">from</span> .vidar_head_base <span class="keyword">import</span> ViDARHeadBase</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@HEADS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ViDARHeadV1</span>(<span class="title class_ inherited__">ViDARHeadBase</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 history_queue_length,</span></span><br><span class="line"><span class="params">                 pred_history_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 pred_future_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 per_frame_loss_weight=(<span class="params"><span class="number">1.0</span>,</span>),</span></span><br><span class="line"><span class="params">                 use_nskg=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 nskg_encoder_cfg=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 nskg_enhancer_cfg=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 use_nstp=<span class="literal">False</span>,  <span class="comment"># 添加nSTP支持参数</span></span></span><br><span class="line"><span class="params">                 nstp_encoder_cfg=<span class="literal">None</span>,  <span class="comment"># 添加nSTP编码器配置</span></span></span><br><span class="line"><span class="params">                 nstp_enhancer_cfg=<span class="literal">None</span>,  <span class="comment"># 添加nSTP增强器配置</span></span></span><br><span class="line"><span class="params">                 *args,</span></span><br><span class="line"><span class="params">                 **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(*args, **kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.history_queue_length = history_queue_length</span><br><span class="line">        <span class="variable language_">self</span>.pred_history_frame_num = pred_history_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.pred_future_frame_num = pred_future_frame_num</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.pred_frame_num = <span class="number">1</span> + <span class="variable language_">self</span>.pred_history_frame_num + <span class="variable language_">self</span>.pred_future_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.per_frame_loss_weight = per_frame_loss_weight</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.per_frame_loss_weight) == <span class="variable language_">self</span>.pred_frame_num</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._init_bev_pred_layers()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># nSKG支持</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nskg = use_nskg</span><br><span class="line">        <span class="comment"># nSTP支持</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nstp = use_nstp</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg:</span><br><span class="line">            <span class="keyword">from</span> ..modules.nskg_gnn <span class="keyword">import</span> NSKGEncoder</span><br><span class="line">            <span class="keyword">from</span> ..modules.nskg_bev_enhancer <span class="keyword">import</span> NSKGBEVEnhancer</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 创建nSKG编码器</span></span><br><span class="line">            <span class="keyword">if</span> nskg_encoder_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_encoder = NSKGEncoder(**nskg_encoder_cfg)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_encoder = NSKGEncoder(</span><br><span class="line">                    in_channels=<span class="number">8</span>,</span><br><span class="line">                    hidden_channels=<span class="number">64</span>,</span><br><span class="line">                    out_channels=<span class="number">256</span>,</span><br><span class="line">                    num_layers=<span class="number">2</span>,</span><br><span class="line">                    gnn_type=<span class="string">&#x27;gat&#x27;</span>,</span><br><span class="line">                    use_hetero=<span class="literal">True</span></span><br><span class="line">                )</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 创建BEV特征增强器</span></span><br><span class="line">            <span class="keyword">if</span> nskg_enhancer_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_enhancer = NSKGBEVEnhancer(**nskg_enhancer_cfg)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_enhancer = NSKGBEVEnhancer(</span><br><span class="line">                    bev_channels=<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                    nskg_channels=<span class="number">256</span>,</span><br><span class="line">                    hidden_channels=<span class="number">128</span>,</span><br><span class="line">                    bev_h=<span class="variable language_">self</span>.bev_h,</span><br><span class="line">                    bev_w=<span class="variable language_">self</span>.bev_w,</span><br><span class="line">                    use_attention=<span class="literal">True</span></span><br><span class="line">                )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.nskg_encoder = <span class="literal">None</span></span><br><span class="line">            <span class="variable language_">self</span>.nskg_enhancer = <span class="literal">None</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 添加nSTP支持</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.use_nstp:</span><br><span class="line">                <span class="keyword">from</span> ..modules.nstp_encoder <span class="keyword">import</span> NSTPEncoder, NSTPEnhancer</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 创建nSTP编码器</span></span><br><span class="line">                <span class="keyword">if</span> nstp_encoder_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_encoder = NSTPEncoder(**nstp_encoder_cfg)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_encoder = NSTPEncoder(</span><br><span class="line">                        in_channels=<span class="number">64</span>,</span><br><span class="line">                        hidden_channels=<span class="number">128</span>,</span><br><span class="line">                        out_channels=<span class="number">256</span>,</span><br><span class="line">                        num_layers=<span class="number">3</span>,</span><br><span class="line">                        gnn_type=<span class="string">&#x27;graphsage&#x27;</span>,</span><br><span class="line">                        dropout=<span class="number">0.1</span>,</span><br><span class="line">                        aggr=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">                    )</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 创建nSTP增强器</span></span><br><span class="line">                <span class="keyword">if</span> nstp_enhancer_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_enhancer = NSTPEnhancer(**nstp_enhancer_cfg)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_enhancer = NSTPEnhancer(</span><br><span class="line">                        bev_channels=<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                        nstp_channels=<span class="number">256</span>,</span><br><span class="line">                        hidden_channels=<span class="number">128</span>,</span><br><span class="line">                        bev_h=<span class="variable language_">self</span>.bev_h,</span><br><span class="line">                        bev_w=<span class="variable language_">self</span>.bev_w,</span><br><span class="line">                        use_attention=<span class="literal">True</span></span><br><span class="line">                    )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nstp_encoder = <span class="literal">None</span></span><br><span class="line">                <span class="variable language_">self</span>.nstp_enhancer = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, mlvl_feats, img_metas, prev_bev=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Forward function.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            mlvl_feats (list(Tensor)): 多尺度特征，每个元素形状为 [B, num_cam, C, H, W]</span></span><br><span class="line"><span class="string">            img_metas (list(dict)): 图像元信息</span></span><br><span class="line"><span class="string">            prev_bev: 历史BEV特征</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            tuple: bev_embed, history_states, future_states</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 调用父类的forward方法获取原始结果</span></span><br><span class="line">        bev_embed, history_states, future_states = <span class="built_in">super</span>().forward(</span><br><span class="line">            mlvl_feats, img_metas, prev_bev, **kwargs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSKG，处理图数据增强BEV特征</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_encoder <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_enhancer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            bs = bev_embed.shape[<span class="number">0</span>]</span><br><span class="line">            bev_h, bev_w = <span class="variable language_">self</span>.bev_h, <span class="variable language_">self</span>.bev_w</span><br><span class="line">            </span><br><span class="line">            nskg_graphs = []</span><br><span class="line">            <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas:</span><br><span class="line">                nskg_graph = img_meta.get(<span class="string">&#x27;nskg_graph&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">                nskg_graphs.append(nskg_graph)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 处理每个样本的nSKG数据</span></span><br><span class="line">            enhanced_bevs = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">                <span class="comment"># 获取当前样本的BEV特征</span></span><br><span class="line">                curr_bev = bev_embed[i:i+<span class="number">1</span>].view(<span class="number">1</span>, bev_h, bev_w, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 获取当前样本的nSKG图</span></span><br><span class="line">                curr_graph = nskg_graphs[i] <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(nskg_graphs) <span class="keyword">and</span> nskg_graphs[i] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> curr_graph <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="comment"># 使用GNN编码器处理图数据</span></span><br><span class="line">                    node_features, global_features = <span class="variable language_">self</span>.nskg_encoder(curr_graph)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 获取节点位置信息</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">hasattr</span>(curr_graph, <span class="string">&#x27;pos&#x27;</span>):</span><br><span class="line">                        node_pos = curr_graph.pos</span><br><span class="line">                    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(curr_graph, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&#x27;pos&#x27;</span> <span class="keyword">in</span> curr_graph:</span><br><span class="line">                        node_pos = curr_graph[<span class="string">&#x27;pos&#x27;</span>]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        node_pos = <span class="literal">None</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 增强BEV特征</span></span><br><span class="line">                    enhanced_bev = <span class="variable language_">self</span>.nskg_enhancer(</span><br><span class="line">                        curr_bev, node_features, global_features, node_pos)</span><br><span class="line">                        </span><br><span class="line">                    enhanced_bevs.append(enhanced_bev)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 如果没有nSKG数据，保持原始BEV特征不变</span></span><br><span class="line">                    enhanced_bevs.append(curr_bev)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 合并增强后的BEV特征</span></span><br><span class="line">            <span class="keyword">if</span> enhanced_bevs:</span><br><span class="line">                enhanced_bev = torch.cat(enhanced_bevs, dim=<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># 转回原始格式</span></span><br><span class="line">                bev_embed = enhanced_bev.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(bs, bev_h * bev_w, -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加nSTP支持</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nstp <span class="keyword">and</span> <span class="variable language_">self</span>.nstp_encoder <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.nstp_enhancer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            bs = bev_embed.shape[<span class="number">0</span>]</span><br><span class="line">            bev_h, bev_w = <span class="variable language_">self</span>.bev_h, <span class="variable language_">self</span>.bev_w</span><br><span class="line">            </span><br><span class="line">            nstp_graphs = []</span><br><span class="line">            <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas:</span><br><span class="line">                nstp_graph = img_meta.get(<span class="string">&#x27;nstp_graph&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">                nstp_graphs.append(nstp_graph)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 处理每个样本的nSTP数据</span></span><br><span class="line">            enhanced_bevs = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">                <span class="comment"># 获取当前样本的BEV特征</span></span><br><span class="line">                curr_bev = bev_embed[i:i+<span class="number">1</span>].view(<span class="number">1</span>, bev_h, bev_w, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 获取当前样本的nSTP图</span></span><br><span class="line">                curr_graph = nstp_graphs[i] <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(nstp_graphs) <span class="keyword">and</span> nstp_graphs[i] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> curr_graph <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="comment"># 使用GNN编码器处理图数据</span></span><br><span class="line">                    node_features = <span class="variable language_">self</span>.nstp_encoder(curr_graph)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 获取节点位置信息（如果有）</span></span><br><span class="line">                    node_pos = <span class="literal">None</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">hasattr</span>(curr_graph, <span class="string">&#x27;pos&#x27;</span>):</span><br><span class="line">                        node_pos = curr_graph.pos</span><br><span class="line">                    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(curr_graph, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&#x27;pos&#x27;</span> <span class="keyword">in</span> curr_graph:</span><br><span class="line">                        node_pos = curr_graph[<span class="string">&#x27;pos&#x27;</span>]</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 增强BEV特征</span></span><br><span class="line">                    enhanced_bev = <span class="variable language_">self</span>.nstp_enhancer(curr_bev, node_features, node_pos)</span><br><span class="line">                    enhanced_bevs.append(enhanced_bev)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 如果没有nSTP数据，保持原始BEV特征不变</span></span><br><span class="line">                    enhanced_bevs.append(curr_bev)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 合并增强后的BEV特征</span></span><br><span class="line">            <span class="keyword">if</span> enhanced_bevs:</span><br><span class="line">                enhanced_bev = torch.cat(enhanced_bevs, dim=<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># 转回原始格式</span></span><br><span class="line">                bev_embed = enhanced_bev.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(bs, bev_h * bev_w, -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> bev_embed, history_states, future_states</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_bev_pred_layers</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Overwrite the &#123;self.bev_pred_head&#125; of super()._init_layers()</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        bev_pred_branch = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_pred_fcs):</span><br><span class="line">            bev_pred_branch.append(nn.Linear(<span class="variable language_">self</span>.embed_dims, <span class="variable language_">self</span>.embed_dims))</span><br><span class="line">            bev_pred_branch.append(nn.LayerNorm(<span class="variable language_">self</span>.embed_dims))</span><br><span class="line">            bev_pred_branch.append(nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line">        bev_pred_branch.append(nn.Linear(</span><br><span class="line">            <span class="variable language_">self</span>.embed_dims, <span class="variable language_">self</span>.pred_frame_num * <span class="variable language_">self</span>.num_pred_height))</span><br><span class="line">        bev_pred_head = nn.Sequential(*bev_pred_branch)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_get_clones</span>(<span class="params">module, N</span>):</span><br><span class="line">            <span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Auxiliary supervision for all intermediate results.</span></span><br><span class="line">        num_pred = <span class="variable language_">self</span>.transformer.decoder.num_layers</span><br><span class="line">        <span class="variable language_">self</span>.bev_pred_head = _get_clones(bev_pred_head, num_pred)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_head</span>(<span class="params">self, next_bev_feats</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get freespace estimation from multi-frame BEV feature maps.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            next_bev_feats (torch.Tensor): with shape as</span></span><br><span class="line"><span class="string">                [pred_frame_num, inter_num, bs, bev_h * bev_w, dims]</span></span><br><span class="line"><span class="string">                pred_frame_num: history frames + current frame + future frames.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        next_bev_preds = []</span><br><span class="line">        <span class="keyword">for</span> lvl <span class="keyword">in</span> <span class="built_in">range</span>(next_bev_feats.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="comment"># pred_frame_num, bs, bev_h * bev_w, num_height_pred * num_frame</span></span><br><span class="line">            <span class="comment">#  ===&gt; pred_frame_num, bs, bev_h * bev_w, num_height_pred, num_frame</span></span><br><span class="line">            <span class="comment">#  ===&gt; pred_frame_num, num_frame, bs, bev_h * bev_w, num_height_pred.</span></span><br><span class="line">            next_bev_pred = <span class="variable language_">self</span>.bev_pred_head[lvl](next_bev_feats[:, lvl])</span><br><span class="line">            next_bev_pred = next_bev_pred.view(</span><br><span class="line">                *next_bev_pred.shape[:-<span class="number">1</span>], <span class="variable language_">self</span>.num_pred_height, <span class="variable language_">self</span>.pred_frame_num)</span><br><span class="line"></span><br><span class="line">            base_bev_pred = next_bev_pred[..., <span class="variable language_">self</span>.pred_history_frame_num][..., <span class="literal">None</span>]</span><br><span class="line">            next_bev_pred = torch.cat([</span><br><span class="line">                next_bev_pred[..., :<span class="variable language_">self</span>.pred_history_frame_num] + base_bev_pred,</span><br><span class="line">                base_bev_pred,</span><br><span class="line">                next_bev_pred[..., <span class="variable language_">self</span>.pred_history_frame_num + <span class="number">1</span>:] + base_bev_pred</span><br><span class="line">            ], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            next_bev_pred = next_bev_pred.permute(<span class="number">0</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>).contiguous()</span><br><span class="line">            next_bev_preds.append(next_bev_pred)</span><br><span class="line">        <span class="comment"># pred_frame_num, inter_num, num_frame, bs, bev_h*bev_w, num_height_pred</span></span><br><span class="line">        next_bev_preds = torch.stack(next_bev_preds, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> next_bev_preds</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_reference_gt_points</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                                 gt_points,</span></span><br><span class="line"><span class="params">                                 src_frame_idx_list,</span></span><br><span class="line"><span class="params">                                 tgt_frame_idx_list,</span></span><br><span class="line"><span class="params">                                 img_metas</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Transform gt_points at src_frame_idx in &#123;src_frame_idx_list&#125; to the coordinate space</span></span><br><span class="line"><span class="string">        of each tgt_frame_idx in &#123;tgt_frame_idx_list&#125;.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        bs = <span class="built_in">len</span>(gt_points)</span><br><span class="line">        aligned_gt_points = []</span><br><span class="line">        batched_origin_points = []</span><br><span class="line">        <span class="keyword">for</span> frame_idx, src_frame_idx, tgt_frame_idx <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">                <span class="built_in">range</span>(<span class="built_in">len</span>(src_frame_idx_list)), src_frame_idx_list, tgt_frame_idx_list):</span><br><span class="line">            <span class="comment"># 1. get gt_points belongs to src_frame_idx.</span></span><br><span class="line">            src_frame_gt_points = [p[p[:, -<span class="number">1</span>] == src_frame_idx] <span class="keyword">for</span> p <span class="keyword">in</span> gt_points]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2. get transformation matrix..</span></span><br><span class="line">            src_to_ref = [img_meta[<span class="string">&#x27;total_cur2ref_lidar_transform&#x27;</span>][src_frame_idx] <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas]</span><br><span class="line">            src_to_ref = gt_points[<span class="number">0</span>].new_tensor(np.array(src_to_ref))  <span class="comment"># bs, 4, 4</span></span><br><span class="line">            ref_to_tgt = [img_meta[<span class="string">&#x27;total_ref2cur_lidar_transform&#x27;</span>][tgt_frame_idx] <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas]</span><br><span class="line">            ref_to_tgt = gt_points[<span class="number">0</span>].new_tensor(np.array(ref_to_tgt))  <span class="comment"># bs, 4, 4</span></span><br><span class="line">            src_to_tgt = torch.matmul(src_to_ref, ref_to_tgt)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3. transfer src_frame_gt_points to src_to_tgt.</span></span><br><span class="line">            aligned_gt_points_per_frame = []</span><br><span class="line">            <span class="keyword">for</span> batch_idx, points <span class="keyword">in</span> <span class="built_in">enumerate</span>(src_frame_gt_points):</span><br><span class="line">                new_points = points.clone()  <span class="comment"># -1, 4</span></span><br><span class="line">                new_points = torch.cat([</span><br><span class="line">                    new_points[:, :<span class="number">3</span>], new_points.new_ones(new_points.shape[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">                ], <span class="number">1</span>)</span><br><span class="line">                new_points = torch.matmul(new_points, src_to_tgt[batch_idx])</span><br><span class="line">                new_points[..., -<span class="number">1</span>] = frame_idx</span><br><span class="line">                aligned_gt_points_per_frame.append(new_points)</span><br><span class="line">            aligned_gt_points.append(aligned_gt_points_per_frame)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4. obtain the aligned origin points.</span></span><br><span class="line">            aligned_origin_points = torch.from_numpy(</span><br><span class="line">                np.zeros((bs, <span class="number">1</span>, <span class="number">3</span>))).to(src_to_tgt.dtype).to(src_to_tgt.device)</span><br><span class="line">            aligned_origin_points = torch.cat([</span><br><span class="line">                aligned_origin_points[..., :<span class="number">3</span>], torch.ones_like(aligned_origin_points)[..., <span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">            ], -<span class="number">1</span>)</span><br><span class="line">            aligned_origin_points = torch.matmul(aligned_origin_points, src_to_tgt)</span><br><span class="line">            batched_origin_points.append(aligned_origin_points[..., :<span class="number">3</span>].contiguous())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># stack points from different timestamps, and transfer to occupancy representation.</span></span><br><span class="line">        batched_gt_points = []</span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">            cur_gt_points = [</span><br><span class="line">                aligned_gt_points[frame_idx][b]</span><br><span class="line">                <span class="keyword">for</span> frame_idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(src_frame_idx_list))]</span><br><span class="line">            cur_gt_points = torch.cat(cur_gt_points, <span class="number">0</span>)</span><br><span class="line">            batched_gt_points.append(cur_gt_points)</span><br><span class="line"></span><br><span class="line">        batched_origin_points = torch.cat(batched_origin_points, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> batched_gt_points, batched_origin_points</span><br><span class="line"></span><br><span class="line"><span class="meta">    @force_fp32(<span class="params">apply_to=(<span class="params"><span class="string">&#x27;pred_dict&#x27;</span></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             pred_dict,</span></span><br><span class="line"><span class="params">             gt_points,</span></span><br><span class="line"><span class="params">             start_idx,</span></span><br><span class="line"><span class="params">             tgt_bev_h,</span></span><br><span class="line"><span class="params">             tgt_bev_w,</span></span><br><span class="line"><span class="params">             tgt_pc_range,</span></span><br><span class="line"><span class="params">             pred_frame_num,</span></span><br><span class="line"><span class="params">             img_metas=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             batched_origin_points=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;Compute loss for all history according to gt_points.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        gt_points: ground-truth point cloud in each frame.</span></span><br><span class="line"><span class="string">            list of tensor with shape [-1, 5], indicating ground-truth point cloud in</span></span><br><span class="line"><span class="string">            each frame.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        bev_preds = pred_dict[<span class="string">&#x27;next_bev_preds&#x27;</span>]</span><br><span class="line">        valid_frames = np.array(pred_dict[<span class="string">&#x27;valid_frames&#x27;</span>])</span><br><span class="line">        start_frames = (valid_frames + <span class="variable language_">self</span>.history_queue_length - <span class="variable language_">self</span>.pred_history_frame_num)</span><br><span class="line">        tgt_frames = valid_frames + <span class="variable language_">self</span>.history_queue_length</span><br><span class="line"></span><br><span class="line">        full_prev_bev_exists = pred_dict.get(<span class="string">&#x27;full_prev_bev_exists&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> full_prev_bev_exists:</span><br><span class="line">            frame_idx_for_loss = [<span class="variable language_">self</span>.pred_history_frame_num] * <span class="variable language_">self</span>.pred_frame_num</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            frame_idx_for_loss = np.arange(<span class="number">0</span>, <span class="variable language_">self</span>.pred_frame_num)</span><br><span class="line"></span><br><span class="line">        loss_dict = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> idx, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(frame_idx_for_loss):</span><br><span class="line">            <span class="comment"># 1. get the predicted occupancy of frame-i.</span></span><br><span class="line">            cur_bev_preds = bev_preds[:, :, i, ...].contiguous()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2. get the frame index of current frame.</span></span><br><span class="line">            src_frames = start_frames + i</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3. get gt_points belonging to cur_valid_frames.</span></span><br><span class="line">            cur_gt_points, cur_origin_points = <span class="variable language_">self</span>._get_reference_gt_points(</span><br><span class="line">                gt_points,</span><br><span class="line">                src_frame_idx_list=src_frames,</span><br><span class="line">                tgt_frame_idx_list=tgt_frames,</span><br><span class="line">                img_metas=img_metas)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4. compute loss.</span></span><br><span class="line">            <span class="keyword">if</span> i != <span class="variable language_">self</span>.pred_history_frame_num:</span><br><span class="line">                <span class="comment"># For aux history-future supervision:</span></span><br><span class="line">                <span class="comment">#  only compute loss for cur_frame prediction.</span></span><br><span class="line">                loss_weight = np.array([[<span class="number">1</span>]] + [[<span class="number">0</span>]] * (<span class="built_in">len</span>(<span class="variable language_">self</span>.loss_weight) - <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                loss_weight = <span class="variable language_">self</span>.loss_weight</span><br><span class="line"></span><br><span class="line">            cur_loss_dict = <span class="built_in">super</span>().loss(</span><br><span class="line">                <span class="built_in">dict</span>(next_bev_preds=cur_bev_preds,</span><br><span class="line">                     valid_frames=np.arange(<span class="number">0</span>, <span class="built_in">len</span>(src_frames))),</span><br><span class="line">                cur_gt_points,</span><br><span class="line">                start_idx=start_idx,</span><br><span class="line">                tgt_bev_h=tgt_bev_h,</span><br><span class="line">                tgt_bev_w=tgt_bev_w,</span><br><span class="line">                tgt_pc_range=tgt_pc_range,</span><br><span class="line">                pred_frame_num=<span class="built_in">len</span>(<span class="variable language_">self</span>.loss_weight)-<span class="number">1</span>,</span><br><span class="line">                img_metas=img_metas,</span><br><span class="line">                batched_origin_points=cur_origin_points,</span><br><span class="line">                loss_weight=loss_weight)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 5. merge dict.</span></span><br><span class="line">            cur_frame_loss_weight = <span class="variable language_">self</span>.per_frame_loss_weight[i]</span><br><span class="line">            cur_frame_loss_weight = cur_frame_loss_weight * (idx == i)</span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> cur_loss_dict.items():</span><br><span class="line">                loss_dict.update(&#123;<span class="string">f&#x27;frame.<span class="subst">&#123;idx&#125;</span>.<span class="subst">&#123;k&#125;</span>.loss&#x27;</span>: v * cur_frame_loss_weight&#125;)</span><br><span class="line">        <span class="keyword">return</span> loss_dict</span><br><span class="line"></span><br><span class="line"><span class="meta">    @force_fp32(<span class="params">apply_to=(<span class="params"><span class="string">&#x27;pred_dict&#x27;</span></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_point_cloud_prediction</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                                   pred_dict,</span></span><br><span class="line"><span class="params">                                   gt_points,</span></span><br><span class="line"><span class="params">                                   start_idx,</span></span><br><span class="line"><span class="params">                                   tgt_bev_h,</span></span><br><span class="line"><span class="params">                                   tgt_bev_w,</span></span><br><span class="line"><span class="params">                                   tgt_pc_range,</span></span><br><span class="line"><span class="params">                                   img_metas=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                                   batched_origin_points=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;Generate point cloud prediction.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># pred_frame_num, inter_num, num_frame, bs, bev_h * bev_w, num_height_pred</span></span><br><span class="line">        pred_dict[<span class="string">&#x27;next_bev_preds&#x27;</span>] = pred_dict[<span class="string">&#x27;next_bev_preds&#x27;</span>][:, :, <span class="variable language_">self</span>.pred_history_frame_num, ...].contiguous()</span><br><span class="line"></span><br><span class="line">        valid_frames = np.array(pred_dict[<span class="string">&#x27;valid_frames&#x27;</span>])</span><br><span class="line">        valid_gt_points, cur_origin_points = <span class="variable language_">self</span>._get_reference_gt_points(</span><br><span class="line">            gt_points,</span><br><span class="line">            src_frame_idx_list=valid_frames + <span class="variable language_">self</span>.history_queue_length,</span><br><span class="line">            tgt_frame_idx_list=valid_frames + <span class="variable language_">self</span>.history_queue_length,</span><br><span class="line">            img_metas=img_metas)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().get_point_cloud_prediction(</span><br><span class="line">            pred_dict=pred_dict,</span><br><span class="line">            gt_points=valid_gt_points,</span><br><span class="line">            start_idx=start_idx,</span><br><span class="line">            tgt_bev_h=tgt_bev_h,</span><br><span class="line">            tgt_bev_w=tgt_bev_w,</span><br><span class="line">            tgt_pc_range=tgt_pc_range,</span><br><span class="line">            img_metas=img_metas,</span><br><span class="line">            batched_origin_points=cur_origin_points)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-3-ViDAR检测器修改"><a href="#2-3-ViDAR检测器修改" class="headerlink" title="2.3 ViDAR检测器修改"></a>2.3 ViDAR检测器修改</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\bevformer\detectors\vidar.py</code></p><p><strong>主要修改</strong>:</p><ul><li>修改了<code>forward_train</code>方法：处理nSTP特征，并解决了元组类型问题</li><li>修改了<code>forward_test</code>方法：支持测试时使用nSTP特征</li></ul><p>关键修改部分：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_train</span>(<span class="params">self, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ...现有代码...</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 修改部分：处理next_bev_feats中可能的元组类型</span></span><br><span class="line">    processed_next_bev_feats = []</span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> next_bev_feats:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(feat, <span class="built_in">tuple</span>):</span><br><span class="line">            <span class="comment"># 如果是元组，取第一个元素（主要特征）</span></span><br><span class="line">            processed_next_bev_feats.append(feat[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            processed_next_bev_feats.append(feat)</span><br><span class="line">    </span><br><span class="line">    next_bev_feats = torch.stack(processed_next_bev_feats, <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ...继续现有代码...</span></span><br></pre></td></tr></table></figure><h2 id="3-配置文件修改"><a href="#3-配置文件修改" class="headerlink" title="3. 配置文件修改"></a>3. 配置文件修改</h2><h3 id="3-1-OpenScene配置"><a href="#3-1-OpenScene配置" class="headerlink" title="3.1 OpenScene配置"></a>3.1 OpenScene配置</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\configs\vidar_pretrain\OpenScene\vidar_OpenScene_mini_1_8_3future_nstp.py</code></p><p><strong>主要修改</strong>:</p><ul><li>添加了nSTP相关配置：启用nSTP，设置数据路径</li><li>修改了数据处理流程，添加了nSTP数据处理组件</li><li>配置了nSTP编码器和增强器参数</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nSTP配置</span></span><br><span class="line">use_nskg = <span class="literal">False</span>  <span class="comment"># 禁用nSKG</span></span><br><span class="line">use_nstp = <span class="literal">True</span>  <span class="comment"># 启用nSTP</span></span><br><span class="line">nstp_path = <span class="string">&#x27;data/nuscenes/nstp/train/raw&#x27;</span>  <span class="comment"># nSTP数据目录路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加nSTP数据处理组件</span></span><br><span class="line">train_pipeline.insert(-<span class="number">2</span>, <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ProcessNSTPGraph&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改数据集配置</span></span><br><span class="line">data = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    train=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">        use_nstp=use_nstp,</span><br><span class="line">        nstp_path=nstp_path,</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    ),</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="3-2-NuScenes全集配置"><a href="#3-2-NuScenes全集配置" class="headerlink" title="3.2 NuScenes全集配置"></a>3.2 NuScenes全集配置</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\configs\vidar_pretrain\nusc_fullset\vidar_nstp_nusc.py</code></p><p><strong>主要修改</strong>:</p><ul><li>基于基础配置，添加了nSTP支持</li><li>配置了nSTP数据路径和处理逻辑</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_base_ = [<span class="string">&#x27;./vidar_full_nusc_1future.py&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># nSTP配置</span></span><br><span class="line">use_nskg = <span class="literal">False</span></span><br><span class="line">use_nstp = <span class="literal">True</span></span><br><span class="line">nstp_path = <span class="string">&#x27;data/nuscenes/nstp/nstp.pkl&#x27;</span>  <span class="comment"># nSTP数据路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改数据集配置</span></span><br><span class="line">data = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    train=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;NuScenesViDARDatasetV1&#x27;</span>,</span><br><span class="line">        use_nskg=use_nskg,</span><br><span class="line">        use_nstp=use_nstp,</span><br><span class="line">        nstp_path=nstp_path,</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    ),</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="4-其他辅助修改"><a href="#4-其他辅助修改" class="headerlink" title="4. 其他辅助修改"></a>4. 其他辅助修改</h2><h3 id="4-1-数据集注册"><a href="#4-1-数据集注册" class="headerlink" title="4.1 数据集注册"></a>4.1 数据集注册</h3><p><strong>文件路径</strong>: <code>d:\git_clone\ViDAR\projects\mmdet3d_plugin\datasets\__init__.py</code></p><p><strong>主要修改</strong>:</p><ul><li>导入并注册了nSTP相关模块：<code>NSTPEncoder</code>, <code>NSTPEnhancer</code></li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> .nstp_encoder <span class="keyword">import</span> NSTPEncoder, NSTPEnhancer</span><br><span class="line"></span><br><span class="line">__all__ = [</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="string">&#x27;NSTPEncoder&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;NSTPEnhancer&#x27;</span>,</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><h2 id="5-过程中的好多错误"><a href="#5-过程中的好多错误" class="headerlink" title="5. 过程中的好多错误"></a>5. 过程中的好多错误</h2><p><img src="/article/8257d2b5/bb0c0e4dfe0861b863c951950326904.png" alt="bb0c0e4dfe0861b863c951950326904"></p><p>首先是数据集nSKG不能用，用了会出现这个问题：</p><p><img src="/article/8257d2b5/c5f86c19470657dbb32886c2a1ecc09.png" alt="c5f86c19470657dbb32886c2a1ecc09"></p><p><img src="/article/8257d2b5/592bd326d2dfd419178041902a18105.png" alt="592bd326d2dfd419178041902a18105"></p><p>然后进而导致：</p><p><img src="/article/8257d2b5/baa821cdf2653096e4ff3d91e0adb78-174584491940213.png" alt="baa821cdf2653096e4ff3d91e0adb78"></p><p><img src="/article/8257d2b5/46aa267f5409cd333b793036e91f475.png" alt="46aa267f5409cd333b793036e91f475"></p><p>然后对他做细致处理的话，其实也可以，但是我写的代码处理不了：</p><p><img src="/article/8257d2b5/919ca81a4064679c687412f83fcacbf.png" alt="919ca81a4064679c687412f83fcacbf"></p><p>所以最后选择使用nSTP，因为在<a href="https://zenodo.org/records/10074393">nuScenes Knowledge Graph</a>发现了nSTP是对nSKG的拓展，而且可以直接拿来训练，因此修改代码适配：</p><p><img src="/article/8257d2b5/image-20250428205817288.png" alt="image-20250428205817288"></p><p><img src="/article/8257d2b5/94c305fa70e234b826ba190de87e104.png" alt="94c305fa70e234b826ba190de87e104"></p><p>最后结果，可以正常读取nSTP数据文件：</p><p><img src="/article/8257d2b5/f4d05a563eb5ef922c95d96436bf1d2.png" alt="f4d05a563eb5ef922c95d96436bf1d2"></p><p>但是……爆内存了：</p><p><img src="/article/8257d2b5/64c1d3c75e8a169d3bffaf3d1b7f692.png" alt="64c1d3c75e8a169d3bffaf3d1b7f692"></p><p>写到这里的时候刚修复了一小点bug，目前仍然在服务器上跑着……</p><p>然后最后贴一张饱受折损的服务器合照（感谢罗勇老师）</p><p><img src="/article/8257d2b5/926d4f6ee558907674f7927728597bc.png" alt="926d4f6ee558907674f7927728597bc"></p><p><img src="/article/8257d2b5/b83a187f7c801ef796584bdd84e832b.png" alt="b83a187f7c801ef796584bdd84e832b"></p><h2 id="6-最后总结"><a href="#6-最后总结" class="headerlink" title="6. 最后总结"></a>6. 最后总结</h2><p>nSTP集成工作主要包括以下几个方面：</p><ol><li><strong>数据处理</strong>：创建了nSTP图数据的加载和处理逻辑，支持从.pt文件中读取图结构数据</li><li><strong>特征提取</strong>：实现了基于图神经网络的nSTP编码器，提取图结构中的时空特征</li><li><strong>特征融合</strong>：实现了nSTP特征与BEV特征的融合机制，通过注意力机制增强BEV特征</li><li><strong>模型集成</strong>：将nSTP模块集成到ViDAR模型中，修改了前向传播逻辑</li><li><strong>配置支持</strong>：添加了nSTP相关配置，支持灵活开启&#x2F;关闭nSTP功能</li></ol><p>这些修改使ViDAR模型能够利用nSTP提供的场景结构和时间演化信息，增强了模型对动态场景的理解能力，特别是在预测未来帧方面。</p><p>然后我们完成的工作：</p><ol><li>完成环境配置，解决冲突依赖问题</li><li>完成数据集的读取与训练问题</li><li>完成对vidar的修改以加入nSTP数据集来调优</li><li>修复原本的pytouch问题</li><li>目前仍然在服务器上跑着，估计还有不少后续的训练问题需要修改……但是没时间了</li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cv </tag>
            
            <tag> 自动驾驶 </tag>
            
            <tag> 课程学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[长期更新]算法总结</title>
      <link href="/article/dba7e729.html"/>
      <url>/article/dba7e729.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>从力扣100题开始的算法总结，决定真正走科班的代码之路后，果然还是得彻底从头开始总结一些算法代码了，感觉会是一个长期的总结过程，而且还要保持长期热情，只能加油吧。之前技能点全点在做游戏上了，但如果真的决定要改变世界，那就不能止步不前了。</p><p>这个总结目前来说还比较简单片面，后续可能考虑针对各个算法进行单一深入应用总结。</p><p><img src="/article/dba7e729/wallhaven-5g22q5_1920x1080.png" alt="wallhaven-5g22q5_1920x1080"></p><h1 id="哈希"><a href="#哈希" class="headerlink" title="哈希"></a>哈希</h1><p>这一部分其实主要是利用哈希表来辅助解决问题。</p><p>可能困难比较大的是<strong>记住哈希表的使用方式</strong>（呃呃这就是记性差的坏处了）</p><p>记住之后很多问题在考虑到查找、拼接就可以直接从哈希表入手了：</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">unordered_map&lt;string, vector&lt;string&gt;&gt; groups;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> it = groups.<span class="built_in">begin</span>(); it != groups.<span class="built_in">end</span>(); it++)</span><br><span class="line">&#123;</span><br><span class="line">    ans.<span class="built_in">emplace_back</span>(it-&gt;second);           <span class="comment">// 每一组键值对的值加入结果中</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">unordered_set&lt;<span class="type">int</span>&gt; <span class="title">st</span><span class="params">(nums.begin(), nums.end())</span></span>; <span class="comment">// 把 nums 转成哈希集合</span></span><br><span class="line">st.<span class="built_in">contains</span>(x - <span class="number">1</span>); <span class="comment">// 哈希判断条件</span></span><br></pre></td></tr></table></figure><p>经典题目链接：</p><p><a href="https://leetcode.cn/problems/group-anagrams/?envType=study-plan-v2&envId=top-100-liked">49. 字母异位词分组 - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/longest-consecutive-sequence/?envType=study-plan-v2&envId=top-100-liked">128. 最长连续序列 - 力扣（LeetCode）</a></p><h1 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h1><p>双指针题目比较灵活，可以有以下两类（目前）：</p><ol><li>指针同时出发，主要挪动一个指针，满足特定条件再挪动另一个指针</li><li>指针同时出发，但是位于数列两端，进行比较选择挪动的指针</li></ol><p>代表性题目分别有：</p><p><a href="https://leetcode.cn/problems/move-zeroes/?envType=study-plan-v2&envId=top-100-liked">283. 移动零 - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/trapping-rain-water/?envType=study-plan-v2&envId=top-100-liked">42. 接雨水 - 力扣（LeetCode）</a></p><h1 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h1><p>先附上比较玄妙的一道题：</p><p><a href="https://leetcode.cn/problems/find-all-anagrams-in-a-string/?envType=study-plan-v2&envId=top-100-liked">438. 找到字符串中所有字母异位词 - 力扣（LeetCode）</a></p><p>这个的话比较字面意思，有点像双指针，主要通过动态调节窗口大小，来满足特定条件</p><p>主要操作是拓展窗口、缩减窗口、比较、选择。</p><p>然后可能会和子串在一起。</p><h1 id="子串"><a href="#子串" class="headerlink" title="子串"></a>子串</h1><h1 id="普通数组"><a href="#普通数组" class="headerlink" title="普通数组"></a>普通数组</h1><h1 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h1><h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><p>奇妙的题目：<a href="https://leetcode.cn/problems/linked-list-cycle-ii/solutions/12616/linked-list-cycle-ii-kuai-man-zhi-zhen-shuang-zhi-/?envType=study-plan-v2&envId=top-100-liked">142. 环形链表 II - 力扣（LeetCode）</a></p><h1 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h1><h1 id="图论"><a href="#图论" class="headerlink" title="图论"></a>图论</h1><h1 id="回溯"><a href="#回溯" class="headerlink" title="回溯"></a>回溯</h1><p>主要是有一个标准的板子</p><p>在此记录一下（其实感觉不是很难）</p><p>题目出处：<a href="https://leetcode.cn/problems/permutations/description/?envType=study-plan-v2&envId=top-100-liked">46. 全排列 - 力扣（LeetCode）</a></p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; res;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; path;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">backtracking</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums, vector&lt;<span class="type">bool</span>&gt;&amp; used)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (path.<span class="built_in">size</span>() == nums.<span class="built_in">size</span>())</span><br><span class="line">        &#123;</span><br><span class="line">            res.<span class="built_in">push_back</span>(path);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nums.<span class="built_in">size</span>(); i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (used[i] == <span class="literal">true</span>)   <span class="comment">//如果该元素被使用过了，则直接跳过</span></span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">            used[i] = <span class="literal">true</span>;        <span class="comment">//下面要用，先标记上已使用</span></span><br><span class="line">            path.<span class="built_in">push_back</span>(nums[i]);</span><br><span class="line">            <span class="built_in">backtracking</span>(nums, used);</span><br><span class="line">            path.<span class="built_in">pop_back</span>();       <span class="comment">//回溯path和used，即将本层的处理全部Ctrl + Z(撤销~~)</span></span><br><span class="line">            used[i] = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">permute</span>(vector&lt;<span class="type">int</span>&gt;&amp; nums) </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">used</span><span class="params">(nums.size(), <span class="literal">false</span>)</span></span>;</span><br><span class="line">        <span class="built_in">backtracking</span>(nums, used);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>还有感觉时不时可以回忆一下n皇后：<a href="https://leetcode.cn/problems/n-queens/?envType=study-plan-v2&envId=top-100-liked">51. N 皇后 - 力扣（LeetCode）</a></p><p>把**行（row）**视为回溯推进的路标！</p><p>感觉重要的就是路标的标定和查找。</p><h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h1><p>感觉是因为自己有一个很笨笨的方法，导致写的每次逻辑都非常不通畅。</p><p>因此在此记录下两者区别：</p><p>题目出处：<a href="https://leetcode.cn/problems/find-minimum-in-rotated-sorted-array/solutions/698479/xun-zhao-xuan-zhuan-pai-xu-shu-zu-zhong-5irwp/?envType=study-plan-v2&envId=top-100-liked">153. 寻找旋转排序数组中的最小值 - 力扣（LeetCode）</a></p><p>官方题解：</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">findMin</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> low = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> high = nums.<span class="built_in">size</span>() - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (low &lt; high) &#123;</span><br><span class="line">            <span class="type">int</span> pivot = low + (high - low) / <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span> (nums[pivot] &lt; nums[high]) &#123;</span><br><span class="line">                high = pivot;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                low = pivot + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> nums[low];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">作者：力扣官方题解</span><br><span class="line">链接：https:<span class="comment">//leetcode.cn/problems/find-minimum-in-rotated-sorted-array/solutions/698479/xun-zhao-xuan-zhuan-pai-xu-shu-zu-zhong-5irwp/</span></span><br><span class="line">来源：力扣（LeetCode）</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure><p>我的铸币理解：</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">findMin</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.<span class="built_in">size</span>() == <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">find</span>(<span class="number">0</span>,nums.<span class="built_in">size</span>()<span class="number">-1</span>,nums);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">int</span> left,<span class="type">int</span> right,vector&lt;<span class="type">int</span>&gt; nums)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="type">int</span> mid = (left + right)/<span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(left == right<span class="number">-1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> nums[right] &gt; nums[left] ? nums[left] : nums[right];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(nums[mid]&lt;nums[left])</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">find</span>(left,mid,nums);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(nums[mid]&gt;nums[right])</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">find</span>(mid,right,nums);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> nums[left];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h1><h1 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h1><h1 id="贪心算法"><a href="#贪心算法" class="headerlink" title="贪心算法"></a>贪心算法</h1><p>嘶……</p><p>大部分贪心都被我用dp过去了……</p><p>不过这道倒是dp没想出来:</p><p><a href="https://leetcode.cn/problems/jump-game-ii/?envType=study-plan-v2&envId=top-100-liked">45. 跳跃游戏 II - 力扣（LeetCode）</a></p><h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><p>感觉没有想象中的那么恐怖，其实就是要找到一条可以表示所有情况的通式。</p><p>接着找到他的初状态就可以了。</p><p>最好是要常备草稿纸！</p><h1 id="多维动态规划"><a href="#多维动态规划" class="headerlink" title="多维动态规划"></a>多维动态规划</h1><h1 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h1>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习ing </tag>
            
            <tag> 哈希 </tag>
            
            <tag> 双指针 </tag>
            
            <tag> 滑动窗口 </tag>
            
            <tag> 子串 </tag>
            
            <tag> 普通数组 </tag>
            
            <tag> 矩阵 </tag>
            
            <tag> 链表 </tag>
            
            <tag> 二叉树 </tag>
            
            <tag> 图论 </tag>
            
            <tag> 回溯 </tag>
            
            <tag> 二分查找 </tag>
            
            <tag> 栈 </tag>
            
            <tag> 堆 </tag>
            
            <tag> 贪心算法 </tag>
            
            <tag> 动态规划 </tag>
            
            <tag> 多维动态规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客迁移备忘录</title>
      <link href="/article/9312db38.html"/>
      <url>/article/9312db38.html</url>
      
        <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>这是一篇日后换电脑时备忘的博客，主要是关于hexo的迁移的。</p><h1 id="NodeJs"><a href="#NodeJs" class="headerlink" title="NodeJs"></a>NodeJs</h1><p>首先是安装nodejs，链接如下：<a href="https://nodejs.org/en/">https://nodejs.org/en/</a></p><p>然后是关于nodejs的配置路径问题：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> prefix <span class="string">&quot;D:\node\node_global&quot;</span></span><br><span class="line">npm config <span class="built_in">set</span> cache <span class="string">&quot;D:\node\node_cache</span></span><br></pre></td></tr></table></figure><p>以及镜像：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry https://registry.npmmirror.com</span><br></pre></td></tr></table></figure><p>最近想起来一件事，好像还得把所有安装的包给安装回来……</p><p>使用指令查看了下，依赖的包大概如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Administrator@PC-202207261451 MINGW64 /f/Hexo/My-Web (main)</span><br><span class="line">$ npm <span class="built_in">ls</span> -g --depth=0</span><br><span class="line">F:\node\node_global</span><br><span class="line">└── hexo-cli@4.3.2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Administrator@PC-202207261451 MINGW64 /f/Hexo/My-Web (main)</span><br><span class="line">$ npm list --depth=0</span><br><span class="line">hexo-site@0.0.0 F:\Hexo\My-Web</span><br><span class="line">├── hexo-abbrlink@2.2.1</span><br><span class="line">├── hexo-asset-img@1.2.0</span><br><span class="line">├── hexo-deployer-git@4.0.0</span><br><span class="line">├── hexo-generator-archive@2.0.0</span><br><span class="line">├── hexo-generator-category@2.0.0</span><br><span class="line">├── hexo-generator-index@4.0.0</span><br><span class="line">├── hexo-generator-search@2.4.3</span><br><span class="line">├── hexo-generator-tag@2.0.0</span><br><span class="line">├── hexo-helper-live2d@3.1.1</span><br><span class="line">├── hexo-renderer-ejs@2.0.0</span><br><span class="line">├── hexo-renderer-marked@7.0.1</span><br><span class="line">├── hexo-renderer-pug@3.0.0</span><br><span class="line">├── hexo-renderer-stylus@3.0.1</span><br><span class="line">├── hexo-server@3.0.0</span><br><span class="line">├── hexo-theme-butterfly@5.3.5</span><br><span class="line">├── hexo-theme-landscape@1.1.0</span><br><span class="line">├── hexo-wordcount@6.0.1</span><br><span class="line">├── hexo@7.3.0</span><br><span class="line">└── live2d-widget-model-tororo@1.0.5</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="拉取博客主站"><a href="#拉取博客主站" class="headerlink" title="拉取博客主站"></a>拉取博客主站</h1><p>这个配置完后，拉一下自己的博客官网进行迁移：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git pull 这个就不给看了</span><br></pre></td></tr></table></figure><h1 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h1><p>然后有比较好的一些教程，先记录一下，都是建站时候的参考：</p><p><a href="https://blog.csdn.net/m0_74795952/article/details/146370818?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-5-146370818-blog-129290903.235%5Ev43%5Epc_blog_bottom_relevance_base7&spm=1001.2101.3001.4242.4&utm_relevant_index=8">基础美化教程</a></p><p><a href="https://blog.anheyu.com/posts/52d8.html">过渡动画</a></p><h1 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h1><p>最后防止自己忘了 补充下hexo的语法：</p><p>hexo三连起手：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><p>创建博客:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new 博客名称</span><br></pre></td></tr></table></figure><p>创建页面：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new page 页面</span><br></pre></td></tr></table></figure><h1 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h1><ol><li><p>封面图片</p><p>补充一下封面图片的用法：</p><p>因为每次文章都会由插件生成一个唯一标识码，根据唯一标识码可以找到对应post的图片目录，比如本post的目录就为:<a href="http://aplainjane.github.io/article/9312db38">http://aplainjane.github.io/article/9312db38</a></p><p>然后由于修改了typora，每次插入图片会复制图片到该博客目录下的同名文件夹，所以最后生成的时候会把图片塞到对应article的目录下，故封面的图片设置就可以设置为：</p><p>top_img: <a href="http://aplainjane.github.io/article/9312db38/wallhaven-d69eom_1920x1080.png">http://aplainjane.github.io/article/9312db38/wallhaven-d69eom_1920x1080.png</a></p><p>cover: <a href="http://aplainjane.github.io/article/9312db38/wallhaven-d69eom_1920x1080.png">http://aplainjane.github.io/article/9312db38/wallhaven-d69eom_1920x1080.png</a></p></li><li><p>内嵌图片</p><p>由于已经修改typora内置参数，因此只需要将typora的图片路径修改为：博客名称&#x2F;图片名称</p><p>即可</p></li></ol><p>大概这样，最后再附张美图吧，以后哪里迁移出问题了再回来看看和补充</p><p><img src="/article/9312db38/wallhaven-d69eom_1920x1080.png" alt="wallhaven-d69eom_1920x1080"></p>]]></content>
      
      
      <categories>
          
          <category> 备忘 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> 博客迁移 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/article/4a17b156.html"/>
      <url>/article/4a17b156.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>你好呀！</p><p>这里是aplainjane的博客，是漂泊了一阵子后想要给自己留下一些足迹的地方。</p><p>之前一直都没有好好留存技术博客和项目介绍的好习惯，</p><p>但是从现在开始也不算迟嘛！</p><p>无论如何对着世界喊出一声“hello world!”</p><p>世界都会给你它最热烈的回应。</p><p>此刻就是好好经营自己，经营生活的最佳时刻！</p><p>所以</p><p>你好，世界！</p><p>后续会陆陆续续把做过的一些项目和文档都搬运过来，嘿嘿。</p><p>希望能一直坚持下去吧！</p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 碎碎念 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
