<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试</title>
      <link href="/article/8257d2b5.html"/>
      <url>/article/8257d2b5.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这个是针对于知识工程的学习与进一步实践，个人感觉难度挺高的，前后花费了大概有三周的时间，第一周主要是解决依赖的各种报错问题，第二周主要用在数据集的裁切和平台迁移上（这个主要受制于gpu的内存不够），第三周主要用在调优思路的探索和实践上，花了这么长时间感觉还是跟学校的课程安排有关，以及现在已经快接近五月了，保研人应该都懂……各种夏令营的事情和课程大作业搞得有点晕头撞向的，因此只能尽自己最大努力利用时间来完成这个课程实践，最后嘛还是有许多遗憾，但只能止步于此了……</p><h1 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h1><h2 id="使用model-art平台"><a href="#使用model-art平台" class="headerlink" title="使用model art平台"></a>使用model art平台</h2><p>模型链接：</p><p><a href="https://github.com/OpenDriveLab/ViDAR">https://github.com/OpenDriveLab/ViDAR</a></p><p>前置：</p><p>配置model art镜像</p><p><img src="/article/undefined/fc91c387a9f5fa96a87e8662028e0c8.png" alt="fc91c387a9f5fa96a87e8662028e0c8"></p><p><img src="/article/undefined/image-20250401153203321.png" alt="image-20250401153203321"></p><p><img src="/article/undefined/image-20250401153223717.png" alt="image-20250401153223717"></p><p><img src="/article/undefined/image-20250401153259882.png" alt="image-20250401153259882"></p><p><img src="/article/undefined/image-20250401153426317.png" alt="image-20250401153426317"></p><p>通过以上步骤进行镜像配置，就不过多赘述了，当时的解释md文件被我删除了……</p><h2 id="遇到的问题以及解决方法"><a href="#遇到的问题以及解决方法" class="headerlink" title="遇到的问题以及解决方法"></a>遇到的问题以及解决方法</h2><ol><li><p>依赖报错问题：主要集中在numpy的版本上，因为model art本身要求的numpy版本较高，但是ViDAR又需要较低版本导致冲突，后面配置了一个脚本用于解决大部分问题：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim install_deps.sh</span><br></pre></td></tr></table></figure><p>然后：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置清华源</span></span><br><span class="line">PIP_SOURCE=<span class="string">&quot;-i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 临时移除 ModelArts SDK 以避免干扰</span></span><br><span class="line"><span class="built_in">export</span> ORIGINAL_PYTHONPATH=<span class="variable">$PYTHONPATH</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=$(<span class="built_in">echo</span> <span class="variable">$PYTHONPATH</span> | sed <span class="string">&#x27;s|/home/ma-user/modelarts-dev/modelarts-sdk||g&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印环境信息</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Checking Python and PyTorch versions...&quot;</span></span><br><span class="line">python -c <span class="string">&quot;import sys, torch; print(&#x27;Python:&#x27;, sys.version); print(&#x27;PyTorch:&#x27;, torch.__version__, &#x27;CUDA:&#x27;, torch.cuda.is_available())&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 1：修复依赖冲突</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Fixing dependency conflicts...&quot;</span></span><br><span class="line">pip install numpy==1.23.5 --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install networkx==2.2 --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install pyasn1==0.6.1 --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install pandas==1.2.5 --force-reinstall <span class="variable">$PIP_SOURCE</span>  <span class="comment"># 确保 pandas 版本</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 2：处理“平台不支持”包，降级到兼容版本</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Fixing platform compatibility issues...&quot;</span></span><br><span class="line">pip install mmengine</span><br><span class="line">pip install PyYAML==6.0 charset-normalizer==3.3.2 fonttools==4.38.0 kiwisolver==1.4.5 \</span><br><span class="line">    lxml==4.9.3 matplotlib==3.5.2 simplejson==3.19.2 MarkupSafe==2.1.5 \</span><br><span class="line">    cffi==1.16.0 greenlet==3.0.3 ijson==3.2.4 SQLAlchemy==2.0.30 \</span><br><span class="line">    --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 3：安装 mmcv-full==1.4.0</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing mmcv-full==1.4.0...&quot;</span></span><br><span class="line">pip install mmcv-full==1.4.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 4：安装 mmdet3d 剩余依赖</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing mmdet3d dependencies...&quot;</span></span><br><span class="line">pip install lyft_dataset_sdk nuscenes-devkit plyfile tensorboard numba==0.48.0 scikit-image==0.19.3 <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install numpy==1.23.5 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install mmcv-full==1.4.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 5：安装 mmdet==2.14.0 和 mmsegmentation==0.14.1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing mmdet==2.14.0 and mmsegmentation==0.14.1...&quot;</span></span><br><span class="line">pip install mmdet==2.14.0 <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install mmsegmentation==0.14.1 <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/open-mmlab/mmdetection3d.git</span><br><span class="line"><span class="built_in">cd</span> mmdetection3d</span><br><span class="line">git checkout v0.17.1 <span class="comment"># Other versions may not be compatible.</span></span><br><span class="line">python setup.py install</span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 6：安装 detectron2 和其他依赖</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing detectron2 and other dependencies...&quot;</span></span><br><span class="line">pip install einops fvcore seaborn iopath==0.1.9 timm==0.6.13 typing-extensions==4.5.0 \</span><br><span class="line">    pylint ipython==8.12 matplotlib==3.5.2 numba==0.48.0 setuptools==59.5.0 <span class="variable">$PIP_SOURCE</span></span><br><span class="line">python -m pip install <span class="string">&#x27;git+https://github.com/facebookresearch/detectron2.git&#x27;</span> <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 7：安装 ViDAR 和 chamferdistance</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing ViDAR and chamferdistance...&quot;</span></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="string">&quot;ViDAR&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    git <span class="built_in">clone</span> https://github.com/OpenDriveLab/ViDAR</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">cd</span> ViDAR</span><br><span class="line"><span class="built_in">mkdir</span> -p pretrained</span><br><span class="line"><span class="built_in">cd</span> pretrained</span><br><span class="line">wget https://github.com/zhiqi-li/storage/releases/download/v1.0/r101_dcn_fcos3d_pretrain.pth || <span class="built_in">echo</span> <span class="string">&quot;Pretrained model download failed, continuing...&quot;</span></span><br><span class="line"><span class="built_in">cd</span> ../third_lib/chamfer_dist/chamferdist/</span><br><span class="line">pip install . <span class="variable">$PIP_SOURCE</span></span><br><span class="line"><span class="built_in">cd</span> ../../..</span><br><span class="line">pip install matplotlib==3.5.3 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install pyparsing==2.4.7 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install kiwisolver==1.3.2 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install --user prettytable==3.7.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提示完成</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installation complete. If errors occurred, check logs above.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可选：隔离环境（注释掉，需手动启用</span></span><br><span class="line"><span class="comment"># echo &quot;If conflicts persist, consider creating a clean environment:&quot;</span></span><br><span class="line"><span class="comment"># echo &quot;conda create -n vidar_clean python=3.8&quot;</span></span><br><span class="line"><span class="comment"># echo &quot;conda activate vidar_clean&quot;</span></span><br><span class="line"><span class="comment"># echo &quot;Then rerun this script.&quot;</span></span><br></pre></td></tr></table></figure><p>然后就是喜闻乐见的一键解决问题了</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x install_deps.sh</span><br><span class="line">./install_deps.sh</span><br></pre></td></tr></table></figure><p>然后有两个地方需要修改：</p><p><img src="/article/undefined/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_2025-04-15_210139_539.png" alt="微信图片_2025-04-15_210139_539"></p><p><img src="/article/undefined/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_2025-04-15_210556_226.png" alt="微信图片_2025-04-15_210556_226"></p><p>之后到达vidar目录下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CONFIG=ViDAR/projects/configs/vidar_pretrain/OpenScene/vidar_OpenScene_train_1_8_3future.py GPU_NUM=1</span><br><span class="line"></span><br><span class="line">CONFIG=projects/configs/vidar_pretrain/OpenScene/vidar_OpenScene_mini_1_8_3future.py</span><br><span class="line"></span><br><span class="line">GPU_NUM=1</span><br><span class="line"></span><br><span class="line">./tools/dist_train.sh <span class="variable">$&#123;CONFIG&#125;</span> <span class="variable">$&#123;GPU_NUM&#125;</span>  </span><br></pre></td></tr></table></figure></li><li><p>数据集</p><p>使用openxlab软件包。注：最高版本openxlab需要python≥3.8，因此需要创建一个虚拟环境安装</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n openxlab python=3.9</span><br><span class="line">pip install openxlab</span><br><span class="line">openxlab login <span class="comment"># 需要创建openxlab账号之后，创建access key再在这里登录</span></span><br><span class="line"><span class="comment">#我的AK/SK放在代码块外面</span></span><br><span class="line">openxlab dataset download --dataset-repo OpenDriveLab/OpenScene --source-path /openscene-v1.1/openscene_sensor_mini_camera.tgz  --target-path .</span><br><span class="line">openxlab dataset download --dataset-repo OpenDriveLab/OpenScene --source-path /openscene-v1.1/openscene_sensor_mini_lidar.tgz  --target-path .</span><br></pre></td></tr></table></figure><p>Access Key: wgakjbrzyyxljprb1b2z Secret Key: rnyq568lwdpayblrb744qdmxyg4xz19vo3b0azog</p><p>然后用上面的指令解压。大概占据硬盘空间170GB左右，因为要解压所以硬盘建议大概250-300GB</p><p>数据集解压后自动移动 MergedPointCloud 到目标路径：</p><p>可以运行脚本vim fix_mergedpointcloud.py</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根目录路径（根据你实际目录修改）</span></span><br><span class="line">bad_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/OpenDriveLab___OpenScene/openscene-v1.1/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line">correct_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有 subdir</span></span><br><span class="line"><span class="keyword">for</span> subdir <span class="keyword">in</span> os.listdir(bad_root):</span><br><span class="line">    full_bad_path = os.path.join(bad_root, subdir, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line">    full_target_dir = os.path.join(correct_root, subdir)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(full_bad_path):</span><br><span class="line">        target_path = os.path.join(full_target_dir, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Moving <span class="subst">&#123;full_bad_path&#125;</span> --&gt; <span class="subst">&#123;target_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        os.makedirs(full_target_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(target_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  - Skipping <span class="subst">&#123;target_path&#125;</span> (already exists)&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            shutil.move(full_bad_path, target_path)</span><br></pre></td></tr></table></figure><p>执行：python fix_mergedpointcloud.py</p><p>或者创建软连接</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">bad_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/OpenDriveLab___OpenScene/openscene-v1.1/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line">correct_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sequence <span class="keyword">in</span> os.listdir(bad_root):</span><br><span class="line">    bad_mp = os.path.join(bad_root, sequence, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line">    correct_target_dir = os.path.join(correct_root, sequence)</span><br><span class="line">    correct_link_path = os.path.join(correct_target_dir, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(bad_mp):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(correct_target_dir):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;路径不存在，创建中：<span class="subst">&#123;correct_target_dir&#125;</span>&quot;</span>)</span><br><span class="line">            os.makedirs(correct_target_dir)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(correct_link_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;创建软链接：<span class="subst">&#123;correct_link_path&#125;</span> -&gt; <span class="subst">&#123;bad_mp&#125;</span>&quot;</span>)</span><br><span class="line">            os.symlink(os.path.abspath(bad_mp), correct_link_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;已存在：<span class="subst">&#123;correct_link_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>openscene_metadata_mini.tgz可以下载本地再直接上传</p><p>最后： <code>python tools/collect_nuplan_data.py mini</code></p></li><li><p>训练的一些报错</p><p><strong>ninja报错</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">RuntimeError: Ninja is required to load C++</span><br></pre></td></tr></table></figure><p>解决：从源码构建并本地安装</p><ol><li><p>下载和构建 Ninja：</p><ul><li><p>克隆 Ninja 官方仓库：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">git clone &lt;https://github.com/ninja-build/ninja.git&gt;</span><br><span class="line">cd ninja</span><br><span class="line">python configure.py --bootstrap</span><br></pre></td></tr></table></figure></li><li><p>这会生成 <code>ninja</code> 二进制文件。</p></li></ul></li><li><p>创建本地目录并移动文件：</p><ul><li><p>创建 <code>~/bin</code> 目录（如果不存在）：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">mkdir -p ~/bin</span><br></pre></td></tr></table></figure></li><li><p>将 <code>ninja</code> 二进制文件移动到 <code>~/bin</code>：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">mv ninja ~/bin/</span><br></pre></td></tr></table></figure></li></ul></li><li><p>更新 PATH 环境变量：</p><ul><li><p>临时添加至当前会话：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">export PATH=~/bin:$PATH</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>验证安装</strong>：</p><ul><li>运行 <code>ninja --version</code> 检查是否成功。</li></ul></li></ol><p><strong><code>crypt.h</code>报错</strong></p><p>解决：</p><ul><li><p>步骤 1：确认 glibc-2.27 源码</p><ul><li><p>确保你已从 <a href="https://ftp.gnu.org/gnu/glibc/glibc-2.27.tar.xz">GNU FTP 服务器</a> 下载并解压了 glibc-2.27.tar.xz 文件。如果未下载，使用以下命令：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ruby</span><br><span class="line">wget &lt;https://ftp.gnu.org/gnu/glibc/glibc-2.27.tar.xz&gt;</span><br><span class="line">tar -xJf glibc-2.27.tar.xz</span><br></pre></td></tr></table></figure></li><li><p>确认解压后生成了 <code>glibc-2.27</code> 目录，并包含 <code>include</code> 子目录。</p></li></ul><p>步骤 2：复制所有头文件</p><ul><li><p>将 glibc-2.27&#x2F;include 目录下的所有头文件复制到你的本地 ~&#x2F;include 目录，以确保所有依赖头文件（如 <code>features.h</code>、<code>stdint.h</code> 等）都可用：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">mkdir -p ~/include</span><br><span class="line">cp -r glibc-2.27/include/* ~/include/</span><br></pre></td></tr></table></figure></li><li><p>这将复制包括 <code>crypt.h</code> 在内的所有头文件到 ~&#x2F;include，确保编译器能找到所有必需的依赖。</p></li></ul><p>步骤 3：设置包含路径</p><ul><li><p>设置 <code>CPLUS_INCLUDE_PATH</code> 环境变量，确保编译器优先搜索 ~&#x2F;include 目录：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">export CPLUS_INCLUDE_PATH=~/include:$CPLUS_INCLUDE_PATH</span><br></pre></td></tr></table></figure></li><li><p>验证环境变量设置：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">echo $CPLUS_INCLUDE_PATH</span><br></pre></td></tr></table></figure><p>应包含 <code>~/include</code>。</p></li></ul><p>步骤 4：检查系统头文件</p><p>首先，检查你的环境中是否已有必要的头文件：</p><ul><li><p>运行 </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ls /usr/include/crypt.h</span><br></pre></td></tr></table></figure><p> 查看是否已有 </p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">crypt.h</span><br></pre></td></tr></table></figure><p>。如果存在，尝试使用系统编译器：</p><ul><li>运行 <code>export CC=/usr/bin/gcc</code> 和 <code>export CXX=/usr/bin/g++</code>。</li><li>然后取消设置 <code>CPLUS_INCLUDE_PATH</code>：<code>unset CPLUS_INCLUDE_PATH</code>。</li><li>重新运行训练脚本：<code>./tools/dist_train.sh $&#123;CONFIG&#125; $&#123;GPU_NUM&#125;</code>。</li></ul></li></ul></li></ul><p><strong>GLIBCXX_3.4.29报错</strong></p><p>参考：</p><p>[如何解决version &#96;GLIBCXX_3.4.29‘ not found的问题_glibcxx not found-CSDN博客](<a href="https://blog.csdn.net/weixin_39379635/article/details/129159713">https://blog.csdn.net/weixin_39379635/article/details/129159713</a>)</p><p><strong>解决：</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ImportError: /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6: version `GLIBCXX_3.4.29&#x27; not found</span><br></pre></td></tr></table></figure><p>1、使用指令先看下系统目前都有哪些版本的</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strings /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6 | grep GLIBCXX</span><br></pre></td></tr></table></figure><p>发现只到3.4.22</p><p>2、来查看当前系统中其它的同类型文件，</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo find / -name &quot;libstdc++.so.6*&quot;</span><br></pre></td></tr></table></figure><p>找到一个版本比较高的 &#x2F;home&#x2F;ma-user&#x2F;anaconda3&#x2F;envs&#x2F;vidar&#x2F;lib&#x2F;libstdc++.so.6.0.29</p><p>查看</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strings /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6.0.29 | grep GLIBCXX</span><br></pre></td></tr></table></figure><p>有了3.4.29</p><p>3、复制到指定目录并建立新的链接</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">复制</span><br><span class="line">sudo cp /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6.0.29 /home/ma-user/anaconda3/envs/vidar/lib/</span><br><span class="line"></span><br><span class="line">删除之前链接</span><br><span class="line">sudo rm /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6</span><br><span class="line"></span><br><span class="line">创建新的链接</span><br><span class="line">sudo ln -s /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6.0.29 /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6</span><br></pre></td></tr></table></figure><p>验证</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strings /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6 | grep GLIBCXX</span><br></pre></td></tr></table></figure><p>有了3.4.29</p><p><strong>另：如果是&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libstdc++.so.6报错，使用：</strong></p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure><p><strong>GPU爆内存</strong></p><p>cuda out of memory</p><p>只训练mini数据集的一部分，注意留的数据meta_datas里的文件夹名字和sensor_blobs里文件夹名对应</p><p><strong>fsspec 与 Python 3.8 兼容性问题</strong></p><p>TypeError: ‘type’ object is not subscriptable</p><p>解决方法：降低到fsspec可以兼容3.8的版本</p><p>pip install fsspec&#x3D;&#x3D;2025.3.0</p></li></ol><h2 id="ViDAR模型实现分析"><a href="#ViDAR模型实现分析" class="headerlink" title="ViDAR模型实现分析"></a>ViDAR模型实现分析</h2><h3 id="模型架构概述"><a href="#模型架构概述" class="headerlink" title="模型架构概述"></a>模型架构概述</h3><p>ViDAR（Visual Point Cloud Forecasting enables Scalable Autonomous Driving）是一个基于BEVFormer架构的模型，专注于自动驾驶场景中的视觉点云预测。从 <code>vidar_transformer.py</code> 文件可以看出，它主要实现了一个预测变换器（PredictionTransformer）。</p><h3 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h3><ol><li>PredictionTransformer ：<ul><li>这是ViDAR的核心组件，用于从多帧BEV特征预测下一帧的BEV特征</li><li>使用了自定义的解码器来处理时序信息</li></ul></li><li>注意力机制 ：<ul><li>时间自注意力（TemporalSelfAttention）：处理时间维度上的信息</li><li>空间交叉注意力（MSDeformableAttention3D）：处理3D空间中的信息</li><li>自定义可变形注意力（CustomMSDeformableAttention）：用于处理特征对齐</li></ul></li></ol><h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><p>项目结构显示ViDAR是基于BEVFormer进行扩展的：</p><p>projects&#x2F;<br>├── configs&#x2F;<br>│   ├── <em>base</em>&#x2F;<br>│   ├── bevformer&#x2F;<br>│   ├── vidar_finetune&#x2F;    # ViDAR微调配置<br>│   └── vidar_pretrain&#x2F;    # ViDAR预训练配置<br>└── mmdet3d_plugin&#x2F;<br>    ├── bevformer&#x2F;         # BEVFormer相关模块<br>    ├── core&#x2F;              # 核心评估和功能模块<br>    ├── datasets&#x2F;          # 数据集处理<br>    ├── dd3d&#x2F;              # 3D检测相关模块<br>    └── models&#x2F;            # 模型定义</p><h3 id="与BEVFormer的关系"><a href="#与BEVFormer的关系" class="headerlink" title="与BEVFormer的关系"></a>与BEVFormer的关系</h3><p>ViDAR似乎是在BEVFormer基础上的扩展，专注于未来帧预测：</p><ul><li>BEVFormer主要关注多视角图像到BEV表示的转换</li><li>ViDAR则进一步关注BEV表示的时序预测，实现对未来场景的预测</li></ul><h2 id="调优思路"><a href="#调优思路" class="headerlink" title="调优思路"></a>调优思路</h2><h3 id="融合Nskg"><a href="#融合Nskg" class="headerlink" title="融合Nskg"></a>融合Nskg</h3><p>写在前面：</p><p>这个项目其实没有想象的复杂，大概如下：</p><p>ViDAR模型似乎是一个基于BEVFormer架构的3D检测&#x2F;分割模型，它利用MMDetection3D框架实现，支持多视角图像到BEV表示的转换。该模型具有灵活的配置系统、插件扩展能力和完善的训练功能。</p><p>那么有了以上信息就好做了，首先学习下MMDetection3D的使用方法，Vidar只不过在上面多封装了一层，那么这一层应该也可以写插件进行拓展</p><p>核心目录：</p><ol><li>模型定义文件（可能在 projects&#x2F;mmdet3d_plugin&#x2F;bevformer&#x2F; 目录下）</li><li>配置文件（通过命令行参数 config 指定）</li><li>自定义训练函数 custom_train_model 的实现</li></ol><ul><li><p>论文1：nuScenes Knowledge Graph (nSKG)</p><p><strong>nuScenes Knowledge Graph (nSKG)</strong> 文章的内容可以很好地融入对 <strong>ViDAR: Visual Point Cloud Forecasting</strong> 模型的理解和调优中，尤其是在以下几个方面：</p><ol><li><strong>丰富场景表示</strong>：nSKG 提供了 nuScenes 数据集的综合语义表示，包含交通场景中的实体（如车辆、行人、车道、交通信号灯）和它们之间的语义与空间关系。这可以增强 ViDAR 的输入数据，改善其点云预测和下游任务（如感知、规划）的性能。</li><li><strong>数据处理改进</strong>：nSKG 的结构化数据（以知识图谱和 PyTorch Geometric 格式提供）可以直接用于 ViDAR 的数据管道，减少数据预处理的工程负担。</li><li><strong>模型架构增强</strong>：nSKG 的异构图表示可以与 ViDAR 的 Transformer 或 BEVFormer 模块结合，引入图神经网络（GNN）来处理语义关系，提升预测的鲁棒性和可解释性。</li><li><strong>调优方向</strong>：利用 nSKG 的丰富上下文（如车道拓扑、代理关系），可以优化 ViDAR 的超参数、数据增强策略和损失函数，特别是在处理复杂交通场景时。</li></ol><p>以下，我将详细说明如何将 nSKG 的内容融入 ViDAR 的运行原理、功能组成部分和调优策略，并结合您提供的 work_dirs&#x2F;vidar_OpenScene_mini_1_8_3future 目录和之前的讨论。</p></li></ul><p>实际修改：</p><p><img src="/article/undefined/e879ac0c92d040202e3ba7450e5459b.png" alt="e879ac0c92d040202e3ba7450e5459b"></p><h1 id="ViDAR项目集成nSTP的工作总结"><a href="#ViDAR项目集成nSTP的工作总结" class="headerlink" title="ViDAR项目集成nSTP的工作总结"></a>ViDAR项目集成nSTP的工作总结</h1><p>根据当前代码库，我将总结从初始状态到现在为止，为了集成nSTP（Neural Scene-Time Priors）所做的工作。</p><h2 id="1-核心文件创建"><a href="#1-核心文件创建" class="headerlink" title="1. 核心文件创建"></a>1. 核心文件创建</h2><h3 id="1-1-nSTP编码器模块"><a href="#1-1-nSTP编码器模块" class="headerlink" title="1.1 nSTP编码器模块"></a>1.1 nSTP编码器模块</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\bevformer\modules\nstp_encoder.py</code></p><p><strong>主要功能</strong>:</p><ul><li>创建了<code>NSTPEncoder</code>类：使用图神经网络（GraphSAGE或GAT）处理nSTP图数据</li><li>创建了<code>NSTPEnhancer</code>类：将nSTP特征与BEV特征融合，通过注意力机制增强BEV特征</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GraphSAGE, GATConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NSTPEncoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;nSTP图数据编码器&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, hidden_channels, out_channels, num_layers=<span class="number">3</span>, </span></span><br><span class="line"><span class="params">                 gnn_type=<span class="string">&#x27;graphsage&#x27;</span>, dropout=<span class="number">0.1</span>, aggr=<span class="string">&#x27;mean&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.in_channels = in_channels</span><br><span class="line">        <span class="variable language_">self</span>.hidden_channels = hidden_channels</span><br><span class="line">        <span class="variable language_">self</span>.out_channels = out_channels</span><br><span class="line">        <span class="variable language_">self</span>.num_layers = num_layers</span><br><span class="line">        <span class="variable language_">self</span>.gnn_type = gnn_type</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输入特征投影</span></span><br><span class="line">        <span class="variable language_">self</span>.input_proj = nn.Linear(in_channels, hidden_channels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 图神经网络</span></span><br><span class="line">        <span class="keyword">if</span> gnn_type == <span class="string">&#x27;graphsage&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.gnn = GraphSAGE(</span><br><span class="line">                in_channels=hidden_channels,</span><br><span class="line">                hidden_channels=hidden_channels,</span><br><span class="line">                num_layers=num_layers,</span><br><span class="line">                out_channels=out_channels,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                aggr=aggr</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">elif</span> gnn_type == <span class="string">&#x27;gat&#x27;</span>:</span><br><span class="line">            <span class="comment"># 简化版GAT实现</span></span><br><span class="line">            <span class="variable language_">self</span>.gnn_layers = nn.ModuleList()</span><br><span class="line">            <span class="variable language_">self</span>.gnn_layers.append(GATConv(hidden_channels, hidden_channels))</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_layers - <span class="number">2</span>):</span><br><span class="line">                <span class="variable language_">self</span>.gnn_layers.append(GATConv(hidden_channels, hidden_channels))</span><br><span class="line">            <span class="variable language_">self</span>.gnn_layers.append(GATConv(hidden_channels, out_channels))</span><br><span class="line">            <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;不支持的GNN类型: <span class="subst">&#123;gnn_type&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            data: PyG Data对象或包含x和edge_index的字典</span></span><br><span class="line"><span class="string">                </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            torch.Tensor: 节点特征</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 添加对None的处理</span></span><br><span class="line">        <span class="keyword">if</span> data <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 返回一个空的特征张量</span></span><br><span class="line">            <span class="keyword">return</span> torch.zeros((<span class="number">1</span>, <span class="variable language_">self</span>.out_channels), device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(data, <span class="string">&#x27;x&#x27;</span>) <span class="keyword">and</span> <span class="built_in">hasattr</span>(data, <span class="string">&#x27;edge_index&#x27;</span>):</span><br><span class="line">            x, edge_index = data.x, data.edge_index</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&#x27;x&#x27;</span> <span class="keyword">in</span> data <span class="keyword">and</span> <span class="string">&#x27;edge_index&#x27;</span> <span class="keyword">in</span> data:</span><br><span class="line">            x, edge_index = data[<span class="string">&#x27;x&#x27;</span>], data[<span class="string">&#x27;edge_index&#x27;</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;警告: 输入数据格式不正确: <span class="subst">&#123;<span class="built_in">type</span>(data)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="comment"># 返回一个空的特征张量</span></span><br><span class="line">            <span class="keyword">return</span> torch.zeros((<span class="number">1</span>, <span class="variable language_">self</span>.out_channels), device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 确保x和edge_index是张量</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, torch.Tensor):</span><br><span class="line">            x = torch.tensor(x, dtype=torch.<span class="built_in">float</span>, device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(edge_index, torch.Tensor):</span><br><span class="line">            edge_index = torch.tensor(edge_index, dtype=torch.long, device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># 特征投影</span></span><br><span class="line">        x = <span class="variable language_">self</span>.input_proj(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 图神经网络处理</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.gnn_type == <span class="string">&#x27;graphsage&#x27;</span>:</span><br><span class="line">            x = <span class="variable language_">self</span>.gnn(x, edge_index)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># gat</span></span><br><span class="line">            <span class="keyword">for</span> i, layer <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.gnn_layers):</span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(<span class="variable language_">self</span>.gnn_layers) - <span class="number">1</span>:</span><br><span class="line">                    x = layer(x, edge_index)</span><br><span class="line">                    x = torch.relu(x)</span><br><span class="line">                    x = <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    x = layer(x, edge_index)</span><br><span class="line">                    </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NSTPEnhancer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;nSTP特征增强器，用于增强BEV特征&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, bev_channels, nstp_channels, hidden_channels, bev_h, bev_w, use_attention=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.bev_channels = bev_channels</span><br><span class="line">        <span class="variable language_">self</span>.nstp_channels = nstp_channels</span><br><span class="line">        <span class="variable language_">self</span>.hidden_channels = hidden_channels</span><br><span class="line">        <span class="variable language_">self</span>.bev_h = bev_h</span><br><span class="line">        <span class="variable language_">self</span>.bev_w = bev_w</span><br><span class="line">        <span class="variable language_">self</span>.use_attention = use_attention</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征融合层</span></span><br><span class="line">        <span class="variable language_">self</span>.nstp_proj = nn.Linear(nstp_channels, hidden_channels)</span><br><span class="line">        <span class="variable language_">self</span>.bev_proj = nn.Linear(bev_channels, hidden_channels)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> use_attention:</span><br><span class="line">            <span class="comment"># 注意力机制</span></span><br><span class="line">            <span class="variable language_">self</span>.query_proj = nn.Linear(hidden_channels, hidden_channels)</span><br><span class="line">            <span class="variable language_">self</span>.key_proj = nn.Linear(hidden_channels, hidden_channels)</span><br><span class="line">            <span class="variable language_">self</span>.value_proj = nn.Linear(hidden_channels, hidden_channels)</span><br><span class="line">            <span class="variable language_">self</span>.attention_scale = hidden_channels ** -<span class="number">0.5</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 输出投影</span></span><br><span class="line">        <span class="variable language_">self</span>.output_proj = nn.Linear(hidden_channels, bev_channels)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, bev_feat, nstp_feat, nstp_pos=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            bev_feat (torch.Tensor): BEV特征 [B, C, H, W]</span></span><br><span class="line"><span class="string">            nstp_feat (torch.Tensor): nSTP节点特征 [B, N, C]</span></span><br><span class="line"><span class="string">            nstp_pos (torch.Tensor, optional): nSTP节点位置 [B, N, 2]</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            torch.Tensor: 增强后的BEV特征 [B, C, H, W]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, C, H, W = bev_feat.shape</span><br><span class="line">        bev_feat_flat = bev_feat.flatten(<span class="number">2</span>).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># [B, H*W, C]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征投影</span></span><br><span class="line">        bev_feat_proj = <span class="variable language_">self</span>.bev_proj(bev_feat_flat)  <span class="comment"># [B, H*W, hidden]</span></span><br><span class="line">        nstp_feat_proj = <span class="variable language_">self</span>.nstp_proj(nstp_feat)  <span class="comment"># [B, N, hidden]</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_attention:</span><br><span class="line">            <span class="comment"># 计算注意力</span></span><br><span class="line">            query = <span class="variable language_">self</span>.query_proj(bev_feat_proj)  <span class="comment"># [B, H*W, hidden]</span></span><br><span class="line">            key = <span class="variable language_">self</span>.key_proj(nstp_feat_proj)  <span class="comment"># [B, N, hidden]</span></span><br><span class="line">            value = <span class="variable language_">self</span>.value_proj(nstp_feat_proj)  <span class="comment"># [B, N, hidden]</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 注意力分数</span></span><br><span class="line">            attn = torch.bmm(query, key.transpose(<span class="number">1</span>, <span class="number">2</span>)) * <span class="variable language_">self</span>.attention_scale  <span class="comment"># [B, H*W, N]</span></span><br><span class="line">            attn = torch.softmax(attn, dim=-<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 加权特征</span></span><br><span class="line">            context = torch.bmm(attn, value)  <span class="comment"># [B, H*W, hidden]</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 融合特征</span></span><br><span class="line">            enhanced_feat = context + bev_feat_proj</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 简单平均</span></span><br><span class="line">            nstp_feat_expanded = nstp_feat_proj.mean(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>).expand(-<span class="number">1</span>, H*W, -<span class="number">1</span>)</span><br><span class="line">            enhanced_feat = bev_feat_proj + nstp_feat_expanded</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 输出投影</span></span><br><span class="line">        enhanced_feat = <span class="variable language_">self</span>.output_proj(enhanced_feat)  <span class="comment"># [B, H*W, C]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 重塑为BEV特征</span></span><br><span class="line">        enhanced_feat = enhanced_feat.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>).reshape(B, C, H, W)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> enhanced_feat</span><br></pre></td></tr></table></figure><h3 id="1-2-nSTP数据处理组件"><a href="#1-2-nSTP数据处理组件" class="headerlink" title="1.2 nSTP数据处理组件"></a>1.2 nSTP数据处理组件</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\datasets\pipelines\nstp_transform.py</code></p><p><strong>主要功能</strong>:</p><ul><li>创建了<code>ProcessNSTPGraph</code>类：处理nSTP图数据，确保格式正确并转换为PyTorch张量</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mmdet.datasets.builder <span class="keyword">import</span> PIPELINES</span><br><span class="line"></span><br><span class="line"><span class="meta">@PIPELINES.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProcessNSTPGraph</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;处理nSTP图数据的转换组件&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, graph_feat_dim=<span class="number">64</span>, with_agent_type=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.graph_feat_dim = graph_feat_dim</span><br><span class="line">        <span class="variable language_">self</span>.with_agent_type = with_agent_type</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, results</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;处理nSTP图数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;nstp_graph&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> results:</span><br><span class="line">            <span class="keyword">return</span> results</span><br><span class="line">            </span><br><span class="line">        graph_data = results[<span class="string">&#x27;nstp_graph&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 处理PyG Data对象</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(graph_data, <span class="string">&#x27;x&#x27;</span>) <span class="keyword">and</span> <span class="built_in">hasattr</span>(graph_data, <span class="string">&#x27;edge_index&#x27;</span>):</span><br><span class="line">            <span class="comment"># 已经是PyG Data对象，确保张量类型正确</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(graph_data.x, torch.Tensor):</span><br><span class="line">                graph_data.x = torch.tensor(graph_data.x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(graph_data.edge_index, torch.Tensor):</span><br><span class="line">                graph_data.edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hasattr</span>(graph_data, <span class="string">&#x27;edge_attr&#x27;</span>) <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(graph_data.edge_attr, torch.Tensor):</span><br><span class="line">                graph_data.edge_attr = torch.tensor(graph_data.edge_attr, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># 处理字典格式的图数据</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(graph_data, <span class="built_in">dict</span>):</span><br><span class="line">            <span class="comment"># 处理节点特征</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;x&#x27;</span> <span class="keyword">in</span> graph_data:</span><br><span class="line">                x = graph_data[<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, np.ndarray):</span><br><span class="line">                    x = torch.from_numpy(x).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(x, <span class="built_in">list</span>):</span><br><span class="line">                    x = torch.tensor(x).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, torch.Tensor):</span><br><span class="line">                    x = torch.tensor(x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">                graph_data[<span class="string">&#x27;x&#x27;</span>] = x</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 处理边索引</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;edge_index&#x27;</span> <span class="keyword">in</span> graph_data:</span><br><span class="line">                edge_index = graph_data[<span class="string">&#x27;edge_index&#x27;</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(edge_index, np.ndarray):</span><br><span class="line">                    edge_index = torch.from_numpy(edge_index).long()</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(edge_index, <span class="built_in">list</span>):</span><br><span class="line">                    edge_index = torch.tensor(edge_index).long()</span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(edge_index, torch.Tensor):</span><br><span class="line">                    edge_index = torch.tensor(edge_index, dtype=torch.long)</span><br><span class="line">                graph_data[<span class="string">&#x27;edge_index&#x27;</span>] = edge_index</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 处理边属性</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;edge_attr&#x27;</span> <span class="keyword">in</span> graph_data:</span><br><span class="line">                edge_attr = graph_data[<span class="string">&#x27;edge_attr&#x27;</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(edge_attr, np.ndarray):</span><br><span class="line">                    edge_attr = torch.from_numpy(edge_attr).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(edge_attr, <span class="built_in">list</span>):</span><br><span class="line">                    edge_attr = torch.tensor(edge_attr).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(edge_attr, torch.Tensor):</span><br><span class="line">                    edge_attr = torch.tensor(edge_attr, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">                graph_data[<span class="string">&#x27;edge_attr&#x27;</span>] = edge_attr</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新结果</span></span><br><span class="line">        results[<span class="string">&#x27;nstp_graph&#x27;</span>] = graph_data</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure><h2 id="2-现有文件修改"><a href="#2-现有文件修改" class="headerlink" title="2. 现有文件修改"></a>2. 现有文件修改</h2><h3 id="2-1-数据集类修改"><a href="#2-1-数据集类修改" class="headerlink" title="2.1 数据集类修改"></a>2.1 数据集类修改</h3><h4 id="2-1-1-NuScenes数据集"><a href="#2-1-1-NuScenes数据集" class="headerlink" title="2.1.1 NuScenes数据集"></a>2.1.1 NuScenes数据集</h4><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\datasets\nuscenes_vidar_dataset_v1.py</code></p><p><strong>主要修改</strong>:</p><ul><li>添加了nSTP相关参数：<code>use_nstp</code>, <code>nstp_path</code></li><li>实现了<code>_load_nstp_data</code>方法：加载nSTP图数据文件</li><li>修改了<code>get_data_info</code>方法：将nSTP数据添加到样本信息中</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"><span class="comment"># Visual Point Cloud Forecasting enables Scalable Autonomous Driving              #</span></span><br><span class="line"><span class="comment"># Copyright (c) OpenDriveLab. All rights reserved.                                #</span></span><br><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入rdflib</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> rdflib <span class="keyword">import</span> Graph</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;警告: 未安装rdflib库，无法加载.ttl格式的nSKG数据&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mmdet.datasets <span class="keyword">import</span> DATASETS</span><br><span class="line"><span class="keyword">from</span> nuscenes.<span class="built_in">eval</span>.common.utils <span class="keyword">import</span> quaternion_yaw, Quaternion</span><br><span class="line"><span class="keyword">from</span> nuscenes.utils.geometry_utils <span class="keyword">import</span> transform_matrix</span><br><span class="line"><span class="keyword">from</span> mmcv.parallel <span class="keyword">import</span> DataContainer <span class="keyword">as</span> DC</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> .nuscenes_vidar_dataset_template <span class="keyword">import</span> NuScenesViDARDatasetTemplate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@DATASETS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NuScenesViDARDatasetV1</span>(<span class="title class_ inherited__">NuScenesViDARDatasetTemplate</span>):  <span class="comment"># 确保类名为NuScenesViDARDatasetV1</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;NuScenes visual point cloud forecasting dataset.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 ann_file,</span></span><br><span class="line"><span class="params">                 pipeline=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 data_root=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 classes=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 load_interval=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 modality=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 box_type_3d=<span class="string">&#x27;LiDAR&#x27;</span>,</span></span><br><span class="line"><span class="params">                 filter_empty_gt=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 test_mode=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 use_valid_flag=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 history_queue_length=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 pred_history_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 pred_future_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 per_frame_loss_weight=(<span class="params"><span class="number">1.0</span>,</span>),</span></span><br><span class="line"><span class="params">                 use_nskg=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 nskg_path=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 nskg_ontology_path=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 use_nstp=<span class="literal">False</span>,  <span class="comment"># 添加nSTP支持参数</span></span></span><br><span class="line"><span class="params">                 nstp_path=<span class="literal">None</span>,  <span class="comment"># 添加nSTP数据路径参数</span></span></span><br><span class="line"><span class="params">                 **kwargs</span>):</span><br><span class="line">        <span class="comment"># 保存history_queue_length参数，但不传递给父类</span></span><br><span class="line">        <span class="variable language_">self</span>.history_queue_length = history_queue_length</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 调用父类初始化方法，移除history_queue_length参数</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            ann_file=ann_file,</span><br><span class="line">            pipeline=pipeline,</span><br><span class="line">            data_root=data_root,</span><br><span class="line">            classes=classes,</span><br><span class="line">            load_interval=load_interval,</span><br><span class="line">            modality=modality,</span><br><span class="line">            box_type_3d=box_type_3d,</span><br><span class="line">            filter_empty_gt=filter_empty_gt,</span><br><span class="line">            test_mode=test_mode,</span><br><span class="line">            use_valid_flag=use_valid_flag,</span><br><span class="line">            **kwargs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存nSKG相关参数</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nskg = use_nskg</span><br><span class="line">        <span class="variable language_">self</span>.nskg_path = nskg_path</span><br><span class="line">        <span class="variable language_">self</span>.nskg_ontology_path = nskg_ontology_path</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存nSTP相关参数</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nstp = use_nstp</span><br><span class="line">        <span class="variable language_">self</span>.nstp_path = nstp_path</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存预测帧数相关参数</span></span><br><span class="line">        <span class="variable language_">self</span>.pred_history_frame_num = pred_history_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.pred_future_frame_num = pred_future_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.per_frame_loss_weight = per_frame_loss_weight</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSKG，加载相关数据</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="variable language_">self</span>._load_nskg_data()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_load_nskg_data</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载nSKG数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.nskg_data = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="variable language_">self</span>.nskg_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;警告: nSKG数据路径 <span class="subst">&#123;self.nskg_path&#125;</span> 不存在&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nskg = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.nskg_path.endswith(<span class="string">&#x27;.ttl&#x27;</span>) <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_ontology_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                g = Graph()</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    g.parse(<span class="variable language_">self</span>.nskg_path, <span class="built_in">format</span>=<span class="string">&#x27;turtle&#x27;</span>)</span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;警告: TTL文件解析失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="variable language_">self</span>.use_nskg = <span class="literal">False</span></span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 加载本体文件</span></span><br><span class="line">                <span class="keyword">if</span> os.path.exists(<span class="variable language_">self</span>.nskg_ontology_path):</span><br><span class="line">                    <span class="keyword">for</span> onto_file <span class="keyword">in</span> os.listdir(<span class="variable language_">self</span>.nskg_ontology_path):</span><br><span class="line">                        <span class="keyword">if</span> onto_file.endswith(<span class="string">&#x27;.ttl&#x27;</span>):</span><br><span class="line">                            onto_path = os.path.join(<span class="variable language_">self</span>.nskg_ontology_path, onto_file)</span><br><span class="line">                            <span class="keyword">try</span>:</span><br><span class="line">                                g.parse(onto_path, <span class="built_in">format</span>=<span class="string">&#x27;turtle&#x27;</span>)</span><br><span class="line">                            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                                <span class="built_in">print</span>(<span class="string">f&quot;警告: 本体文件 <span class="subst">&#123;onto_file&#125;</span> 解析失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;成功加载nSKG数据，共 <span class="subst">&#123;<span class="built_in">len</span>(g)&#125;</span> 个三元组&quot;</span>)</span><br><span class="line">                <span class="variable language_">self</span>.nskg_data = <span class="variable language_">self</span>._convert_rdf_to_pyg(g)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">import</span> pickle</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(<span class="variable language_">self</span>.nskg_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    <span class="variable language_">self</span>.nskg_data = pickle.load(f)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;成功加载nSKG数据，共 <span class="subst">&#123;<span class="built_in">len</span>(self.nskg_data)&#125;</span> 条记录&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;加载nSKG数据失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;继续训练，但不使用nSKG数据&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nskg = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_convert_rdf_to_pyg</span>(<span class="params">self, graph</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;将RDF图转换为PyG格式</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            graph: RDF图对象</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            转换后的数据字典，键为sample_token</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result = &#123;&#125;</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">import</span> torch_geometric <span class="keyword">as</span> pyg</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 查询所有场景</span></span><br><span class="line">            scenes = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> s, p, o <span class="keyword">in</span> graph.triples((<span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>)):</span><br><span class="line">                <span class="comment"># 假设每个场景都有一个token属性</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">str</span>(p).endswith(<span class="string">&#x27;hasToken&#x27;</span>):</span><br><span class="line">                    scene_uri = <span class="built_in">str</span>(s)</span><br><span class="line">                    token = <span class="built_in">str</span>(o)</span><br><span class="line">                    scenes[scene_uri] = token</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 为每个场景构建图</span></span><br><span class="line">            <span class="keyword">for</span> scene_uri, token <span class="keyword">in</span> scenes.items():</span><br><span class="line">                <span class="comment"># 收集节点</span></span><br><span class="line">                nodes = &#123;&#125;</span><br><span class="line">                node_types = &#123;&#125;</span><br><span class="line">                node_features = &#123;&#125;</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 收集边</span></span><br><span class="line">                edges = &#123;&#125;</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 查询与场景相关的所有三元组</span></span><br><span class="line">                <span class="keyword">for</span> s, p, o <span class="keyword">in</span> graph.triples((<span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>)):</span><br><span class="line">                    <span class="comment"># 处理节点和边的逻辑...</span></span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 构建PyG数据对象</span></span><br><span class="line">                data = &#123;</span><br><span class="line">                    <span class="string">&#x27;x&#x27;</span>: node_features,</span><br><span class="line">                    <span class="string">&#x27;edge_index&#x27;</span>: edges,</span><br><span class="line">                    <span class="string">&#x27;node_type&#x27;</span>: node_types</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                result[token] = data</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">except</span> ImportError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;警告: 未安装PyTorch Geometric库，无法转换RDF数据为图格式&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_data_info</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;获取数据信息，添加nSKG或nSTP数据&quot;&quot;&quot;</span></span><br><span class="line">        info = <span class="built_in">super</span>().get_data_info(index)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取当前样本的标识符</span></span><br><span class="line">        sample_token = info.get(<span class="string">&#x27;sample_token&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSKG，添加nSKG数据到info中</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg <span class="keyword">and</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>, <span class="string">&#x27;nskg_data&#x27;</span>) <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_data <span class="keyword">and</span> sample_token <span class="keyword">in</span> <span class="variable language_">self</span>.nskg_data:</span><br><span class="line">            info[<span class="string">&#x27;nskg_graph&#x27;</span>] = <span class="variable language_">self</span>.nskg_data[sample_token]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSTP，添加nSTP数据到info中（优先使用nSTP）</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nstp <span class="keyword">and</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>, <span class="string">&#x27;nstp_data&#x27;</span>) <span class="keyword">and</span> <span class="variable language_">self</span>.nstp_data <span class="keyword">and</span> sample_token <span class="keyword">in</span> <span class="variable language_">self</span>.nstp_data:</span><br><span class="line">            info[<span class="string">&#x27;nstp_graph&#x27;</span>] = <span class="variable language_">self</span>.nstp_data[sample_token]</span><br><span class="line">            <span class="comment"># 如果同时存在nSKG和nSTP，使用nSTP替代nSKG</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;nskg_graph&#x27;</span> <span class="keyword">in</span> info:</span><br><span class="line">                <span class="keyword">del</span> info[<span class="string">&#x27;nskg_graph&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> info</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_mask_points</span>(<span class="params">self, pts_list</span>):</span><br><span class="line">        <span class="keyword">assert</span> <span class="variable language_">self</span>.ego_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">        <span class="comment"># remove points belonging to ego vehicle.</span></span><br><span class="line">        masked_pts_list = []</span><br><span class="line">        <span class="keyword">for</span> pts <span class="keyword">in</span> pts_list:</span><br><span class="line">            ego_mask = np.logical_and(</span><br><span class="line">                np.logical_and(<span class="variable language_">self</span>.ego_mask[<span class="number">0</span>] &lt;= pts[:, <span class="number">0</span>],</span><br><span class="line">                               <span class="variable language_">self</span>.ego_mask[<span class="number">2</span>] &gt;= pts[:, <span class="number">0</span>]),</span><br><span class="line">                np.logical_and(<span class="variable language_">self</span>.ego_mask[<span class="number">1</span>] &lt;= pts[:, <span class="number">1</span>],</span><br><span class="line">                               <span class="variable language_">self</span>.ego_mask[<span class="number">3</span>] &gt;= pts[:, <span class="number">1</span>]),</span><br><span class="line">            )</span><br><span class="line">            pts = pts[np.logical_not(ego_mask)]</span><br><span class="line">            masked_pts_list.append(pts)</span><br><span class="line">        pts_list = masked_pts_list</span><br><span class="line">        <span class="keyword">return</span> pts_list</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">union2one</span>(<span class="params">self, previous_queue, future_queue</span>):</span><br><span class="line">        <span class="comment"># 1. get transformation from all frames to current (reference) frame</span></span><br><span class="line">        ref_meta = previous_queue[-<span class="number">1</span>][<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line">        valid_scene_token = ref_meta[<span class="string">&#x27;scene_token&#x27;</span>]</span><br><span class="line">        <span class="comment"># compute reference e2g_transform and g2e_transform.</span></span><br><span class="line">        ref_e2g_translation = ref_meta[<span class="string">&#x27;ego2global_translation&#x27;</span>]</span><br><span class="line">        ref_e2g_rotation = ref_meta[<span class="string">&#x27;ego2global_rotation&#x27;</span>]</span><br><span class="line">        ref_e2g_transform = transform_matrix(</span><br><span class="line">            ref_e2g_translation, Quaternion(ref_e2g_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">        ref_g2e_transform = transform_matrix(</span><br><span class="line">            ref_e2g_translation, Quaternion(ref_e2g_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line">        ref_l2e_translation = ref_meta[<span class="string">&#x27;lidar2ego_translation&#x27;</span>]</span><br><span class="line">        ref_l2e_rotation = ref_meta[<span class="string">&#x27;lidar2ego_rotation&#x27;</span>]</span><br><span class="line">        ref_l2e_transform = transform_matrix(</span><br><span class="line">            ref_l2e_translation, Quaternion(ref_l2e_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">        ref_e2l_transform = transform_matrix(</span><br><span class="line">            ref_l2e_translation, Quaternion(ref_l2e_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        queue = previous_queue[:-<span class="number">1</span>] + future_queue</span><br><span class="line">        pts_list = [each[<span class="string">&#x27;points&#x27;</span>].data <span class="keyword">for</span> each <span class="keyword">in</span> queue]</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.ego_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            pts_list = <span class="variable language_">self</span>._mask_points(pts_list)</span><br><span class="line">        total_cur2ref_lidar_transform = []</span><br><span class="line">        total_ref2cur_lidar_transform = []</span><br><span class="line">        total_pts_list = []</span><br><span class="line">        <span class="keyword">for</span> i, each <span class="keyword">in</span> <span class="built_in">enumerate</span>(queue):</span><br><span class="line">            meta = each[<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line"></span><br><span class="line">            <span class="comment"># store points in the current frame.</span></span><br><span class="line">            cur_pts = pts_list[i].cpu().numpy().copy()</span><br><span class="line">            cur_pts[:, -<span class="number">1</span>] = i</span><br><span class="line">            total_pts_list.append(cur_pts)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># store the transformation from current frame to reference frame.</span></span><br><span class="line">            curr_e2g_translation = meta[<span class="string">&#x27;ego2global_translation&#x27;</span>]</span><br><span class="line">            curr_e2g_rotation = meta[<span class="string">&#x27;ego2global_rotation&#x27;</span>]</span><br><span class="line">            curr_e2g_transform = transform_matrix(</span><br><span class="line">                curr_e2g_translation, Quaternion(curr_e2g_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">            curr_g2e_transform = transform_matrix(</span><br><span class="line">                curr_e2g_translation, Quaternion(curr_e2g_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            curr_l2e_translation = meta[<span class="string">&#x27;lidar2ego_translation&#x27;</span>]</span><br><span class="line">            curr_l2e_rotation = meta[<span class="string">&#x27;lidar2ego_rotation&#x27;</span>]</span><br><span class="line">            curr_l2e_transform = transform_matrix(</span><br><span class="line">                curr_l2e_translation, Quaternion(curr_l2e_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">            curr_e2l_transform = transform_matrix(</span><br><span class="line">                curr_l2e_translation, Quaternion(curr_l2e_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute future to reference matrix.</span></span><br><span class="line">            cur_lidar_to_ref_lidar = (curr_l2e_transform.T @</span><br><span class="line">                                      curr_e2g_transform.T @</span><br><span class="line">                                      ref_g2e_transform.T @</span><br><span class="line">                                      ref_e2l_transform.T)</span><br><span class="line">            total_cur2ref_lidar_transform.append(cur_lidar_to_ref_lidar)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute reference to future matrix.</span></span><br><span class="line">            ref_lidar_to_cur_lidar = (ref_l2e_transform.T @</span><br><span class="line">                                      ref_e2g_transform.T @</span><br><span class="line">                                      curr_g2e_transform.T @</span><br><span class="line">                                      curr_e2l_transform.T)</span><br><span class="line">            total_ref2cur_lidar_transform.append(ref_lidar_to_cur_lidar)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. Parse previous and future can_bus information.</span></span><br><span class="line">        imgs_list = [each[<span class="string">&#x27;img&#x27;</span>].data <span class="keyword">for</span> each <span class="keyword">in</span> previous_queue]</span><br><span class="line">        metas_map = &#123;&#125;</span><br><span class="line">        prev_scene_token = <span class="literal">None</span></span><br><span class="line">        prev_pos = <span class="literal">None</span></span><br><span class="line">        prev_angle = <span class="literal">None</span></span><br><span class="line">        ref_meta = previous_queue[-<span class="number">1</span>][<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.2. Previous</span></span><br><span class="line">        <span class="keyword">for</span> i, each <span class="keyword">in</span> <span class="built_in">enumerate</span>(previous_queue):</span><br><span class="line">            metas_map[i] = each[<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;aug_param&#x27;</span> <span class="keyword">in</span> each:</span><br><span class="line">                metas_map[i][<span class="string">&#x27;aug_param&#x27;</span>] = each[<span class="string">&#x27;aug_param&#x27;</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> metas_map[i][<span class="string">&#x27;scene_token&#x27;</span>] != prev_scene_token:</span><br><span class="line">                metas_map[i][<span class="string">&#x27;prev_bev_exists&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">                prev_scene_token = metas_map[i][<span class="string">&#x27;scene_token&#x27;</span>]</span><br><span class="line">                prev_pos = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][:<span class="number">3</span>])</span><br><span class="line">                prev_angle = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][-<span class="number">1</span>])</span><br><span class="line">                <span class="comment"># Set the original point of this motion.</span></span><br><span class="line">                new_can_bus = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = <span class="number">0</span></span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">                metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>] = new_can_bus</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                metas_map[i][<span class="string">&#x27;prev_bev_exists&#x27;</span>] = <span class="literal">True</span></span><br><span class="line">                tmp_pos = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][:<span class="number">3</span>])</span><br><span class="line">                tmp_angle = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][-<span class="number">1</span>])</span><br><span class="line">                <span class="comment"># Compute the later waypoint.</span></span><br><span class="line">                <span class="comment"># To align the shift and rotate difference due to the BEV.</span></span><br><span class="line">                new_can_bus = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = tmp_pos - prev_pos</span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = tmp_angle - prev_angle</span><br><span class="line">                metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>] = new_can_bus</span><br><span class="line">                prev_pos = copy.deepcopy(tmp_pos)</span><br><span class="line">                prev_angle = copy.deepcopy(tmp_angle)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute cur_lidar_to_ref_lidar transformation matrix for quickly align generated</span></span><br><span class="line">            <span class="comment">#  bev features to the reference frame.</span></span><br><span class="line">            metas_map[i][<span class="string">&#x27;ref_lidar_to_cur_lidar&#x27;</span>] = total_ref2cur_lidar_transform[i]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.3. Future</span></span><br><span class="line">        current_scene_token = ref_meta[<span class="string">&#x27;scene_token&#x27;</span>]</span><br><span class="line">        ref_can_bus = <span class="literal">None</span></span><br><span class="line">        future_can_bus = []</span><br><span class="line">        future2ref_lidar_transform = []</span><br><span class="line">        ref2future_lidar_transform = []</span><br><span class="line">        <span class="keyword">for</span> i, each <span class="keyword">in</span> <span class="built_in">enumerate</span>(future_queue):</span><br><span class="line">            future_meta = each[<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line">            <span class="keyword">if</span> future_meta[<span class="string">&#x27;scene_token&#x27;</span>] != current_scene_token:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># store the transformation:</span></span><br><span class="line">            future2ref_lidar_transform.append(</span><br><span class="line">                total_cur2ref_lidar_transform[i + <span class="built_in">len</span>(previous_queue) - <span class="number">1</span>]</span><br><span class="line">            )  <span class="comment"># current -&gt; reference.</span></span><br><span class="line">            ref2future_lidar_transform.append(</span><br><span class="line">                total_ref2cur_lidar_transform[i + <span class="built_in">len</span>(previous_queue) - <span class="number">1</span>]</span><br><span class="line">            )  <span class="comment"># reference -&gt; current.</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># can_bus information.</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                new_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = <span class="number">0</span></span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">                future_can_bus.append(new_can_bus)</span><br><span class="line">                ref_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                new_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line"></span><br><span class="line">                new_can_bus_pos = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]).reshape(<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">                ref2prev_lidar_transform = ref2future_lidar_transform[-<span class="number">2</span>]</span><br><span class="line">                cur2ref_lidar_transform = future2ref_lidar_transform[-<span class="number">1</span>]</span><br><span class="line">                new_can_bus_pos = new_can_bus_pos @ cur2ref_lidar_transform @ ref2prev_lidar_transform</span><br><span class="line"></span><br><span class="line">                new_can_bus_angle = new_can_bus[-<span class="number">1</span>] - ref_can_bus[-<span class="number">1</span>]</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = new_can_bus_pos[:, :<span class="number">3</span>]</span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = new_can_bus_angle</span><br><span class="line">                future_can_bus.append(new_can_bus)</span><br><span class="line">                ref_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        ret_queue = previous_queue[-<span class="number">1</span>]</span><br><span class="line">        ret_queue[<span class="string">&#x27;img&#x27;</span>] = DC(torch.stack(imgs_list), cpu_only=<span class="literal">False</span>, stack=<span class="literal">True</span>)</span><br><span class="line">        ret_queue.pop(<span class="string">&#x27;aug_param&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;future_can_bus&#x27;</span>] = np.array(future_can_bus)</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;future2ref_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(future2ref_lidar_transform))</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;ref2future_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(ref2future_lidar_transform))</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;total_cur2ref_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(total_cur2ref_lidar_transform))</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;total_ref2cur_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(total_ref2cur_lidar_transform))</span><br><span class="line"></span><br><span class="line">        ret_queue[<span class="string">&#x27;img_metas&#x27;</span>] = DC(metas_map, cpu_only=<span class="literal">True</span>)</span><br><span class="line">        ret_queue.pop(<span class="string">&#x27;points&#x27;</span>)</span><br><span class="line">        ret_queue[<span class="string">&#x27;gt_points&#x27;</span>] = DC(</span><br><span class="line">            torch.from_numpy(np.concatenate(total_pts_list, <span class="number">0</span>)), cpu_only=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(future_can_bus) &lt; <span class="number">1</span> + <span class="variable language_">self</span>.future_length:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> ret_queue</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_load_nstp_data</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载nSTP数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.nstp_data = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="variable language_">self</span>.nstp_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;警告: nSTP数据路径 <span class="subst">&#123;self.nstp_path&#125;</span> 不存在&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nstp = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">import</span> torch</span><br><span class="line">            <span class="keyword">import</span> glob</span><br><span class="line">            <span class="keyword">import</span> os.path <span class="keyword">as</span> osp</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 获取目录中所有的.pt文件</span></span><br><span class="line">            pt_files = glob.glob(osp.join(<span class="variable language_">self</span>.nstp_path, <span class="string">&quot;*.pt&quot;</span>))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> pt_files:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;警告: 在 <span class="subst">&#123;self.nstp_path&#125;</span> 中未找到.pt文件&quot;</span>)</span><br><span class="line">                <span class="variable language_">self</span>.use_nstp = <span class="literal">False</span></span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">                </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;找到 <span class="subst">&#123;<span class="built_in">len</span>(pt_files)&#125;</span> 个nSTP数据文件&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 加载每个.pt文件</span></span><br><span class="line">            <span class="keyword">for</span> pt_file <span class="keyword">in</span> pt_files:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="comment"># 从文件名获取样本ID</span></span><br><span class="line">                    sample_id = osp.splitext(osp.basename(pt_file))[<span class="number">0</span>]</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 加载PyTorch张量</span></span><br><span class="line">                    graph_data = torch.load(pt_file)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 将数据添加到字典中</span></span><br><span class="line">                    <span class="variable language_">self</span>.nstp_data[sample_id] = graph_data</span><br><span class="line">                    </span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;加载文件 <span class="subst">&#123;pt_file&#125;</span> 失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">                    </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;成功加载 <span class="subst">&#123;<span class="built_in">len</span>(self.nstp_data)&#125;</span> 个nSTP样本&quot;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;加载nSTP数据失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;继续训练，但不使用nSTP数据&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nstp = <span class="literal">False</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="2-1-2-NuPlan数据集"><a href="#2-1-2-NuPlan数据集" class="headerlink" title="2.1.2 NuPlan数据集"></a>2.1.2 NuPlan数据集</h4><p><strong>文件路径</strong>: <code>d:\git_clone\ViDAR\projects\mmdet3d_plugin\datasets\nuplan_vidar_dataset_v1.py</code></p><p><strong>主要修改</strong>:</p><ul><li>与NuScenes数据集类似，添加了nSTP支持</li><li>实现了特定于NuPlan数据集的nSTP数据加载和处理逻辑</li></ul><h3 id="2-2-模型头部修改"><a href="#2-2-模型头部修改" class="headerlink" title="2.2 模型头部修改"></a>2.2 模型头部修改</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\bevformer\dense_heads\vidar_head_v1.py</code></p><p><strong>主要修改</strong>:</p><ul><li>添加了nSTP相关参数：<code>use_nstp</code>, <code>nstp_encoder_cfg</code>, <code>nstp_enhancer_cfg</code></li><li>集成了nSTP编码器和增强器到模型头部</li><li>修改了前向传播逻辑，处理nSTP特征</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"><span class="comment"># Visual Point Cloud Forecasting enables Scalable Autonomous Driving              #</span></span><br><span class="line"><span class="comment"># Copyright (c) OpenDriveLab. All rights reserved.                                #</span></span><br><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;V1.multiframe&gt; of ViDAR future prediction head:</span></span><br><span class="line"><span class="string">    * Predict future &amp; history frames simultaneously.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mmdet.models <span class="keyword">import</span> HEADS, build_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mmcv.runner <span class="keyword">import</span> force_fp32, auto_fp16</span><br><span class="line"><span class="keyword">from</span> .vidar_head_base <span class="keyword">import</span> ViDARHeadBase</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@HEADS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ViDARHeadV1</span>(<span class="title class_ inherited__">ViDARHeadBase</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 history_queue_length,</span></span><br><span class="line"><span class="params">                 pred_history_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 pred_future_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 per_frame_loss_weight=(<span class="params"><span class="number">1.0</span>,</span>),</span></span><br><span class="line"><span class="params">                 use_nskg=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 nskg_encoder_cfg=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 nskg_enhancer_cfg=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 use_nstp=<span class="literal">False</span>,  <span class="comment"># 添加nSTP支持参数</span></span></span><br><span class="line"><span class="params">                 nstp_encoder_cfg=<span class="literal">None</span>,  <span class="comment"># 添加nSTP编码器配置</span></span></span><br><span class="line"><span class="params">                 nstp_enhancer_cfg=<span class="literal">None</span>,  <span class="comment"># 添加nSTP增强器配置</span></span></span><br><span class="line"><span class="params">                 *args,</span></span><br><span class="line"><span class="params">                 **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(*args, **kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.history_queue_length = history_queue_length</span><br><span class="line">        <span class="variable language_">self</span>.pred_history_frame_num = pred_history_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.pred_future_frame_num = pred_future_frame_num</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.pred_frame_num = <span class="number">1</span> + <span class="variable language_">self</span>.pred_history_frame_num + <span class="variable language_">self</span>.pred_future_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.per_frame_loss_weight = per_frame_loss_weight</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.per_frame_loss_weight) == <span class="variable language_">self</span>.pred_frame_num</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._init_bev_pred_layers()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># nSKG支持</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nskg = use_nskg</span><br><span class="line">        <span class="comment"># nSTP支持</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nstp = use_nstp</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg:</span><br><span class="line">            <span class="keyword">from</span> ..modules.nskg_gnn <span class="keyword">import</span> NSKGEncoder</span><br><span class="line">            <span class="keyword">from</span> ..modules.nskg_bev_enhancer <span class="keyword">import</span> NSKGBEVEnhancer</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 创建nSKG编码器</span></span><br><span class="line">            <span class="keyword">if</span> nskg_encoder_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_encoder = NSKGEncoder(**nskg_encoder_cfg)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_encoder = NSKGEncoder(</span><br><span class="line">                    in_channels=<span class="number">8</span>,</span><br><span class="line">                    hidden_channels=<span class="number">64</span>,</span><br><span class="line">                    out_channels=<span class="number">256</span>,</span><br><span class="line">                    num_layers=<span class="number">2</span>,</span><br><span class="line">                    gnn_type=<span class="string">&#x27;gat&#x27;</span>,</span><br><span class="line">                    use_hetero=<span class="literal">True</span></span><br><span class="line">                )</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 创建BEV特征增强器</span></span><br><span class="line">            <span class="keyword">if</span> nskg_enhancer_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_enhancer = NSKGBEVEnhancer(**nskg_enhancer_cfg)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_enhancer = NSKGBEVEnhancer(</span><br><span class="line">                    bev_channels=<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                    nskg_channels=<span class="number">256</span>,</span><br><span class="line">                    hidden_channels=<span class="number">128</span>,</span><br><span class="line">                    bev_h=<span class="variable language_">self</span>.bev_h,</span><br><span class="line">                    bev_w=<span class="variable language_">self</span>.bev_w,</span><br><span class="line">                    use_attention=<span class="literal">True</span></span><br><span class="line">                )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.nskg_encoder = <span class="literal">None</span></span><br><span class="line">            <span class="variable language_">self</span>.nskg_enhancer = <span class="literal">None</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 添加nSTP支持</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.use_nstp:</span><br><span class="line">                <span class="keyword">from</span> ..modules.nstp_encoder <span class="keyword">import</span> NSTPEncoder, NSTPEnhancer</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 创建nSTP编码器</span></span><br><span class="line">                <span class="keyword">if</span> nstp_encoder_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_encoder = NSTPEncoder(**nstp_encoder_cfg)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_encoder = NSTPEncoder(</span><br><span class="line">                        in_channels=<span class="number">64</span>,</span><br><span class="line">                        hidden_channels=<span class="number">128</span>,</span><br><span class="line">                        out_channels=<span class="number">256</span>,</span><br><span class="line">                        num_layers=<span class="number">3</span>,</span><br><span class="line">                        gnn_type=<span class="string">&#x27;graphsage&#x27;</span>,</span><br><span class="line">                        dropout=<span class="number">0.1</span>,</span><br><span class="line">                        aggr=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">                    )</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 创建nSTP增强器</span></span><br><span class="line">                <span class="keyword">if</span> nstp_enhancer_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_enhancer = NSTPEnhancer(**nstp_enhancer_cfg)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_enhancer = NSTPEnhancer(</span><br><span class="line">                        bev_channels=<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                        nstp_channels=<span class="number">256</span>,</span><br><span class="line">                        hidden_channels=<span class="number">128</span>,</span><br><span class="line">                        bev_h=<span class="variable language_">self</span>.bev_h,</span><br><span class="line">                        bev_w=<span class="variable language_">self</span>.bev_w,</span><br><span class="line">                        use_attention=<span class="literal">True</span></span><br><span class="line">                    )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nstp_encoder = <span class="literal">None</span></span><br><span class="line">                <span class="variable language_">self</span>.nstp_enhancer = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, mlvl_feats, img_metas, prev_bev=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Forward function.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            mlvl_feats (list(Tensor)): 多尺度特征，每个元素形状为 [B, num_cam, C, H, W]</span></span><br><span class="line"><span class="string">            img_metas (list(dict)): 图像元信息</span></span><br><span class="line"><span class="string">            prev_bev: 历史BEV特征</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            tuple: bev_embed, history_states, future_states</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 调用父类的forward方法获取原始结果</span></span><br><span class="line">        bev_embed, history_states, future_states = <span class="built_in">super</span>().forward(</span><br><span class="line">            mlvl_feats, img_metas, prev_bev, **kwargs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSKG，处理图数据增强BEV特征</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_encoder <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_enhancer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            bs = bev_embed.shape[<span class="number">0</span>]</span><br><span class="line">            bev_h, bev_w = <span class="variable language_">self</span>.bev_h, <span class="variable language_">self</span>.bev_w</span><br><span class="line">            </span><br><span class="line">            nskg_graphs = []</span><br><span class="line">            <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas:</span><br><span class="line">                nskg_graph = img_meta.get(<span class="string">&#x27;nskg_graph&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">                nskg_graphs.append(nskg_graph)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 处理每个样本的nSKG数据</span></span><br><span class="line">            enhanced_bevs = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">                <span class="comment"># 获取当前样本的BEV特征</span></span><br><span class="line">                curr_bev = bev_embed[i:i+<span class="number">1</span>].view(<span class="number">1</span>, bev_h, bev_w, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 获取当前样本的nSKG图</span></span><br><span class="line">                curr_graph = nskg_graphs[i] <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(nskg_graphs) <span class="keyword">and</span> nskg_graphs[i] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> curr_graph <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="comment"># 使用GNN编码器处理图数据</span></span><br><span class="line">                    node_features, global_features = <span class="variable language_">self</span>.nskg_encoder(curr_graph)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 获取节点位置信息</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">hasattr</span>(curr_graph, <span class="string">&#x27;pos&#x27;</span>):</span><br><span class="line">                        node_pos = curr_graph.pos</span><br><span class="line">                    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(curr_graph, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&#x27;pos&#x27;</span> <span class="keyword">in</span> curr_graph:</span><br><span class="line">                        node_pos = curr_graph[<span class="string">&#x27;pos&#x27;</span>]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        node_pos = <span class="literal">None</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 增强BEV特征</span></span><br><span class="line">                    enhanced_bev = <span class="variable language_">self</span>.nskg_enhancer(</span><br><span class="line">                        curr_bev, node_features, global_features, node_pos)</span><br><span class="line">                        </span><br><span class="line">                    enhanced_bevs.append(enhanced_bev)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 如果没有nSKG数据，保持原始BEV特征不变</span></span><br><span class="line">                    enhanced_bevs.append(curr_bev)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 合并增强后的BEV特征</span></span><br><span class="line">            <span class="keyword">if</span> enhanced_bevs:</span><br><span class="line">                enhanced_bev = torch.cat(enhanced_bevs, dim=<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># 转回原始格式</span></span><br><span class="line">                bev_embed = enhanced_bev.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(bs, bev_h * bev_w, -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加nSTP支持</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nstp <span class="keyword">and</span> <span class="variable language_">self</span>.nstp_encoder <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.nstp_enhancer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            bs = bev_embed.shape[<span class="number">0</span>]</span><br><span class="line">            bev_h, bev_w = <span class="variable language_">self</span>.bev_h, <span class="variable language_">self</span>.bev_w</span><br><span class="line">            </span><br><span class="line">            nstp_graphs = []</span><br><span class="line">            <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas:</span><br><span class="line">                nstp_graph = img_meta.get(<span class="string">&#x27;nstp_graph&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">                nstp_graphs.append(nstp_graph)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 处理每个样本的nSTP数据</span></span><br><span class="line">            enhanced_bevs = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">                <span class="comment"># 获取当前样本的BEV特征</span></span><br><span class="line">                curr_bev = bev_embed[i:i+<span class="number">1</span>].view(<span class="number">1</span>, bev_h, bev_w, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 获取当前样本的nSTP图</span></span><br><span class="line">                curr_graph = nstp_graphs[i] <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(nstp_graphs) <span class="keyword">and</span> nstp_graphs[i] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> curr_graph <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="comment"># 使用GNN编码器处理图数据</span></span><br><span class="line">                    node_features = <span class="variable language_">self</span>.nstp_encoder(curr_graph)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 获取节点位置信息（如果有）</span></span><br><span class="line">                    node_pos = <span class="literal">None</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">hasattr</span>(curr_graph, <span class="string">&#x27;pos&#x27;</span>):</span><br><span class="line">                        node_pos = curr_graph.pos</span><br><span class="line">                    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(curr_graph, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&#x27;pos&#x27;</span> <span class="keyword">in</span> curr_graph:</span><br><span class="line">                        node_pos = curr_graph[<span class="string">&#x27;pos&#x27;</span>]</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 增强BEV特征</span></span><br><span class="line">                    enhanced_bev = <span class="variable language_">self</span>.nstp_enhancer(curr_bev, node_features, node_pos)</span><br><span class="line">                    enhanced_bevs.append(enhanced_bev)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 如果没有nSTP数据，保持原始BEV特征不变</span></span><br><span class="line">                    enhanced_bevs.append(curr_bev)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 合并增强后的BEV特征</span></span><br><span class="line">            <span class="keyword">if</span> enhanced_bevs:</span><br><span class="line">                enhanced_bev = torch.cat(enhanced_bevs, dim=<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># 转回原始格式</span></span><br><span class="line">                bev_embed = enhanced_bev.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(bs, bev_h * bev_w, -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> bev_embed, history_states, future_states</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_bev_pred_layers</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Overwrite the &#123;self.bev_pred_head&#125; of super()._init_layers()</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        bev_pred_branch = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_pred_fcs):</span><br><span class="line">            bev_pred_branch.append(nn.Linear(<span class="variable language_">self</span>.embed_dims, <span class="variable language_">self</span>.embed_dims))</span><br><span class="line">            bev_pred_branch.append(nn.LayerNorm(<span class="variable language_">self</span>.embed_dims))</span><br><span class="line">            bev_pred_branch.append(nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line">        bev_pred_branch.append(nn.Linear(</span><br><span class="line">            <span class="variable language_">self</span>.embed_dims, <span class="variable language_">self</span>.pred_frame_num * <span class="variable language_">self</span>.num_pred_height))</span><br><span class="line">        bev_pred_head = nn.Sequential(*bev_pred_branch)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_get_clones</span>(<span class="params">module, N</span>):</span><br><span class="line">            <span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Auxiliary supervision for all intermediate results.</span></span><br><span class="line">        num_pred = <span class="variable language_">self</span>.transformer.decoder.num_layers</span><br><span class="line">        <span class="variable language_">self</span>.bev_pred_head = _get_clones(bev_pred_head, num_pred)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_head</span>(<span class="params">self, next_bev_feats</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get freespace estimation from multi-frame BEV feature maps.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            next_bev_feats (torch.Tensor): with shape as</span></span><br><span class="line"><span class="string">                [pred_frame_num, inter_num, bs, bev_h * bev_w, dims]</span></span><br><span class="line"><span class="string">                pred_frame_num: history frames + current frame + future frames.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        next_bev_preds = []</span><br><span class="line">        <span class="keyword">for</span> lvl <span class="keyword">in</span> <span class="built_in">range</span>(next_bev_feats.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="comment"># pred_frame_num, bs, bev_h * bev_w, num_height_pred * num_frame</span></span><br><span class="line">            <span class="comment">#  ===&gt; pred_frame_num, bs, bev_h * bev_w, num_height_pred, num_frame</span></span><br><span class="line">            <span class="comment">#  ===&gt; pred_frame_num, num_frame, bs, bev_h * bev_w, num_height_pred.</span></span><br><span class="line">            next_bev_pred = <span class="variable language_">self</span>.bev_pred_head[lvl](next_bev_feats[:, lvl])</span><br><span class="line">            next_bev_pred = next_bev_pred.view(</span><br><span class="line">                *next_bev_pred.shape[:-<span class="number">1</span>], <span class="variable language_">self</span>.num_pred_height, <span class="variable language_">self</span>.pred_frame_num)</span><br><span class="line"></span><br><span class="line">            base_bev_pred = next_bev_pred[..., <span class="variable language_">self</span>.pred_history_frame_num][..., <span class="literal">None</span>]</span><br><span class="line">            next_bev_pred = torch.cat([</span><br><span class="line">                next_bev_pred[..., :<span class="variable language_">self</span>.pred_history_frame_num] + base_bev_pred,</span><br><span class="line">                base_bev_pred,</span><br><span class="line">                next_bev_pred[..., <span class="variable language_">self</span>.pred_history_frame_num + <span class="number">1</span>:] + base_bev_pred</span><br><span class="line">            ], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            next_bev_pred = next_bev_pred.permute(<span class="number">0</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>).contiguous()</span><br><span class="line">            next_bev_preds.append(next_bev_pred)</span><br><span class="line">        <span class="comment"># pred_frame_num, inter_num, num_frame, bs, bev_h*bev_w, num_height_pred</span></span><br><span class="line">        next_bev_preds = torch.stack(next_bev_preds, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> next_bev_preds</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_reference_gt_points</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                                 gt_points,</span></span><br><span class="line"><span class="params">                                 src_frame_idx_list,</span></span><br><span class="line"><span class="params">                                 tgt_frame_idx_list,</span></span><br><span class="line"><span class="params">                                 img_metas</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Transform gt_points at src_frame_idx in &#123;src_frame_idx_list&#125; to the coordinate space</span></span><br><span class="line"><span class="string">        of each tgt_frame_idx in &#123;tgt_frame_idx_list&#125;.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        bs = <span class="built_in">len</span>(gt_points)</span><br><span class="line">        aligned_gt_points = []</span><br><span class="line">        batched_origin_points = []</span><br><span class="line">        <span class="keyword">for</span> frame_idx, src_frame_idx, tgt_frame_idx <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">                <span class="built_in">range</span>(<span class="built_in">len</span>(src_frame_idx_list)), src_frame_idx_list, tgt_frame_idx_list):</span><br><span class="line">            <span class="comment"># 1. get gt_points belongs to src_frame_idx.</span></span><br><span class="line">            src_frame_gt_points = [p[p[:, -<span class="number">1</span>] == src_frame_idx] <span class="keyword">for</span> p <span class="keyword">in</span> gt_points]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2. get transformation matrix..</span></span><br><span class="line">            src_to_ref = [img_meta[<span class="string">&#x27;total_cur2ref_lidar_transform&#x27;</span>][src_frame_idx] <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas]</span><br><span class="line">            src_to_ref = gt_points[<span class="number">0</span>].new_tensor(np.array(src_to_ref))  <span class="comment"># bs, 4, 4</span></span><br><span class="line">            ref_to_tgt = [img_meta[<span class="string">&#x27;total_ref2cur_lidar_transform&#x27;</span>][tgt_frame_idx] <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas]</span><br><span class="line">            ref_to_tgt = gt_points[<span class="number">0</span>].new_tensor(np.array(ref_to_tgt))  <span class="comment"># bs, 4, 4</span></span><br><span class="line">            src_to_tgt = torch.matmul(src_to_ref, ref_to_tgt)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3. transfer src_frame_gt_points to src_to_tgt.</span></span><br><span class="line">            aligned_gt_points_per_frame = []</span><br><span class="line">            <span class="keyword">for</span> batch_idx, points <span class="keyword">in</span> <span class="built_in">enumerate</span>(src_frame_gt_points):</span><br><span class="line">                new_points = points.clone()  <span class="comment"># -1, 4</span></span><br><span class="line">                new_points = torch.cat([</span><br><span class="line">                    new_points[:, :<span class="number">3</span>], new_points.new_ones(new_points.shape[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">                ], <span class="number">1</span>)</span><br><span class="line">                new_points = torch.matmul(new_points, src_to_tgt[batch_idx])</span><br><span class="line">                new_points[..., -<span class="number">1</span>] = frame_idx</span><br><span class="line">                aligned_gt_points_per_frame.append(new_points)</span><br><span class="line">            aligned_gt_points.append(aligned_gt_points_per_frame)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4. obtain the aligned origin points.</span></span><br><span class="line">            aligned_origin_points = torch.from_numpy(</span><br><span class="line">                np.zeros((bs, <span class="number">1</span>, <span class="number">3</span>))).to(src_to_tgt.dtype).to(src_to_tgt.device)</span><br><span class="line">            aligned_origin_points = torch.cat([</span><br><span class="line">                aligned_origin_points[..., :<span class="number">3</span>], torch.ones_like(aligned_origin_points)[..., <span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">            ], -<span class="number">1</span>)</span><br><span class="line">            aligned_origin_points = torch.matmul(aligned_origin_points, src_to_tgt)</span><br><span class="line">            batched_origin_points.append(aligned_origin_points[..., :<span class="number">3</span>].contiguous())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># stack points from different timestamps, and transfer to occupancy representation.</span></span><br><span class="line">        batched_gt_points = []</span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">            cur_gt_points = [</span><br><span class="line">                aligned_gt_points[frame_idx][b]</span><br><span class="line">                <span class="keyword">for</span> frame_idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(src_frame_idx_list))]</span><br><span class="line">            cur_gt_points = torch.cat(cur_gt_points, <span class="number">0</span>)</span><br><span class="line">            batched_gt_points.append(cur_gt_points)</span><br><span class="line"></span><br><span class="line">        batched_origin_points = torch.cat(batched_origin_points, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> batched_gt_points, batched_origin_points</span><br><span class="line"></span><br><span class="line"><span class="meta">    @force_fp32(<span class="params">apply_to=(<span class="params"><span class="string">&#x27;pred_dict&#x27;</span></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             pred_dict,</span></span><br><span class="line"><span class="params">             gt_points,</span></span><br><span class="line"><span class="params">             start_idx,</span></span><br><span class="line"><span class="params">             tgt_bev_h,</span></span><br><span class="line"><span class="params">             tgt_bev_w,</span></span><br><span class="line"><span class="params">             tgt_pc_range,</span></span><br><span class="line"><span class="params">             pred_frame_num,</span></span><br><span class="line"><span class="params">             img_metas=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             batched_origin_points=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;Compute loss for all history according to gt_points.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        gt_points: ground-truth point cloud in each frame.</span></span><br><span class="line"><span class="string">            list of tensor with shape [-1, 5], indicating ground-truth point cloud in</span></span><br><span class="line"><span class="string">            each frame.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        bev_preds = pred_dict[<span class="string">&#x27;next_bev_preds&#x27;</span>]</span><br><span class="line">        valid_frames = np.array(pred_dict[<span class="string">&#x27;valid_frames&#x27;</span>])</span><br><span class="line">        start_frames = (valid_frames + <span class="variable language_">self</span>.history_queue_length - <span class="variable language_">self</span>.pred_history_frame_num)</span><br><span class="line">        tgt_frames = valid_frames + <span class="variable language_">self</span>.history_queue_length</span><br><span class="line"></span><br><span class="line">        full_prev_bev_exists = pred_dict.get(<span class="string">&#x27;full_prev_bev_exists&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> full_prev_bev_exists:</span><br><span class="line">            frame_idx_for_loss = [<span class="variable language_">self</span>.pred_history_frame_num] * <span class="variable language_">self</span>.pred_frame_num</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            frame_idx_for_loss = np.arange(<span class="number">0</span>, <span class="variable language_">self</span>.pred_frame_num)</span><br><span class="line"></span><br><span class="line">        loss_dict = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> idx, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(frame_idx_for_loss):</span><br><span class="line">            <span class="comment"># 1. get the predicted occupancy of frame-i.</span></span><br><span class="line">            cur_bev_preds = bev_preds[:, :, i, ...].contiguous()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2. get the frame index of current frame.</span></span><br><span class="line">            src_frames = start_frames + i</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3. get gt_points belonging to cur_valid_frames.</span></span><br><span class="line">            cur_gt_points, cur_origin_points = <span class="variable language_">self</span>._get_reference_gt_points(</span><br><span class="line">                gt_points,</span><br><span class="line">                src_frame_idx_list=src_frames,</span><br><span class="line">                tgt_frame_idx_list=tgt_frames,</span><br><span class="line">                img_metas=img_metas)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4. compute loss.</span></span><br><span class="line">            <span class="keyword">if</span> i != <span class="variable language_">self</span>.pred_history_frame_num:</span><br><span class="line">                <span class="comment"># For aux history-future supervision:</span></span><br><span class="line">                <span class="comment">#  only compute loss for cur_frame prediction.</span></span><br><span class="line">                loss_weight = np.array([[<span class="number">1</span>]] + [[<span class="number">0</span>]] * (<span class="built_in">len</span>(<span class="variable language_">self</span>.loss_weight) - <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                loss_weight = <span class="variable language_">self</span>.loss_weight</span><br><span class="line"></span><br><span class="line">            cur_loss_dict = <span class="built_in">super</span>().loss(</span><br><span class="line">                <span class="built_in">dict</span>(next_bev_preds=cur_bev_preds,</span><br><span class="line">                     valid_frames=np.arange(<span class="number">0</span>, <span class="built_in">len</span>(src_frames))),</span><br><span class="line">                cur_gt_points,</span><br><span class="line">                start_idx=start_idx,</span><br><span class="line">                tgt_bev_h=tgt_bev_h,</span><br><span class="line">                tgt_bev_w=tgt_bev_w,</span><br><span class="line">                tgt_pc_range=tgt_pc_range,</span><br><span class="line">                pred_frame_num=<span class="built_in">len</span>(<span class="variable language_">self</span>.loss_weight)-<span class="number">1</span>,</span><br><span class="line">                img_metas=img_metas,</span><br><span class="line">                batched_origin_points=cur_origin_points,</span><br><span class="line">                loss_weight=loss_weight)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 5. merge dict.</span></span><br><span class="line">            cur_frame_loss_weight = <span class="variable language_">self</span>.per_frame_loss_weight[i]</span><br><span class="line">            cur_frame_loss_weight = cur_frame_loss_weight * (idx == i)</span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> cur_loss_dict.items():</span><br><span class="line">                loss_dict.update(&#123;<span class="string">f&#x27;frame.<span class="subst">&#123;idx&#125;</span>.<span class="subst">&#123;k&#125;</span>.loss&#x27;</span>: v * cur_frame_loss_weight&#125;)</span><br><span class="line">        <span class="keyword">return</span> loss_dict</span><br><span class="line"></span><br><span class="line"><span class="meta">    @force_fp32(<span class="params">apply_to=(<span class="params"><span class="string">&#x27;pred_dict&#x27;</span></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_point_cloud_prediction</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                                   pred_dict,</span></span><br><span class="line"><span class="params">                                   gt_points,</span></span><br><span class="line"><span class="params">                                   start_idx,</span></span><br><span class="line"><span class="params">                                   tgt_bev_h,</span></span><br><span class="line"><span class="params">                                   tgt_bev_w,</span></span><br><span class="line"><span class="params">                                   tgt_pc_range,</span></span><br><span class="line"><span class="params">                                   img_metas=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                                   batched_origin_points=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;Generate point cloud prediction.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># pred_frame_num, inter_num, num_frame, bs, bev_h * bev_w, num_height_pred</span></span><br><span class="line">        pred_dict[<span class="string">&#x27;next_bev_preds&#x27;</span>] = pred_dict[<span class="string">&#x27;next_bev_preds&#x27;</span>][:, :, <span class="variable language_">self</span>.pred_history_frame_num, ...].contiguous()</span><br><span class="line"></span><br><span class="line">        valid_frames = np.array(pred_dict[<span class="string">&#x27;valid_frames&#x27;</span>])</span><br><span class="line">        valid_gt_points, cur_origin_points = <span class="variable language_">self</span>._get_reference_gt_points(</span><br><span class="line">            gt_points,</span><br><span class="line">            src_frame_idx_list=valid_frames + <span class="variable language_">self</span>.history_queue_length,</span><br><span class="line">            tgt_frame_idx_list=valid_frames + <span class="variable language_">self</span>.history_queue_length,</span><br><span class="line">            img_metas=img_metas)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().get_point_cloud_prediction(</span><br><span class="line">            pred_dict=pred_dict,</span><br><span class="line">            gt_points=valid_gt_points,</span><br><span class="line">            start_idx=start_idx,</span><br><span class="line">            tgt_bev_h=tgt_bev_h,</span><br><span class="line">            tgt_bev_w=tgt_bev_w,</span><br><span class="line">            tgt_pc_range=tgt_pc_range,</span><br><span class="line">            img_metas=img_metas,</span><br><span class="line">            batched_origin_points=cur_origin_points)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="2-3-ViDAR检测器修改"><a href="#2-3-ViDAR检测器修改" class="headerlink" title="2.3 ViDAR检测器修改"></a>2.3 ViDAR检测器修改</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\bevformer\detectors\vidar.py</code></p><p><strong>主要修改</strong>:</p><ul><li>修改了<code>forward_train</code>方法：处理nSTP特征，并解决了元组类型问题</li><li>修改了<code>forward_test</code>方法：支持测试时使用nSTP特征</li></ul><p>关键修改部分：</p><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_train</span>(<span class="params">self, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ...现有代码...</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 修改部分：处理next_bev_feats中可能的元组类型</span></span><br><span class="line">    processed_next_bev_feats = []</span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> next_bev_feats:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(feat, <span class="built_in">tuple</span>):</span><br><span class="line">            <span class="comment"># 如果是元组，取第一个元素（主要特征）</span></span><br><span class="line">            processed_next_bev_feats.append(feat[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            processed_next_bev_feats.append(feat)</span><br><span class="line">    </span><br><span class="line">    next_bev_feats = torch.stack(processed_next_bev_feats, <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ...继续现有代码...</span></span><br></pre></td></tr></table></figure><h2 id="3-配置文件修改"><a href="#3-配置文件修改" class="headerlink" title="3. 配置文件修改"></a>3. 配置文件修改</h2><h3 id="3-1-OpenScene配置"><a href="#3-1-OpenScene配置" class="headerlink" title="3.1 OpenScene配置"></a>3.1 OpenScene配置</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\configs\vidar_pretrain\OpenScene\vidar_OpenScene_mini_1_8_3future_nstp.py</code></p><p><strong>主要修改</strong>:</p><ul><li>添加了nSTP相关配置：启用nSTP，设置数据路径</li><li>修改了数据处理流程，添加了nSTP数据处理组件</li><li>配置了nSTP编码器和增强器参数</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nSTP配置</span></span><br><span class="line">use_nskg = <span class="literal">False</span>  <span class="comment"># 禁用nSKG</span></span><br><span class="line">use_nstp = <span class="literal">True</span>  <span class="comment"># 启用nSTP</span></span><br><span class="line">nstp_path = <span class="string">&#x27;data/nuscenes/nstp/train/raw&#x27;</span>  <span class="comment"># nSTP数据目录路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加nSTP数据处理组件</span></span><br><span class="line">train_pipeline.insert(-<span class="number">2</span>, <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ProcessNSTPGraph&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改数据集配置</span></span><br><span class="line">data = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    train=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">        use_nstp=use_nstp,</span><br><span class="line">        nstp_path=nstp_path,</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    ),</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h3 id="3-2-NuScenes全集配置"><a href="#3-2-NuScenes全集配置" class="headerlink" title="3.2 NuScenes全集配置"></a>3.2 NuScenes全集配置</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\configs\vidar_pretrain\nusc_fullset\vidar_nstp_nusc.py</code></p><p><strong>主要修改</strong>:</p><ul><li>基于基础配置，添加了nSTP支持</li><li>配置了nSTP数据路径和处理逻辑</li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_base_ = [<span class="string">&#x27;./vidar_full_nusc_1future.py&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># nSTP配置</span></span><br><span class="line">use_nskg = <span class="literal">False</span></span><br><span class="line">use_nstp = <span class="literal">True</span></span><br><span class="line">nstp_path = <span class="string">&#x27;data/nuscenes/nstp/nstp.pkl&#x27;</span>  <span class="comment"># nSTP数据路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改数据集配置</span></span><br><span class="line">data = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    train=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;NuScenesViDARDatasetV1&#x27;</span>,</span><br><span class="line">        use_nskg=use_nskg,</span><br><span class="line">        use_nstp=use_nstp,</span><br><span class="line">        nstp_path=nstp_path,</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    ),</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="4-其他辅助修改"><a href="#4-其他辅助修改" class="headerlink" title="4. 其他辅助修改"></a>4. 其他辅助修改</h2><h3 id="4-1-数据集注册"><a href="#4-1-数据集注册" class="headerlink" title="4.1 数据集注册"></a>4.1 数据集注册</h3><p><strong>文件路径</strong>: <code>d:\git_clone\ViDAR\projects\mmdet3d_plugin\datasets\__init__.py</code></p><p><strong>主要修改</strong>:</p><ul><li>导入并注册了nSTP相关模块：<code>NSTPEncoder</code>, <code>NSTPEnhancer</code></li></ul><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> .nstp_encoder <span class="keyword">import</span> NSTPEncoder, NSTPEnhancer</span><br><span class="line"></span><br><span class="line">__all__ = [</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="string">&#x27;NSTPEncoder&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;NSTPEnhancer&#x27;</span>,</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure><h2 id="5-过程中的好多错误"><a href="#5-过程中的好多错误" class="headerlink" title="5. 过程中的好多错误"></a>5. 过程中的好多错误</h2><p><img src="/article/undefined/bb0c0e4dfe0861b863c951950326904.png" alt="bb0c0e4dfe0861b863c951950326904"></p><p>首先是数据集nSKG不能用，用了会出现这个问题：</p><p><img src="/article/undefined/c5f86c19470657dbb32886c2a1ecc09.png" alt="c5f86c19470657dbb32886c2a1ecc09"></p><p><img src="/article/undefined/592bd326d2dfd419178041902a18105.png" alt="592bd326d2dfd419178041902a18105"></p><p>然后进而导致：</p><p><img src="F:\Hexo\My-Web\source_posts\自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试\baa821cdf2653096e4ff3d91e0adb78-174584491940213.png" alt="baa821cdf2653096e4ff3d91e0adb78"></p><p><img src="/article/undefined/46aa267f5409cd333b793036e91f475.png" alt="46aa267f5409cd333b793036e91f475"></p><p>然后对他做细致处理的话，其实也可以，但是我写的代码处理不了：</p><p><img src="/article/undefined/919ca81a4064679c687412f83fcacbf.png" alt="919ca81a4064679c687412f83fcacbf"></p><p>所以最后选择使用nSTP，因为在<a href="https://zenodo.org/records/10074393">nuScenes Knowledge Graph</a>发现了nSTP是对nSKG的拓展，而且可以直接拿来训练，因此修改代码适配：</p><p><img src="/article/undefined/image-20250428205817288.png" alt="image-20250428205817288"></p><p><img src="/article/undefined/94c305fa70e234b826ba190de87e104.png" alt="94c305fa70e234b826ba190de87e104"></p><p>最后结果，可以正常读取nSTP数据文件：</p><p><img src="F:\Hexo\My-Web\source_posts\自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试\f4d05a563eb5ef922c95d96436bf1d2.png" alt="f4d05a563eb5ef922c95d96436bf1d2"></p><p>但是……爆内存了：</p><p><img src="F:\Hexo\My-Web\source_posts\自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试\64c1d3c75e8a169d3bffaf3d1b7f692.png" alt="64c1d3c75e8a169d3bffaf3d1b7f692"></p><p>写到这里的时候刚修复了一小点bug，目前仍然在服务器上跑着……</p><p>然后最后贴一张饱受折损的服务器合照（感谢罗勇老师）</p><p><img src="/article/undefined/926d4f6ee558907674f7927728597bc.png" alt="926d4f6ee558907674f7927728597bc"></p><p><img src="/article/undefined/b83a187f7c801ef796584bdd84e832b.png" alt="b83a187f7c801ef796584bdd84e832b"></p><h2 id="6-最后总结"><a href="#6-最后总结" class="headerlink" title="6. 最后总结"></a>6. 最后总结</h2><p>nSTP集成工作主要包括以下几个方面：</p><ol><li><strong>数据处理</strong>：创建了nSTP图数据的加载和处理逻辑，支持从.pt文件中读取图结构数据</li><li><strong>特征提取</strong>：实现了基于图神经网络的nSTP编码器，提取图结构中的时空特征</li><li><strong>特征融合</strong>：实现了nSTP特征与BEV特征的融合机制，通过注意力机制增强BEV特征</li><li><strong>模型集成</strong>：将nSTP模块集成到ViDAR模型中，修改了前向传播逻辑</li><li><strong>配置支持</strong>：添加了nSTP相关配置，支持灵活开启&#x2F;关闭nSTP功能</li></ol><p>这些修改使ViDAR模型能够利用nSTP提供的场景结构和时间演化信息，增强了模型对动态场景的理解能力，特别是在预测未来帧方面。</p><p>然后我们完成的工作：</p><ol><li>完成环境配置，解决冲突依赖问题</li><li>完成数据集的读取与训练问题</li><li>完成对vidar的修改以加入nSTP数据集来调优</li><li>修复原本的pytouch问题</li><li>目前仍然在服务器上跑着，估计还有不少后续的训练问题需要修改……但是没时间了</li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cv </tag>
            
            <tag> 自动驾驶 </tag>
            
            <tag> 课程学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>[长期更新]算法总结</title>
      <link href="/article/dba7e729.html"/>
      <url>/article/dba7e729.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>从力扣100题开始的算法总结，决定真正走科班的代码之路后，果然还是得彻底从头开始总结一些算法代码了，感觉会是一个长期的总结过程，而且还要保持长期热情，只能加油吧。之前技能点全点在做游戏上了，但如果真的决定要改变世界，那就不能止步不前了。</p><p>这个总结目前来说还比较简单片面，后续可能考虑针对各个算法进行单一深入应用总结。</p><p><img src="/article/dba7e729/wallhaven-5g22q5_1920x1080.png" alt="wallhaven-5g22q5_1920x1080"></p><h1 id="哈希"><a href="#哈希" class="headerlink" title="哈希"></a>哈希</h1><p>这一部分其实主要是利用哈希表来辅助解决问题。</p><p>可能困难比较大的是<strong>记住哈希表的使用方式</strong>（呃呃这就是记性差的坏处了）</p><p>记住之后很多问题在考虑到查找、拼接就可以直接从哈希表入手了：</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">unordered_map&lt;string, vector&lt;string&gt;&gt; groups;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> it = groups.<span class="built_in">begin</span>(); it != groups.<span class="built_in">end</span>(); it++)</span><br><span class="line">&#123;</span><br><span class="line">    ans.<span class="built_in">emplace_back</span>(it-&gt;second);           <span class="comment">// 每一组键值对的值加入结果中</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">unordered_set&lt;<span class="type">int</span>&gt; <span class="title">st</span><span class="params">(nums.begin(), nums.end())</span></span>; <span class="comment">// 把 nums 转成哈希集合</span></span><br><span class="line">st.<span class="built_in">contains</span>(x - <span class="number">1</span>); <span class="comment">// 哈希判断条件</span></span><br></pre></td></tr></table></figure><p>经典题目链接：</p><p><a href="https://leetcode.cn/problems/group-anagrams/?envType=study-plan-v2&envId=top-100-liked">49. 字母异位词分组 - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/longest-consecutive-sequence/?envType=study-plan-v2&envId=top-100-liked">128. 最长连续序列 - 力扣（LeetCode）</a></p><h1 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h1><p>双指针题目比较灵活，可以有以下两类（目前）：</p><ol><li>指针同时出发，主要挪动一个指针，满足特定条件再挪动另一个指针</li><li>指针同时出发，但是位于数列两端，进行比较选择挪动的指针</li></ol><p>代表性题目分别有：</p><p><a href="https://leetcode.cn/problems/move-zeroes/?envType=study-plan-v2&envId=top-100-liked">283. 移动零 - 力扣（LeetCode）</a></p><p><a href="https://leetcode.cn/problems/trapping-rain-water/?envType=study-plan-v2&envId=top-100-liked">42. 接雨水 - 力扣（LeetCode）</a></p><h1 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h1><p>先附上比较玄妙的一道题：</p><p><a href="https://leetcode.cn/problems/find-all-anagrams-in-a-string/?envType=study-plan-v2&envId=top-100-liked">438. 找到字符串中所有字母异位词 - 力扣（LeetCode）</a></p><p>这个的话比较字面意思，有点像双指针，主要通过动态调节窗口大小，来满足特定条件</p><p>主要操作是拓展窗口、缩减窗口、比较、选择。</p><p>然后可能会和子串在一起。</p><h1 id="子串"><a href="#子串" class="headerlink" title="子串"></a>子串</h1><h1 id="普通数组"><a href="#普通数组" class="headerlink" title="普通数组"></a>普通数组</h1><h1 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h1><h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><p>奇妙的题目：<a href="https://leetcode.cn/problems/linked-list-cycle-ii/solutions/12616/linked-list-cycle-ii-kuai-man-zhi-zhen-shuang-zhi-/?envType=study-plan-v2&envId=top-100-liked">142. 环形链表 II - 力扣（LeetCode）</a></p><h1 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h1><h1 id="图论"><a href="#图论" class="headerlink" title="图论"></a>图论</h1><h1 id="回溯"><a href="#回溯" class="headerlink" title="回溯"></a>回溯</h1><p>主要是有一个标准的板子</p><p>在此记录一下（其实感觉不是很难）</p><p>题目出处：<a href="https://leetcode.cn/problems/permutations/description/?envType=study-plan-v2&envId=top-100-liked">46. 全排列 - 力扣（LeetCode）</a></p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; res;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; path;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">backtracking</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums, vector&lt;<span class="type">bool</span>&gt;&amp; used)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (path.<span class="built_in">size</span>() == nums.<span class="built_in">size</span>())</span><br><span class="line">        &#123;</span><br><span class="line">            res.<span class="built_in">push_back</span>(path);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; nums.<span class="built_in">size</span>(); i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (used[i] == <span class="literal">true</span>)   <span class="comment">//如果该元素被使用过了，则直接跳过</span></span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">            used[i] = <span class="literal">true</span>;        <span class="comment">//下面要用，先标记上已使用</span></span><br><span class="line">            path.<span class="built_in">push_back</span>(nums[i]);</span><br><span class="line">            <span class="built_in">backtracking</span>(nums, used);</span><br><span class="line">            path.<span class="built_in">pop_back</span>();       <span class="comment">//回溯path和used，即将本层的处理全部Ctrl + Z(撤销~~)</span></span><br><span class="line">            used[i] = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">permute</span>(vector&lt;<span class="type">int</span>&gt;&amp; nums) </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function">vector&lt;<span class="type">bool</span>&gt; <span class="title">used</span><span class="params">(nums.size(), <span class="literal">false</span>)</span></span>;</span><br><span class="line">        <span class="built_in">backtracking</span>(nums, used);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>还有感觉时不时可以回忆一下n皇后：<a href="https://leetcode.cn/problems/n-queens/?envType=study-plan-v2&envId=top-100-liked">51. N 皇后 - 力扣（LeetCode）</a></p><p>把**行（row）**视为回溯推进的路标！</p><p>感觉重要的就是路标的标定和查找。</p><h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h1><p>感觉是因为自己有一个很笨笨的方法，导致写的每次逻辑都非常不通畅。</p><p>因此在此记录下两者区别：</p><p>题目出处：<a href="https://leetcode.cn/problems/find-minimum-in-rotated-sorted-array/solutions/698479/xun-zhao-xuan-zhuan-pai-xu-shu-zu-zhong-5irwp/?envType=study-plan-v2&envId=top-100-liked">153. 寻找旋转排序数组中的最小值 - 力扣（LeetCode）</a></p><p>官方题解：</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">findMin</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> low = <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> high = nums.<span class="built_in">size</span>() - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (low &lt; high) &#123;</span><br><span class="line">            <span class="type">int</span> pivot = low + (high - low) / <span class="number">2</span>;</span><br><span class="line">            <span class="keyword">if</span> (nums[pivot] &lt; nums[high]) &#123;</span><br><span class="line">                high = pivot;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                low = pivot + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> nums[low];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">作者：力扣官方题解</span><br><span class="line">链接：https:<span class="comment">//leetcode.cn/problems/find-minimum-in-rotated-sorted-array/solutions/698479/xun-zhao-xuan-zhuan-pai-xu-shu-zu-zhong-5irwp/</span></span><br><span class="line">来源：力扣（LeetCode）</span><br><span class="line">著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</span><br></pre></td></tr></table></figure><p>我的铸币理解：</p><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">findMin</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(nums.<span class="built_in">size</span>() == <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">return</span> nums[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">find</span>(<span class="number">0</span>,nums.<span class="built_in">size</span>()<span class="number">-1</span>,nums);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">find</span><span class="params">(<span class="type">int</span> left,<span class="type">int</span> right,vector&lt;<span class="type">int</span>&gt; nums)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="type">int</span> mid = (left + right)/<span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(left == right<span class="number">-1</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> nums[right] &gt; nums[left] ? nums[left] : nums[right];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(nums[mid]&lt;nums[left])</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">find</span>(left,mid,nums);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(nums[mid]&gt;nums[right])</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="built_in">find</span>(mid,right,nums);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> nums[left];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h1 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h1><h1 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h1><h1 id="贪心算法"><a href="#贪心算法" class="headerlink" title="贪心算法"></a>贪心算法</h1><p>嘶……</p><p>大部分贪心都被我用dp过去了……</p><p>不过这道倒是dp没想出来:</p><p><a href="https://leetcode.cn/problems/jump-game-ii/?envType=study-plan-v2&envId=top-100-liked">45. 跳跃游戏 II - 力扣（LeetCode）</a></p><h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><p>感觉没有想象中的那么恐怖，其实就是要找到一条可以表示所有情况的通式。</p><p>接着找到他的初状态就可以了。</p><p>最好是要常备草稿纸！</p><h1 id="多维动态规划"><a href="#多维动态规划" class="headerlink" title="多维动态规划"></a>多维动态规划</h1><h1 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h1>]]></content>
      
      
      <categories>
          
          <category> 算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 学习ing </tag>
            
            <tag> 哈希 </tag>
            
            <tag> 双指针 </tag>
            
            <tag> 滑动窗口 </tag>
            
            <tag> 子串 </tag>
            
            <tag> 普通数组 </tag>
            
            <tag> 矩阵 </tag>
            
            <tag> 链表 </tag>
            
            <tag> 二叉树 </tag>
            
            <tag> 图论 </tag>
            
            <tag> 回溯 </tag>
            
            <tag> 二分查找 </tag>
            
            <tag> 栈 </tag>
            
            <tag> 堆 </tag>
            
            <tag> 贪心算法 </tag>
            
            <tag> 动态规划 </tag>
            
            <tag> 多维动态规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>博客迁移备忘录</title>
      <link href="/article/9312db38.html"/>
      <url>/article/9312db38.html</url>
      
        <content type="html"><![CDATA[<h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>这是一篇日后换电脑时备忘的博客，主要是关于hexo的迁移的。</p><h1 id="NodeJs"><a href="#NodeJs" class="headerlink" title="NodeJs"></a>NodeJs</h1><p>首先是安装nodejs，链接如下：<a href="https://nodejs.org/en/">https://nodejs.org/en/</a></p><p>然后是关于nodejs的配置路径问题：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> prefix <span class="string">&quot;D:\node\node_global&quot;</span></span><br><span class="line">npm config <span class="built_in">set</span> cache <span class="string">&quot;D:\node\node_cache</span></span><br></pre></td></tr></table></figure><p>以及镜像：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry https://registry.npmmirror.com</span><br></pre></td></tr></table></figure><p>最近想起来一件事，好像还得把所有安装的包给安装回来……</p><p>使用指令查看了下，依赖的包大概如下：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Administrator@PC-202207261451 MINGW64 /f/Hexo/My-Web (main)</span><br><span class="line">$ npm <span class="built_in">ls</span> -g --depth=0</span><br><span class="line">F:\node\node_global</span><br><span class="line">└── hexo-cli@4.3.2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Administrator@PC-202207261451 MINGW64 /f/Hexo/My-Web (main)</span><br><span class="line">$ npm list --depth=0</span><br><span class="line">hexo-site@0.0.0 F:\Hexo\My-Web</span><br><span class="line">├── hexo-abbrlink@2.2.1</span><br><span class="line">├── hexo-asset-img@1.2.0</span><br><span class="line">├── hexo-deployer-git@4.0.0</span><br><span class="line">├── hexo-generator-archive@2.0.0</span><br><span class="line">├── hexo-generator-category@2.0.0</span><br><span class="line">├── hexo-generator-index@4.0.0</span><br><span class="line">├── hexo-generator-search@2.4.3</span><br><span class="line">├── hexo-generator-tag@2.0.0</span><br><span class="line">├── hexo-helper-live2d@3.1.1</span><br><span class="line">├── hexo-renderer-ejs@2.0.0</span><br><span class="line">├── hexo-renderer-marked@7.0.1</span><br><span class="line">├── hexo-renderer-pug@3.0.0</span><br><span class="line">├── hexo-renderer-stylus@3.0.1</span><br><span class="line">├── hexo-server@3.0.0</span><br><span class="line">├── hexo-theme-butterfly@5.3.5</span><br><span class="line">├── hexo-theme-landscape@1.1.0</span><br><span class="line">├── hexo-wordcount@6.0.1</span><br><span class="line">├── hexo@7.3.0</span><br><span class="line">└── live2d-widget-model-tororo@1.0.5</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="拉取博客主站"><a href="#拉取博客主站" class="headerlink" title="拉取博客主站"></a>拉取博客主站</h1><p>这个配置完后，拉一下自己的博客官网进行迁移：</p><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git pull 这个就不给看了</span><br></pre></td></tr></table></figure><h1 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h1><p>然后有比较好的一些教程，先记录一下，都是建站时候的参考：</p><p><a href="https://blog.csdn.net/m0_74795952/article/details/146370818?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-5-146370818-blog-129290903.235%5Ev43%5Epc_blog_bottom_relevance_base7&spm=1001.2101.3001.4242.4&utm_relevant_index=8">基础美化教程</a></p><p><a href="https://blog.anheyu.com/posts/52d8.html">过渡动画</a></p><h1 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h1><p>最后防止自己忘了 补充下hexo的语法：</p><p>hexo三连起手：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><p>创建博客:</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new 博客名称</span><br></pre></td></tr></table></figure><p>创建页面：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new page 页面</span><br></pre></td></tr></table></figure><h1 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h1><ol><li><p>封面图片</p><p>补充一下封面图片的用法：</p><p>因为每次文章都会由插件生成一个唯一标识码，根据唯一标识码可以找到对应post的图片目录，比如本post的目录就为:<a href="http://aplainjane.github.io/article/9312db38">http://aplainjane.github.io/article/9312db38</a></p><p>然后由于修改了typora，每次插入图片会复制图片到该博客目录下的同名文件夹，所以最后生成的时候会把图片塞到对应article的目录下，故封面的图片设置就可以设置为：</p><p>top_img: <a href="http://aplainjane.github.io/article/9312db38/wallhaven-d69eom_1920x1080.png">http://aplainjane.github.io/article/9312db38/wallhaven-d69eom_1920x1080.png</a></p><p>cover: <a href="http://aplainjane.github.io/article/9312db38/wallhaven-d69eom_1920x1080.png">http://aplainjane.github.io/article/9312db38/wallhaven-d69eom_1920x1080.png</a></p></li><li><p>内嵌图片</p><p>由于已经修改typora内置参数，因此只需要将typora的图片路径修改为：博客名称&#x2F;图片名称</p><p>即可</p></li></ol><p>大概这样，最后再附张美图吧，以后哪里迁移出问题了再回来看看和补充</p><p><img src="/article/9312db38/wallhaven-d69eom_1920x1080.png" alt="wallhaven-d69eom_1920x1080"></p>]]></content>
      
      
      <categories>
          
          <category> 备忘 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> hexo </tag>
            
            <tag> 博客迁移 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/article/4a17b156.html"/>
      <url>/article/4a17b156.html</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>你好呀！</p><p>这里是aplainjane的博客，是漂泊了一阵子后想要给自己留下一些足迹的地方。</p><p>之前一直都没有好好留存技术博客和项目介绍的好习惯，</p><p>但是从现在开始也不算迟嘛！</p><p>无论如何对着世界喊出一声“hello world!”</p><p>世界都会给你它最热烈的回应。</p><p>此刻就是好好经营自己，经营生活的最佳时刻！</p><p>所以</p><p>你好，世界！</p><p>后续会陆陆续续把做过的一些项目和文档都搬运过来，嘿嘿。</p><p>希望能一直坚持下去吧！</p>]]></content>
      
      
      <categories>
          
          <category> 杂谈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 碎碎念 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
