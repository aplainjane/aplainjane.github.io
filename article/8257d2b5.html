<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试 | 去远方</title><meta name="author" content="APlainJane"><meta name="copyright" content="APlainJane"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="前言这个是针对于知识工程的学习与进一步实践，个人感觉难度挺高的，前后花费了大概有三周的时间，第一周主要是解决依赖的各种报错问题，第二周主要用在数据集的裁切和平台迁移上（这个主要受制于gpu的内存不够），第三周主要用在调优思路的探索和实践上，花了这么长时间感觉还是跟学校的课程安排有关，以及现在已经快接近五月了，保研人应该都懂……各种夏令营的事情和课程大作业搞得有点晕头撞向的，因此只能尽自己最大努力利">
<meta property="og:type" content="article">
<meta property="og:title" content="自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试">
<meta property="og:url" content="https://aplainjane.github.io/article/8257d2b5.html">
<meta property="og:site_name" content="去远方">
<meta property="og:description" content="前言这个是针对于知识工程的学习与进一步实践，个人感觉难度挺高的，前后花费了大概有三周的时间，第一周主要是解决依赖的各种报错问题，第二周主要用在数据集的裁切和平台迁移上（这个主要受制于gpu的内存不够），第三周主要用在调优思路的探索和实践上，花了这么长时间感觉还是跟学校的课程安排有关，以及现在已经快接近五月了，保研人应该都懂……各种夏令营的事情和课程大作业搞得有点晕头撞向的，因此只能尽自己最大努力利">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://aplainjane.github.io/article/8257d2b5/wallhaven-9oxme1_1920x1080.png">
<meta property="article:published_time" content="2025-04-28T11:17:51.000Z">
<meta property="article:modified_time" content="2025-04-29T01:07:42.140Z">
<meta property="article:author" content="APlainJane">
<meta property="article:tag" content="cv">
<meta property="article:tag" content="自动驾驶">
<meta property="article:tag" content="课程学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://aplainjane.github.io/article/8257d2b5/wallhaven-9oxme1_1920x1080.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试",
  "url": "https://aplainjane.github.io/article/8257d2b5.html",
  "image": "http://aplainjane.github.io/article/8257d2b5/wallhaven-9oxme1_1920x1080.png",
  "datePublished": "2025-04-28T11:17:51.000Z",
  "dateModified": "2025-04-29T01:07:42.140Z",
  "author": [
    {
      "@type": "Person",
      "name": "APlainJane",
      "url": "https://aplainjane.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/me.jpg"><link rel="canonical" href="https://aplainjane.github.io/article/8257d2b5.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'medium_zoom',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/self.css"><link rel="stylesheet" href="/css/background.css"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><div class="loading-img"></div><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><script>window.paceOptions = {
  restartOnPushState: false
}

btf.addGlobalFn('pjaxSend', () => {
  Pace.restart()
}, 'pace_restart')

</script><link rel="stylesheet" href="/css/progress_bar.css"/><script src="https://cdn.jsdelivr.net/npm/pace-js/pace.min.js"></script><div id="web_bg" style="background-image: url(/img/fullbackground.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/me.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(http://aplainjane.github.io/article/8257d2b5/wallhaven-9oxme1_1920x1080.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">去远方</span></a><a class="nav-page-title" href="/"><span class="site-name">自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-04-28T11:17:51.000Z" title="发表于 2025-04-28 19:17:51">2025-04-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-04-29T01:07:42.140Z" title="更新于 2025-04-29 09:07:42">2025-04-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">9.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>44分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>这个是针对于知识工程的学习与进一步实践，个人感觉难度挺高的，前后花费了大概有三周的时间，第一周主要是解决依赖的各种报错问题，第二周主要用在数据集的裁切和平台迁移上（这个主要受制于gpu的内存不够），第三周主要用在调优思路的探索和实践上，花了这么长时间感觉还是跟学校的课程安排有关，以及现在已经快接近五月了，保研人应该都懂……各种夏令营的事情和课程大作业搞得有点晕头撞向的，因此只能尽自己最大努力利用时间来完成这个课程实践，最后嘛还是有许多遗憾，但只能止步于此了……</p>
<h1 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h1><h2 id="使用model-art平台"><a href="#使用model-art平台" class="headerlink" title="使用model art平台"></a>使用model art平台</h2><p>模型链接：</p>
<p><a target="_blank" rel="noopener" href="https://github.com/OpenDriveLab/ViDAR">https://github.com/OpenDriveLab/ViDAR</a></p>
<p>前置：</p>
<p>配置model art镜像</p>
<p><img src="/article/8257d2b5/fc91c387a9f5fa96a87e8662028e0c8.png" alt="fc91c387a9f5fa96a87e8662028e0c8"></p>
<p><img src="/article/8257d2b5/image-20250401153203321.png" alt="image-20250401153203321"></p>
<p><img src="/article/8257d2b5/image-20250401153223717.png" alt="image-20250401153223717"></p>
<p><img src="/article/8257d2b5/image-20250401153259882.png" alt="image-20250401153259882"></p>
<p><img src="/article/8257d2b5/image-20250401153426317.png" alt="image-20250401153426317"></p>
<p>通过以上步骤进行镜像配置，就不过多赘述了，当时的解释md文件被我删除了……</p>
<h2 id="遇到的问题以及解决方法"><a href="#遇到的问题以及解决方法" class="headerlink" title="遇到的问题以及解决方法"></a>遇到的问题以及解决方法</h2><ol>
<li><p>依赖报错问题：主要集中在numpy的版本上，因为model art本身要求的numpy版本较高，但是ViDAR又需要较低版本导致冲突，后面配置了一个脚本用于解决大部分问题：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim install_deps.sh</span><br></pre></td></tr></table></figure>

<p>然后：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置清华源</span></span><br><span class="line">PIP_SOURCE=<span class="string">&quot;-i https://pypi.tuna.tsinghua.edu.cn/simple --trusted-host pypi.tuna.tsinghua.edu.cn&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 临时移除 ModelArts SDK 以避免干扰</span></span><br><span class="line"><span class="built_in">export</span> ORIGINAL_PYTHONPATH=<span class="variable">$PYTHONPATH</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=$(<span class="built_in">echo</span> <span class="variable">$PYTHONPATH</span> | sed <span class="string">&#x27;s|/home/ma-user/modelarts-dev/modelarts-sdk||g&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印环境信息</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Checking Python and PyTorch versions...&quot;</span></span><br><span class="line">python -c <span class="string">&quot;import sys, torch; print(&#x27;Python:&#x27;, sys.version); print(&#x27;PyTorch:&#x27;, torch.__version__, &#x27;CUDA:&#x27;, torch.cuda.is_available())&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 1：修复依赖冲突</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Fixing dependency conflicts...&quot;</span></span><br><span class="line">pip install numpy==1.23.5 --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install networkx==2.2 --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install pyasn1==0.6.1 --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install pandas==1.2.5 --force-reinstall <span class="variable">$PIP_SOURCE</span>  <span class="comment"># 确保 pandas 版本</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 2：处理“平台不支持”包，降级到兼容版本</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Fixing platform compatibility issues...&quot;</span></span><br><span class="line">pip install mmengine</span><br><span class="line">pip install PyYAML==6.0 charset-normalizer==3.3.2 fonttools==4.38.0 kiwisolver==1.4.5 \</span><br><span class="line">    lxml==4.9.3 matplotlib==3.5.2 simplejson==3.19.2 MarkupSafe==2.1.5 \</span><br><span class="line">    cffi==1.16.0 greenlet==3.0.3 ijson==3.2.4 SQLAlchemy==2.0.30 \</span><br><span class="line">    --force-reinstall <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 3：安装 mmcv-full==1.4.0</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing mmcv-full==1.4.0...&quot;</span></span><br><span class="line">pip install mmcv-full==1.4.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 4：安装 mmdet3d 剩余依赖</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing mmdet3d dependencies...&quot;</span></span><br><span class="line">pip install lyft_dataset_sdk nuscenes-devkit plyfile tensorboard numba==0.48.0 scikit-image==0.19.3 <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install numpy==1.23.5 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install mmcv-full==1.4.0 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 5：安装 mmdet==2.14.0 和 mmsegmentation==0.14.1</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing mmdet==2.14.0 and mmsegmentation==0.14.1...&quot;</span></span><br><span class="line">pip install mmdet==2.14.0 <span class="variable">$PIP_SOURCE</span></span><br><span class="line">pip install mmsegmentation==0.14.1 <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/open-mmlab/mmdetection3d.git</span><br><span class="line"><span class="built_in">cd</span> mmdetection3d</span><br><span class="line">git checkout v0.17.1 <span class="comment"># Other versions may not be compatible.</span></span><br><span class="line">python setup.py install</span><br><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 6：安装 detectron2 和其他依赖</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing detectron2 and other dependencies...&quot;</span></span><br><span class="line">pip install einops fvcore seaborn iopath==0.1.9 timm==0.6.13 typing-extensions==4.5.0 \</span><br><span class="line">    pylint ipython==8.12 matplotlib==3.5.2 numba==0.48.0 setuptools==59.5.0 <span class="variable">$PIP_SOURCE</span></span><br><span class="line">python -m pip install <span class="string">&#x27;git+https://github.com/facebookresearch/detectron2.git&#x27;</span> <span class="variable">$PIP_SOURCE</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤 7：安装 ViDAR 和 chamferdistance</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installing ViDAR and chamferdistance...&quot;</span></span><br><span class="line"><span class="keyword">if</span> [ ! -d <span class="string">&quot;ViDAR&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">    git <span class="built_in">clone</span> https://github.com/OpenDriveLab/ViDAR</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="built_in">cd</span> ViDAR</span><br><span class="line"><span class="built_in">mkdir</span> -p pretrained</span><br><span class="line"><span class="built_in">cd</span> pretrained</span><br><span class="line">wget https://github.com/zhiqi-li/storage/releases/download/v1.0/r101_dcn_fcos3d_pretrain.pth || <span class="built_in">echo</span> <span class="string">&quot;Pretrained model download failed, continuing...&quot;</span></span><br><span class="line"><span class="built_in">cd</span> ../third_lib/chamfer_dist/chamferdist/</span><br><span class="line">pip install . <span class="variable">$PIP_SOURCE</span></span><br><span class="line"><span class="built_in">cd</span> ../../..</span><br><span class="line">pip install matplotlib==3.5.3 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install pyparsing==2.4.7 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install kiwisolver==1.3.2 -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class="line">pip install --user prettytable==3.7.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提示完成</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;Installation complete. If errors occurred, check logs above.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可选：隔离环境（注释掉，需手动启用</span></span><br><span class="line"><span class="comment"># echo &quot;If conflicts persist, consider creating a clean environment:&quot;</span></span><br><span class="line"><span class="comment"># echo &quot;conda create -n vidar_clean python=3.8&quot;</span></span><br><span class="line"><span class="comment"># echo &quot;conda activate vidar_clean&quot;</span></span><br><span class="line"><span class="comment"># echo &quot;Then rerun this script.&quot;</span></span><br></pre></td></tr></table></figure>

<p>然后就是喜闻乐见的一键解决问题了</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x install_deps.sh</span><br><span class="line">./install_deps.sh</span><br></pre></td></tr></table></figure>

<p>然后有两个地方需要修改：</p>
<p><img src="/article/8257d2b5/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_2025-04-15_210139_539.png" alt="微信图片_2025-04-15_210139_539"></p>
<p><img src="/article/8257d2b5/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_2025-04-15_210556_226.png" alt="微信图片_2025-04-15_210556_226"></p>
<p>之后到达vidar目录下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">CONFIG=ViDAR/projects/configs/vidar_pretrain/OpenScene/vidar_OpenScene_train_1_8_3future.py GPU_NUM=1</span><br><span class="line"></span><br><span class="line">CONFIG=projects/configs/vidar_pretrain/OpenScene/vidar_OpenScene_mini_1_8_3future.py</span><br><span class="line"></span><br><span class="line">GPU_NUM=1</span><br><span class="line"></span><br><span class="line">./tools/dist_train.sh <span class="variable">$&#123;CONFIG&#125;</span> <span class="variable">$&#123;GPU_NUM&#125;</span>  </span><br></pre></td></tr></table></figure>
</li>
<li><p>数据集</p>
<p>使用openxlab软件包。注：最高版本openxlab需要python≥3.8，因此需要创建一个虚拟环境安装</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n openxlab python=3.9</span><br><span class="line">pip install openxlab</span><br><span class="line">openxlab login <span class="comment"># 需要创建openxlab账号之后，创建access key再在这里登录</span></span><br><span class="line"><span class="comment">#我的AK/SK放在代码块外面</span></span><br><span class="line">openxlab dataset download --dataset-repo OpenDriveLab/OpenScene --source-path /openscene-v1.1/openscene_sensor_mini_camera.tgz  --target-path .</span><br><span class="line">openxlab dataset download --dataset-repo OpenDriveLab/OpenScene --source-path /openscene-v1.1/openscene_sensor_mini_lidar.tgz  --target-path .</span><br></pre></td></tr></table></figure>

<p>Access Key: wgakjbrzyyxljprb1b2z Secret Key: rnyq568lwdpayblrb744qdmxyg4xz19vo3b0azog</p>
<p>然后用上面的指令解压。大概占据硬盘空间170GB左右，因为要解压所以硬盘建议大概250-300GB</p>
<p>数据集解压后自动移动 MergedPointCloud 到目标路径：</p>
<p>可以运行脚本vim fix_mergedpointcloud.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根目录路径（根据你实际目录修改）</span></span><br><span class="line">bad_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/OpenDriveLab___OpenScene/openscene-v1.1/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line">correct_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历所有 subdir</span></span><br><span class="line"><span class="keyword">for</span> subdir <span class="keyword">in</span> os.listdir(bad_root):</span><br><span class="line">    full_bad_path = os.path.join(bad_root, subdir, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line">    full_target_dir = os.path.join(correct_root, subdir)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(full_bad_path):</span><br><span class="line">        target_path = os.path.join(full_target_dir, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Moving <span class="subst">&#123;full_bad_path&#125;</span> --&gt; <span class="subst">&#123;target_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        os.makedirs(full_target_dir, exist_ok=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> os.path.exists(target_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;  - Skipping <span class="subst">&#123;target_path&#125;</span> (already exists)&quot;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            shutil.move(full_bad_path, target_path)</span><br></pre></td></tr></table></figure>

<p>执行：python fix_mergedpointcloud.py</p>
<p>或者创建软连接</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">bad_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/OpenDriveLab___OpenScene/openscene-v1.1/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line">correct_root = <span class="string">&quot;ViDAR/data/openscene_v1.1/sensor_blobs/mini&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> sequence <span class="keyword">in</span> os.listdir(bad_root):</span><br><span class="line">    bad_mp = os.path.join(bad_root, sequence, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line">    correct_target_dir = os.path.join(correct_root, sequence)</span><br><span class="line">    correct_link_path = os.path.join(correct_target_dir, <span class="string">&quot;MergedPointCloud&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(bad_mp):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(correct_target_dir):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;路径不存在，创建中：<span class="subst">&#123;correct_target_dir&#125;</span>&quot;</span>)</span><br><span class="line">            os.makedirs(correct_target_dir)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(correct_link_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;创建软链接：<span class="subst">&#123;correct_link_path&#125;</span> -&gt; <span class="subst">&#123;bad_mp&#125;</span>&quot;</span>)</span><br><span class="line">            os.symlink(os.path.abspath(bad_mp), correct_link_path)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;已存在：<span class="subst">&#123;correct_link_path&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>openscene_metadata_mini.tgz可以下载本地再直接上传</p>
<p>最后： <code>python tools/collect_nuplan_data.py mini</code></p>
</li>
<li><p>训练的一些报错</p>
<p><strong>ninja报错</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">RuntimeError: Ninja is required to load C++</span><br></pre></td></tr></table></figure>

<p>解决：从源码构建并本地安装</p>
<ol>
<li><p>下载和构建 Ninja：</p>
<ul>
<li><p>克隆 Ninja 官方仓库：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">git clone &lt;https://github.com/ninja-build/ninja.git&gt;</span><br><span class="line">cd ninja</span><br><span class="line">python configure.py --bootstrap</span><br></pre></td></tr></table></figure>
</li>
<li><p>这会生成 <code>ninja</code> 二进制文件。</p>
</li>
</ul>
</li>
<li><p>创建本地目录并移动文件：</p>
<ul>
<li><p>创建 <code>~/bin</code> 目录（如果不存在）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">mkdir -p ~/bin</span><br></pre></td></tr></table></figure>
</li>
<li><p>将 <code>ninja</code> 二进制文件移动到 <code>~/bin</code>：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">mv ninja ~/bin/</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>更新 PATH 环境变量：</p>
<ul>
<li><p>临时添加至当前会话：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">export PATH=~/bin:$PATH</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p><strong>验证安装</strong>：</p>
<ul>
<li>运行 <code>ninja --version</code> 检查是否成功。</li>
</ul>
</li>
</ol>
<p><strong><code>crypt.h</code>报错</strong></p>
<p>解决：</p>
<ul>
<li><p>步骤 1：确认 glibc-2.27 源码</p>
<ul>
<li><p>确保你已从 <a target="_blank" rel="noopener" href="https://ftp.gnu.org/gnu/glibc/glibc-2.27.tar.xz">GNU FTP 服务器</a> 下载并解压了 glibc-2.27.tar.xz 文件。如果未下载，使用以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ruby</span><br><span class="line">wget &lt;https://ftp.gnu.org/gnu/glibc/glibc-2.27.tar.xz&gt;</span><br><span class="line">tar -xJf glibc-2.27.tar.xz</span><br></pre></td></tr></table></figure>
</li>
<li><p>确认解压后生成了 <code>glibc-2.27</code> 目录，并包含 <code>include</code> 子目录。</p>
</li>
</ul>
<p>步骤 2：复制所有头文件</p>
<ul>
<li><p>将 glibc-2.27&#x2F;include 目录下的所有头文件复制到你的本地 ~&#x2F;include 目录，以确保所有依赖头文件（如 <code>features.h</code>、<code>stdint.h</code> 等）都可用：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">mkdir -p ~/include</span><br><span class="line">cp -r glibc-2.27/include/* ~/include/</span><br></pre></td></tr></table></figure>
</li>
<li><p>这将复制包括 <code>crypt.h</code> 在内的所有头文件到 ~&#x2F;include，确保编译器能找到所有必需的依赖。</p>
</li>
</ul>
<p>步骤 3：设置包含路径</p>
<ul>
<li><p>设置 <code>CPLUS_INCLUDE_PATH</code> 环境变量，确保编译器优先搜索 ~&#x2F;include 目录：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">export CPLUS_INCLUDE_PATH=~/include:$CPLUS_INCLUDE_PATH</span><br></pre></td></tr></table></figure>
</li>
<li><p>验证环境变量设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bash</span><br><span class="line">echo $CPLUS_INCLUDE_PATH</span><br></pre></td></tr></table></figure>

<p>应包含 <code>~/include</code>。</p>
</li>
</ul>
<p>步骤 4：检查系统头文件</p>
<p>首先，检查你的环境中是否已有必要的头文件：</p>
<ul>
<li><p>运行 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ls /usr/include/crypt.h</span><br></pre></td></tr></table></figure>

<p> 查看是否已有 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">crypt.h</span><br></pre></td></tr></table></figure>

<p>。如果存在，尝试使用系统编译器：</p>
<ul>
<li>运行 <code>export CC=/usr/bin/gcc</code> 和 <code>export CXX=/usr/bin/g++</code>。</li>
<li>然后取消设置 <code>CPLUS_INCLUDE_PATH</code>：<code>unset CPLUS_INCLUDE_PATH</code>。</li>
<li>重新运行训练脚本：<code>./tools/dist_train.sh $&#123;CONFIG&#125; $&#123;GPU_NUM&#125;</code>。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>GLIBCXX_3.4.29报错</strong></p>
<p>参考：</p>
<p>[如何解决version &#96;GLIBCXX_3.4.29‘ not found的问题_glibcxx not found-CSDN博客](<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_39379635/article/details/129159713">https://blog.csdn.net/weixin_39379635/article/details/129159713</a>)</p>
<p><strong>解决：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ImportError: /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6: version `GLIBCXX_3.4.29&#x27; not found</span><br></pre></td></tr></table></figure>

<p>1、使用指令先看下系统目前都有哪些版本的</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strings /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6 | grep GLIBCXX</span><br></pre></td></tr></table></figure>

<p>发现只到3.4.22</p>
<p>2、来查看当前系统中其它的同类型文件，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo find / -name &quot;libstdc++.so.6*&quot;</span><br></pre></td></tr></table></figure>

<p>找到一个版本比较高的 &#x2F;home&#x2F;ma-user&#x2F;anaconda3&#x2F;envs&#x2F;vidar&#x2F;lib&#x2F;libstdc++.so.6.0.29</p>
<p>查看</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strings /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6.0.29 | grep GLIBCXX</span><br></pre></td></tr></table></figure>

<p>有了3.4.29</p>
<p>3、复制到指定目录并建立新的链接</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">复制</span><br><span class="line">sudo cp /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6.0.29 /home/ma-user/anaconda3/envs/vidar/lib/</span><br><span class="line"></span><br><span class="line">删除之前链接</span><br><span class="line">sudo rm /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6</span><br><span class="line"></span><br><span class="line">创建新的链接</span><br><span class="line">sudo ln -s /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6.0.29 /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6</span><br></pre></td></tr></table></figure>

<p>验证</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">strings /home/ma-user/anaconda3/envs/vidar/lib/libstdc++.so.6 | grep GLIBCXX</span><br></pre></td></tr></table></figure>

<p>有了3.4.29</p>
<p><strong>另：如果是&#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libstdc++.so.6报错，使用：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>

<p><strong>GPU爆内存</strong></p>
<p>cuda out of memory</p>
<p>只训练mini数据集的一部分，注意留的数据meta_datas里的文件夹名字和sensor_blobs里文件夹名对应</p>
<p><strong>fsspec 与 Python 3.8 兼容性问题</strong></p>
<p>TypeError: ‘type’ object is not subscriptable</p>
<p>解决方法：降低到fsspec可以兼容3.8的版本</p>
<p>pip install fsspec&#x3D;&#x3D;2025.3.0</p>
</li>
</ol>
<h2 id="ViDAR模型实现分析"><a href="#ViDAR模型实现分析" class="headerlink" title="ViDAR模型实现分析"></a>ViDAR模型实现分析</h2><h3 id="模型架构概述"><a href="#模型架构概述" class="headerlink" title="模型架构概述"></a>模型架构概述</h3><p>ViDAR（Visual Point Cloud Forecasting enables Scalable Autonomous Driving）是一个基于BEVFormer架构的模型，专注于自动驾驶场景中的视觉点云预测。从 <code>vidar_transformer.py</code> 文件可以看出，它主要实现了一个预测变换器（PredictionTransformer）。</p>
<h3 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h3><ol>
<li>PredictionTransformer ：<ul>
<li>这是ViDAR的核心组件，用于从多帧BEV特征预测下一帧的BEV特征</li>
<li>使用了自定义的解码器来处理时序信息</li>
</ul>
</li>
<li>注意力机制 ：<ul>
<li>时间自注意力（TemporalSelfAttention）：处理时间维度上的信息</li>
<li>空间交叉注意力（MSDeformableAttention3D）：处理3D空间中的信息</li>
<li>自定义可变形注意力（CustomMSDeformableAttention）：用于处理特征对齐</li>
</ul>
</li>
</ol>
<h3 id="项目结构"><a href="#项目结构" class="headerlink" title="项目结构"></a>项目结构</h3><p>项目结构显示ViDAR是基于BEVFormer进行扩展的：</p>
<p>projects&#x2F;<br>├── configs&#x2F;<br>│   ├── <em>base</em>&#x2F;<br>│   ├── bevformer&#x2F;<br>│   ├── vidar_finetune&#x2F;    # ViDAR微调配置<br>│   └── vidar_pretrain&#x2F;    # ViDAR预训练配置<br>└── mmdet3d_plugin&#x2F;<br>    ├── bevformer&#x2F;         # BEVFormer相关模块<br>    ├── core&#x2F;              # 核心评估和功能模块<br>    ├── datasets&#x2F;          # 数据集处理<br>    ├── dd3d&#x2F;              # 3D检测相关模块<br>    └── models&#x2F;            # 模型定义</p>
<h3 id="与BEVFormer的关系"><a href="#与BEVFormer的关系" class="headerlink" title="与BEVFormer的关系"></a>与BEVFormer的关系</h3><p>ViDAR似乎是在BEVFormer基础上的扩展，专注于未来帧预测：</p>
<ul>
<li>BEVFormer主要关注多视角图像到BEV表示的转换</li>
<li>ViDAR则进一步关注BEV表示的时序预测，实现对未来场景的预测</li>
</ul>
<h2 id="调优思路"><a href="#调优思路" class="headerlink" title="调优思路"></a>调优思路</h2><h3 id="融合Nskg"><a href="#融合Nskg" class="headerlink" title="融合Nskg"></a>融合Nskg</h3><p>写在前面：</p>
<p>这个项目其实没有想象的复杂，大概如下：</p>
<p>ViDAR模型似乎是一个基于BEVFormer架构的3D检测&#x2F;分割模型，它利用MMDetection3D框架实现，支持多视角图像到BEV表示的转换。该模型具有灵活的配置系统、插件扩展能力和完善的训练功能。</p>
<p>那么有了以上信息就好做了，首先学习下MMDetection3D的使用方法，Vidar只不过在上面多封装了一层，那么这一层应该也可以写插件进行拓展</p>
<p>核心目录：</p>
<ol>
<li>模型定义文件（可能在 projects&#x2F;mmdet3d_plugin&#x2F;bevformer&#x2F; 目录下）</li>
<li>配置文件（通过命令行参数 config 指定）</li>
<li>自定义训练函数 custom_train_model 的实现</li>
</ol>
<ul>
<li><p>论文1：nuScenes Knowledge Graph (nSKG)</p>
<p><strong>nuScenes Knowledge Graph (nSKG)</strong> 文章的内容可以很好地融入对 <strong>ViDAR: Visual Point Cloud Forecasting</strong> 模型的理解和调优中，尤其是在以下几个方面：</p>
<ol>
<li><strong>丰富场景表示</strong>：nSKG 提供了 nuScenes 数据集的综合语义表示，包含交通场景中的实体（如车辆、行人、车道、交通信号灯）和它们之间的语义与空间关系。这可以增强 ViDAR 的输入数据，改善其点云预测和下游任务（如感知、规划）的性能。</li>
<li><strong>数据处理改进</strong>：nSKG 的结构化数据（以知识图谱和 PyTorch Geometric 格式提供）可以直接用于 ViDAR 的数据管道，减少数据预处理的工程负担。</li>
<li><strong>模型架构增强</strong>：nSKG 的异构图表示可以与 ViDAR 的 Transformer 或 BEVFormer 模块结合，引入图神经网络（GNN）来处理语义关系，提升预测的鲁棒性和可解释性。</li>
<li><strong>调优方向</strong>：利用 nSKG 的丰富上下文（如车道拓扑、代理关系），可以优化 ViDAR 的超参数、数据增强策略和损失函数，特别是在处理复杂交通场景时。</li>
</ol>
</li>
</ul>
<p>实际修改：</p>
<p><img src="/article/8257d2b5/e879ac0c92d040202e3ba7450e5459b.png" alt="e879ac0c92d040202e3ba7450e5459b"></p>
<h1 id="ViDAR项目集成nSTP的工作总结"><a href="#ViDAR项目集成nSTP的工作总结" class="headerlink" title="ViDAR项目集成nSTP的工作总结"></a>ViDAR项目集成nSTP的工作总结</h1><p>根据当前代码库，我将总结从初始状态到现在为止，为了集成nSTP（Neural Scene-Time Priors）所做的工作。</p>
<h2 id="1-核心文件创建"><a href="#1-核心文件创建" class="headerlink" title="1. 核心文件创建"></a>1. 核心文件创建</h2><h3 id="1-1-nSTP编码器模块"><a href="#1-1-nSTP编码器模块" class="headerlink" title="1.1 nSTP编码器模块"></a>1.1 nSTP编码器模块</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\bevformer\modules\nstp_encoder.py</code></p>
<p><strong>主要功能</strong>:</p>
<ul>
<li>创建了<code>NSTPEncoder</code>类：使用图神经网络（GraphSAGE或GAT）处理nSTP图数据</li>
<li>创建了<code>NSTPEnhancer</code>类：将nSTP特征与BEV特征融合，通过注意力机制增强BEV特征</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch_geometric.nn <span class="keyword">import</span> GraphSAGE, GATConv</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NSTPEncoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;nSTP图数据编码器&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, hidden_channels, out_channels, num_layers=<span class="number">3</span>, </span></span><br><span class="line"><span class="params">                 gnn_type=<span class="string">&#x27;graphsage&#x27;</span>, dropout=<span class="number">0.1</span>, aggr=<span class="string">&#x27;mean&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.in_channels = in_channels</span><br><span class="line">        <span class="variable language_">self</span>.hidden_channels = hidden_channels</span><br><span class="line">        <span class="variable language_">self</span>.out_channels = out_channels</span><br><span class="line">        <span class="variable language_">self</span>.num_layers = num_layers</span><br><span class="line">        <span class="variable language_">self</span>.gnn_type = gnn_type</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 输入特征投影</span></span><br><span class="line">        <span class="variable language_">self</span>.input_proj = nn.Linear(in_channels, hidden_channels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 图神经网络</span></span><br><span class="line">        <span class="keyword">if</span> gnn_type == <span class="string">&#x27;graphsage&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.gnn = GraphSAGE(</span><br><span class="line">                in_channels=hidden_channels,</span><br><span class="line">                hidden_channels=hidden_channels,</span><br><span class="line">                num_layers=num_layers,</span><br><span class="line">                out_channels=out_channels,</span><br><span class="line">                dropout=dropout,</span><br><span class="line">                aggr=aggr</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">elif</span> gnn_type == <span class="string">&#x27;gat&#x27;</span>:</span><br><span class="line">            <span class="comment"># 简化版GAT实现</span></span><br><span class="line">            <span class="variable language_">self</span>.gnn_layers = nn.ModuleList()</span><br><span class="line">            <span class="variable language_">self</span>.gnn_layers.append(GATConv(hidden_channels, hidden_channels))</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_layers - <span class="number">2</span>):</span><br><span class="line">                <span class="variable language_">self</span>.gnn_layers.append(GATConv(hidden_channels, hidden_channels))</span><br><span class="line">            <span class="variable language_">self</span>.gnn_layers.append(GATConv(hidden_channels, out_channels))</span><br><span class="line">            <span class="variable language_">self</span>.dropout = nn.Dropout(dropout)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;不支持的GNN类型: <span class="subst">&#123;gnn_type&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            data: PyG Data对象或包含x和edge_index的字典</span></span><br><span class="line"><span class="string">                </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            torch.Tensor: 节点特征</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 添加对None的处理</span></span><br><span class="line">        <span class="keyword">if</span> data <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 返回一个空的特征张量</span></span><br><span class="line">            <span class="keyword">return</span> torch.zeros((<span class="number">1</span>, <span class="variable language_">self</span>.out_channels), device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(data, <span class="string">&#x27;x&#x27;</span>) <span class="keyword">and</span> <span class="built_in">hasattr</span>(data, <span class="string">&#x27;edge_index&#x27;</span>):</span><br><span class="line">            x, edge_index = data.x, data.edge_index</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(data, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&#x27;x&#x27;</span> <span class="keyword">in</span> data <span class="keyword">and</span> <span class="string">&#x27;edge_index&#x27;</span> <span class="keyword">in</span> data:</span><br><span class="line">            x, edge_index = data[<span class="string">&#x27;x&#x27;</span>], data[<span class="string">&#x27;edge_index&#x27;</span>]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;警告: 输入数据格式不正确: <span class="subst">&#123;<span class="built_in">type</span>(data)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="comment"># 返回一个空的特征张量</span></span><br><span class="line">            <span class="keyword">return</span> torch.zeros((<span class="number">1</span>, <span class="variable language_">self</span>.out_channels), device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 确保x和edge_index是张量</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, torch.Tensor):</span><br><span class="line">            x = torch.tensor(x, dtype=torch.<span class="built_in">float</span>, device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(edge_index, torch.Tensor):</span><br><span class="line">            edge_index = torch.tensor(edge_index, dtype=torch.long, device=<span class="variable language_">self</span>.input_proj.weight.device)</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># 特征投影</span></span><br><span class="line">        x = <span class="variable language_">self</span>.input_proj(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 图神经网络处理</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.gnn_type == <span class="string">&#x27;graphsage&#x27;</span>:</span><br><span class="line">            x = <span class="variable language_">self</span>.gnn(x, edge_index)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># gat</span></span><br><span class="line">            <span class="keyword">for</span> i, layer <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="variable language_">self</span>.gnn_layers):</span><br><span class="line">                <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(<span class="variable language_">self</span>.gnn_layers) - <span class="number">1</span>:</span><br><span class="line">                    x = layer(x, edge_index)</span><br><span class="line">                    x = torch.relu(x)</span><br><span class="line">                    x = <span class="variable language_">self</span>.dropout(x)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    x = layer(x, edge_index)</span><br><span class="line">                    </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NSTPEnhancer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;nSTP特征增强器，用于增强BEV特征&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, bev_channels, nstp_channels, hidden_channels, bev_h, bev_w, use_attention=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.bev_channels = bev_channels</span><br><span class="line">        <span class="variable language_">self</span>.nstp_channels = nstp_channels</span><br><span class="line">        <span class="variable language_">self</span>.hidden_channels = hidden_channels</span><br><span class="line">        <span class="variable language_">self</span>.bev_h = bev_h</span><br><span class="line">        <span class="variable language_">self</span>.bev_w = bev_w</span><br><span class="line">        <span class="variable language_">self</span>.use_attention = use_attention</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征融合层</span></span><br><span class="line">        <span class="variable language_">self</span>.nstp_proj = nn.Linear(nstp_channels, hidden_channels)</span><br><span class="line">        <span class="variable language_">self</span>.bev_proj = nn.Linear(bev_channels, hidden_channels)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> use_attention:</span><br><span class="line">            <span class="comment"># 注意力机制</span></span><br><span class="line">            <span class="variable language_">self</span>.query_proj = nn.Linear(hidden_channels, hidden_channels)</span><br><span class="line">            <span class="variable language_">self</span>.key_proj = nn.Linear(hidden_channels, hidden_channels)</span><br><span class="line">            <span class="variable language_">self</span>.value_proj = nn.Linear(hidden_channels, hidden_channels)</span><br><span class="line">            <span class="variable language_">self</span>.attention_scale = hidden_channels ** -<span class="number">0.5</span></span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 输出投影</span></span><br><span class="line">        <span class="variable language_">self</span>.output_proj = nn.Linear(hidden_channels, bev_channels)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, bev_feat, nstp_feat, nstp_pos=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;前向传播</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            bev_feat (torch.Tensor): BEV特征 [B, C, H, W]</span></span><br><span class="line"><span class="string">            nstp_feat (torch.Tensor): nSTP节点特征 [B, N, C]</span></span><br><span class="line"><span class="string">            nstp_pos (torch.Tensor, optional): nSTP节点位置 [B, N, 2]</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            torch.Tensor: 增强后的BEV特征 [B, C, H, W]</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B, C, H, W = bev_feat.shape</span><br><span class="line">        bev_feat_flat = bev_feat.flatten(<span class="number">2</span>).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># [B, H*W, C]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 特征投影</span></span><br><span class="line">        bev_feat_proj = <span class="variable language_">self</span>.bev_proj(bev_feat_flat)  <span class="comment"># [B, H*W, hidden]</span></span><br><span class="line">        nstp_feat_proj = <span class="variable language_">self</span>.nstp_proj(nstp_feat)  <span class="comment"># [B, N, hidden]</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_attention:</span><br><span class="line">            <span class="comment"># 计算注意力</span></span><br><span class="line">            query = <span class="variable language_">self</span>.query_proj(bev_feat_proj)  <span class="comment"># [B, H*W, hidden]</span></span><br><span class="line">            key = <span class="variable language_">self</span>.key_proj(nstp_feat_proj)  <span class="comment"># [B, N, hidden]</span></span><br><span class="line">            value = <span class="variable language_">self</span>.value_proj(nstp_feat_proj)  <span class="comment"># [B, N, hidden]</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 注意力分数</span></span><br><span class="line">            attn = torch.bmm(query, key.transpose(<span class="number">1</span>, <span class="number">2</span>)) * <span class="variable language_">self</span>.attention_scale  <span class="comment"># [B, H*W, N]</span></span><br><span class="line">            attn = torch.softmax(attn, dim=-<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 加权特征</span></span><br><span class="line">            context = torch.bmm(attn, value)  <span class="comment"># [B, H*W, hidden]</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 融合特征</span></span><br><span class="line">            enhanced_feat = context + bev_feat_proj</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 简单平均</span></span><br><span class="line">            nstp_feat_expanded = nstp_feat_proj.mean(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>).expand(-<span class="number">1</span>, H*W, -<span class="number">1</span>)</span><br><span class="line">            enhanced_feat = bev_feat_proj + nstp_feat_expanded</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 输出投影</span></span><br><span class="line">        enhanced_feat = <span class="variable language_">self</span>.output_proj(enhanced_feat)  <span class="comment"># [B, H*W, C]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 重塑为BEV特征</span></span><br><span class="line">        enhanced_feat = enhanced_feat.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>).reshape(B, C, H, W)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> enhanced_feat</span><br></pre></td></tr></table></figure>

<h3 id="1-2-nSTP数据处理组件"><a href="#1-2-nSTP数据处理组件" class="headerlink" title="1.2 nSTP数据处理组件"></a>1.2 nSTP数据处理组件</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\datasets\pipelines\nstp_transform.py</code></p>
<p><strong>主要功能</strong>:</p>
<ul>
<li>创建了<code>ProcessNSTPGraph</code>类：处理nSTP图数据，确保格式正确并转换为PyTorch张量</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> mmdet.datasets.builder <span class="keyword">import</span> PIPELINES</span><br><span class="line"></span><br><span class="line"><span class="meta">@PIPELINES.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProcessNSTPGraph</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;处理nSTP图数据的转换组件&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, graph_feat_dim=<span class="number">64</span>, with_agent_type=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.graph_feat_dim = graph_feat_dim</span><br><span class="line">        <span class="variable language_">self</span>.with_agent_type = with_agent_type</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, results</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;处理nSTP图数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;nstp_graph&#x27;</span> <span class="keyword">not</span> <span class="keyword">in</span> results:</span><br><span class="line">            <span class="keyword">return</span> results</span><br><span class="line">            </span><br><span class="line">        graph_data = results[<span class="string">&#x27;nstp_graph&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 处理PyG Data对象</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(graph_data, <span class="string">&#x27;x&#x27;</span>) <span class="keyword">and</span> <span class="built_in">hasattr</span>(graph_data, <span class="string">&#x27;edge_index&#x27;</span>):</span><br><span class="line">            <span class="comment"># 已经是PyG Data对象，确保张量类型正确</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(graph_data.x, torch.Tensor):</span><br><span class="line">                graph_data.x = torch.tensor(graph_data.x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(graph_data.edge_index, torch.Tensor):</span><br><span class="line">                graph_data.edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">hasattr</span>(graph_data, <span class="string">&#x27;edge_attr&#x27;</span>) <span class="keyword">and</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(graph_data.edge_attr, torch.Tensor):</span><br><span class="line">                graph_data.edge_attr = torch.tensor(graph_data.edge_attr, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">                </span><br><span class="line">        <span class="comment"># 处理字典格式的图数据</span></span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">isinstance</span>(graph_data, <span class="built_in">dict</span>):</span><br><span class="line">            <span class="comment"># 处理节点特征</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;x&#x27;</span> <span class="keyword">in</span> graph_data:</span><br><span class="line">                x = graph_data[<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(x, np.ndarray):</span><br><span class="line">                    x = torch.from_numpy(x).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(x, <span class="built_in">list</span>):</span><br><span class="line">                    x = torch.tensor(x).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(x, torch.Tensor):</span><br><span class="line">                    x = torch.tensor(x, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">                graph_data[<span class="string">&#x27;x&#x27;</span>] = x</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 处理边索引</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;edge_index&#x27;</span> <span class="keyword">in</span> graph_data:</span><br><span class="line">                edge_index = graph_data[<span class="string">&#x27;edge_index&#x27;</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(edge_index, np.ndarray):</span><br><span class="line">                    edge_index = torch.from_numpy(edge_index).long()</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(edge_index, <span class="built_in">list</span>):</span><br><span class="line">                    edge_index = torch.tensor(edge_index).long()</span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(edge_index, torch.Tensor):</span><br><span class="line">                    edge_index = torch.tensor(edge_index, dtype=torch.long)</span><br><span class="line">                graph_data[<span class="string">&#x27;edge_index&#x27;</span>] = edge_index</span><br><span class="line">                </span><br><span class="line">            <span class="comment"># 处理边属性</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;edge_attr&#x27;</span> <span class="keyword">in</span> graph_data:</span><br><span class="line">                edge_attr = graph_data[<span class="string">&#x27;edge_attr&#x27;</span>]</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">isinstance</span>(edge_attr, np.ndarray):</span><br><span class="line">                    edge_attr = torch.from_numpy(edge_attr).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="built_in">isinstance</span>(edge_attr, <span class="built_in">list</span>):</span><br><span class="line">                    edge_attr = torch.tensor(edge_attr).<span class="built_in">float</span>()</span><br><span class="line">                <span class="keyword">elif</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(edge_attr, torch.Tensor):</span><br><span class="line">                    edge_attr = torch.tensor(edge_attr, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">                graph_data[<span class="string">&#x27;edge_attr&#x27;</span>] = edge_attr</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新结果</span></span><br><span class="line">        results[<span class="string">&#x27;nstp_graph&#x27;</span>] = graph_data</span><br><span class="line">        <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>

<h2 id="2-现有文件修改"><a href="#2-现有文件修改" class="headerlink" title="2. 现有文件修改"></a>2. 现有文件修改</h2><h3 id="2-1-数据集类修改"><a href="#2-1-数据集类修改" class="headerlink" title="2.1 数据集类修改"></a>2.1 数据集类修改</h3><h4 id="2-1-1-NuScenes数据集"><a href="#2-1-1-NuScenes数据集" class="headerlink" title="2.1.1 NuScenes数据集"></a>2.1.1 NuScenes数据集</h4><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\datasets\nuscenes_vidar_dataset_v1.py</code></p>
<p><strong>主要修改</strong>:</p>
<ul>
<li>添加了nSTP相关参数：<code>use_nstp</code>, <code>nstp_path</code></li>
<li>实现了<code>_load_nstp_data</code>方法：加载nSTP图数据文件</li>
<li>修改了<code>get_data_info</code>方法：将nSTP数据添加到样本信息中</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"><span class="comment"># Visual Point Cloud Forecasting enables Scalable Autonomous Driving              #</span></span><br><span class="line"><span class="comment"># Copyright (c) OpenDriveLab. All rights reserved.                                #</span></span><br><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入rdflib</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">from</span> rdflib <span class="keyword">import</span> Graph</span><br><span class="line"><span class="keyword">except</span> ImportError:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;警告: 未安装rdflib库，无法加载.ttl格式的nSKG数据&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mmdet.datasets <span class="keyword">import</span> DATASETS</span><br><span class="line"><span class="keyword">from</span> nuscenes.<span class="built_in">eval</span>.common.utils <span class="keyword">import</span> quaternion_yaw, Quaternion</span><br><span class="line"><span class="keyword">from</span> nuscenes.utils.geometry_utils <span class="keyword">import</span> transform_matrix</span><br><span class="line"><span class="keyword">from</span> mmcv.parallel <span class="keyword">import</span> DataContainer <span class="keyword">as</span> DC</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> .nuscenes_vidar_dataset_template <span class="keyword">import</span> NuScenesViDARDatasetTemplate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@DATASETS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NuScenesViDARDatasetV1</span>(<span class="title class_ inherited__">NuScenesViDARDatasetTemplate</span>):  <span class="comment"># 确保类名为NuScenesViDARDatasetV1</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;NuScenes visual point cloud forecasting dataset.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 ann_file,</span></span><br><span class="line"><span class="params">                 pipeline=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 data_root=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 classes=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 load_interval=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 modality=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 box_type_3d=<span class="string">&#x27;LiDAR&#x27;</span>,</span></span><br><span class="line"><span class="params">                 filter_empty_gt=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                 test_mode=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 use_valid_flag=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 history_queue_length=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 pred_history_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 pred_future_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 per_frame_loss_weight=(<span class="params"><span class="number">1.0</span>,</span>),</span></span><br><span class="line"><span class="params">                 use_nskg=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 nskg_path=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 nskg_ontology_path=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 use_nstp=<span class="literal">False</span>,  <span class="comment"># 添加nSTP支持参数</span></span></span><br><span class="line"><span class="params">                 nstp_path=<span class="literal">None</span>,  <span class="comment"># 添加nSTP数据路径参数</span></span></span><br><span class="line"><span class="params">                 **kwargs</span>):</span><br><span class="line">        <span class="comment"># 保存history_queue_length参数，但不传递给父类</span></span><br><span class="line">        <span class="variable language_">self</span>.history_queue_length = history_queue_length</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 调用父类初始化方法，移除history_queue_length参数</span></span><br><span class="line">        <span class="built_in">super</span>().__init__(</span><br><span class="line">            ann_file=ann_file,</span><br><span class="line">            pipeline=pipeline,</span><br><span class="line">            data_root=data_root,</span><br><span class="line">            classes=classes,</span><br><span class="line">            load_interval=load_interval,</span><br><span class="line">            modality=modality,</span><br><span class="line">            box_type_3d=box_type_3d,</span><br><span class="line">            filter_empty_gt=filter_empty_gt,</span><br><span class="line">            test_mode=test_mode,</span><br><span class="line">            use_valid_flag=use_valid_flag,</span><br><span class="line">            **kwargs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存nSKG相关参数</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nskg = use_nskg</span><br><span class="line">        <span class="variable language_">self</span>.nskg_path = nskg_path</span><br><span class="line">        <span class="variable language_">self</span>.nskg_ontology_path = nskg_ontology_path</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存nSTP相关参数</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nstp = use_nstp</span><br><span class="line">        <span class="variable language_">self</span>.nstp_path = nstp_path</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存预测帧数相关参数</span></span><br><span class="line">        <span class="variable language_">self</span>.pred_history_frame_num = pred_history_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.pred_future_frame_num = pred_future_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.per_frame_loss_weight = per_frame_loss_weight</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSKG，加载相关数据</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="variable language_">self</span>._load_nskg_data()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_load_nskg_data</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载nSKG数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.nskg_data = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="variable language_">self</span>.nskg_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;警告: nSKG数据路径 <span class="subst">&#123;self.nskg_path&#125;</span> 不存在&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nskg = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.nskg_path.endswith(<span class="string">&#x27;.ttl&#x27;</span>) <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_ontology_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                g = Graph()</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    g.parse(<span class="variable language_">self</span>.nskg_path, <span class="built_in">format</span>=<span class="string">&#x27;turtle&#x27;</span>)</span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;警告: TTL文件解析失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">                    <span class="variable language_">self</span>.use_nskg = <span class="literal">False</span></span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">                <span class="comment"># 加载本体文件</span></span><br><span class="line">                <span class="keyword">if</span> os.path.exists(<span class="variable language_">self</span>.nskg_ontology_path):</span><br><span class="line">                    <span class="keyword">for</span> onto_file <span class="keyword">in</span> os.listdir(<span class="variable language_">self</span>.nskg_ontology_path):</span><br><span class="line">                        <span class="keyword">if</span> onto_file.endswith(<span class="string">&#x27;.ttl&#x27;</span>):</span><br><span class="line">                            onto_path = os.path.join(<span class="variable language_">self</span>.nskg_ontology_path, onto_file)</span><br><span class="line">                            <span class="keyword">try</span>:</span><br><span class="line">                                g.parse(onto_path, <span class="built_in">format</span>=<span class="string">&#x27;turtle&#x27;</span>)</span><br><span class="line">                            <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                                <span class="built_in">print</span>(<span class="string">f&quot;警告: 本体文件 <span class="subst">&#123;onto_file&#125;</span> 解析失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;成功加载nSKG数据，共 <span class="subst">&#123;<span class="built_in">len</span>(g)&#125;</span> 个三元组&quot;</span>)</span><br><span class="line">                <span class="variable language_">self</span>.nskg_data = <span class="variable language_">self</span>._convert_rdf_to_pyg(g)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">import</span> pickle</span><br><span class="line">                <span class="keyword">with</span> <span class="built_in">open</span>(<span class="variable language_">self</span>.nskg_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    <span class="variable language_">self</span>.nskg_data = pickle.load(f)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;成功加载nSKG数据，共 <span class="subst">&#123;<span class="built_in">len</span>(self.nskg_data)&#125;</span> 条记录&quot;</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;加载nSKG数据失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;继续训练，但不使用nSKG数据&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nskg = <span class="literal">False</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_convert_rdf_to_pyg</span>(<span class="params">self, graph</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;将RDF图转换为PyG格式</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            graph: RDF图对象</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            转换后的数据字典，键为sample_token</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        result = &#123;&#125;</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">import</span> torch_geometric <span class="keyword">as</span> pyg</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 查询所有场景</span></span><br><span class="line">            scenes = &#123;&#125;</span><br><span class="line">            <span class="keyword">for</span> s, p, o <span class="keyword">in</span> graph.triples((<span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>)):</span><br><span class="line">                <span class="comment"># 假设每个场景都有一个token属性</span></span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">str</span>(p).endswith(<span class="string">&#x27;hasToken&#x27;</span>):</span><br><span class="line">                    scene_uri = <span class="built_in">str</span>(s)</span><br><span class="line">                    token = <span class="built_in">str</span>(o)</span><br><span class="line">                    scenes[scene_uri] = token</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 为每个场景构建图</span></span><br><span class="line">            <span class="keyword">for</span> scene_uri, token <span class="keyword">in</span> scenes.items():</span><br><span class="line">                <span class="comment"># 收集节点</span></span><br><span class="line">                nodes = &#123;&#125;</span><br><span class="line">                node_types = &#123;&#125;</span><br><span class="line">                node_features = &#123;&#125;</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 收集边</span></span><br><span class="line">                edges = &#123;&#125;</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 查询与场景相关的所有三元组</span></span><br><span class="line">                <span class="keyword">for</span> s, p, o <span class="keyword">in</span> graph.triples((<span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span>)):</span><br><span class="line">                    <span class="comment"># 处理节点和边的逻辑...</span></span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 构建PyG数据对象</span></span><br><span class="line">                data = &#123;</span><br><span class="line">                    <span class="string">&#x27;x&#x27;</span>: node_features,</span><br><span class="line">                    <span class="string">&#x27;edge_index&#x27;</span>: edges,</span><br><span class="line">                    <span class="string">&#x27;node_type&#x27;</span>: node_types</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">                result[token] = data</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">return</span> result</span><br><span class="line">        <span class="keyword">except</span> ImportError:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;警告: 未安装PyTorch Geometric库，无法转换RDF数据为图格式&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> &#123;&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_data_info</span>(<span class="params">self, index</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;获取数据信息，添加nSKG或nSTP数据&quot;&quot;&quot;</span></span><br><span class="line">        info = <span class="built_in">super</span>().get_data_info(index)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取当前样本的标识符</span></span><br><span class="line">        sample_token = info.get(<span class="string">&#x27;sample_token&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSKG，添加nSKG数据到info中</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg <span class="keyword">and</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>, <span class="string">&#x27;nskg_data&#x27;</span>) <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_data <span class="keyword">and</span> sample_token <span class="keyword">in</span> <span class="variable language_">self</span>.nskg_data:</span><br><span class="line">            info[<span class="string">&#x27;nskg_graph&#x27;</span>] = <span class="variable language_">self</span>.nskg_data[sample_token]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSTP，添加nSTP数据到info中（优先使用nSTP）</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nstp <span class="keyword">and</span> <span class="built_in">hasattr</span>(<span class="variable language_">self</span>, <span class="string">&#x27;nstp_data&#x27;</span>) <span class="keyword">and</span> <span class="variable language_">self</span>.nstp_data <span class="keyword">and</span> sample_token <span class="keyword">in</span> <span class="variable language_">self</span>.nstp_data:</span><br><span class="line">            info[<span class="string">&#x27;nstp_graph&#x27;</span>] = <span class="variable language_">self</span>.nstp_data[sample_token]</span><br><span class="line">            <span class="comment"># 如果同时存在nSKG和nSTP，使用nSTP替代nSKG</span></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;nskg_graph&#x27;</span> <span class="keyword">in</span> info:</span><br><span class="line">                <span class="keyword">del</span> info[<span class="string">&#x27;nskg_graph&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> info</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_mask_points</span>(<span class="params">self, pts_list</span>):</span><br><span class="line">        <span class="keyword">assert</span> <span class="variable language_">self</span>.ego_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">        <span class="comment"># remove points belonging to ego vehicle.</span></span><br><span class="line">        masked_pts_list = []</span><br><span class="line">        <span class="keyword">for</span> pts <span class="keyword">in</span> pts_list:</span><br><span class="line">            ego_mask = np.logical_and(</span><br><span class="line">                np.logical_and(<span class="variable language_">self</span>.ego_mask[<span class="number">0</span>] &lt;= pts[:, <span class="number">0</span>],</span><br><span class="line">                               <span class="variable language_">self</span>.ego_mask[<span class="number">2</span>] &gt;= pts[:, <span class="number">0</span>]),</span><br><span class="line">                np.logical_and(<span class="variable language_">self</span>.ego_mask[<span class="number">1</span>] &lt;= pts[:, <span class="number">1</span>],</span><br><span class="line">                               <span class="variable language_">self</span>.ego_mask[<span class="number">3</span>] &gt;= pts[:, <span class="number">1</span>]),</span><br><span class="line">            )</span><br><span class="line">            pts = pts[np.logical_not(ego_mask)]</span><br><span class="line">            masked_pts_list.append(pts)</span><br><span class="line">        pts_list = masked_pts_list</span><br><span class="line">        <span class="keyword">return</span> pts_list</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">union2one</span>(<span class="params">self, previous_queue, future_queue</span>):</span><br><span class="line">        <span class="comment"># 1. get transformation from all frames to current (reference) frame</span></span><br><span class="line">        ref_meta = previous_queue[-<span class="number">1</span>][<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line">        valid_scene_token = ref_meta[<span class="string">&#x27;scene_token&#x27;</span>]</span><br><span class="line">        <span class="comment"># compute reference e2g_transform and g2e_transform.</span></span><br><span class="line">        ref_e2g_translation = ref_meta[<span class="string">&#x27;ego2global_translation&#x27;</span>]</span><br><span class="line">        ref_e2g_rotation = ref_meta[<span class="string">&#x27;ego2global_rotation&#x27;</span>]</span><br><span class="line">        ref_e2g_transform = transform_matrix(</span><br><span class="line">            ref_e2g_translation, Quaternion(ref_e2g_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">        ref_g2e_transform = transform_matrix(</span><br><span class="line">            ref_e2g_translation, Quaternion(ref_e2g_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line">        ref_l2e_translation = ref_meta[<span class="string">&#x27;lidar2ego_translation&#x27;</span>]</span><br><span class="line">        ref_l2e_rotation = ref_meta[<span class="string">&#x27;lidar2ego_rotation&#x27;</span>]</span><br><span class="line">        ref_l2e_transform = transform_matrix(</span><br><span class="line">            ref_l2e_translation, Quaternion(ref_l2e_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">        ref_e2l_transform = transform_matrix(</span><br><span class="line">            ref_l2e_translation, Quaternion(ref_l2e_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        queue = previous_queue[:-<span class="number">1</span>] + future_queue</span><br><span class="line">        pts_list = [each[<span class="string">&#x27;points&#x27;</span>].data <span class="keyword">for</span> each <span class="keyword">in</span> queue]</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.ego_mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            pts_list = <span class="variable language_">self</span>._mask_points(pts_list)</span><br><span class="line">        total_cur2ref_lidar_transform = []</span><br><span class="line">        total_ref2cur_lidar_transform = []</span><br><span class="line">        total_pts_list = []</span><br><span class="line">        <span class="keyword">for</span> i, each <span class="keyword">in</span> <span class="built_in">enumerate</span>(queue):</span><br><span class="line">            meta = each[<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line"></span><br><span class="line">            <span class="comment"># store points in the current frame.</span></span><br><span class="line">            cur_pts = pts_list[i].cpu().numpy().copy()</span><br><span class="line">            cur_pts[:, -<span class="number">1</span>] = i</span><br><span class="line">            total_pts_list.append(cur_pts)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># store the transformation from current frame to reference frame.</span></span><br><span class="line">            curr_e2g_translation = meta[<span class="string">&#x27;ego2global_translation&#x27;</span>]</span><br><span class="line">            curr_e2g_rotation = meta[<span class="string">&#x27;ego2global_rotation&#x27;</span>]</span><br><span class="line">            curr_e2g_transform = transform_matrix(</span><br><span class="line">                curr_e2g_translation, Quaternion(curr_e2g_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">            curr_g2e_transform = transform_matrix(</span><br><span class="line">                curr_e2g_translation, Quaternion(curr_e2g_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            curr_l2e_translation = meta[<span class="string">&#x27;lidar2ego_translation&#x27;</span>]</span><br><span class="line">            curr_l2e_rotation = meta[<span class="string">&#x27;lidar2ego_rotation&#x27;</span>]</span><br><span class="line">            curr_l2e_transform = transform_matrix(</span><br><span class="line">                curr_l2e_translation, Quaternion(curr_l2e_rotation), inverse=<span class="literal">False</span>)</span><br><span class="line">            curr_e2l_transform = transform_matrix(</span><br><span class="line">                curr_l2e_translation, Quaternion(curr_l2e_rotation), inverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute future to reference matrix.</span></span><br><span class="line">            cur_lidar_to_ref_lidar = (curr_l2e_transform.T @</span><br><span class="line">                                      curr_e2g_transform.T @</span><br><span class="line">                                      ref_g2e_transform.T @</span><br><span class="line">                                      ref_e2l_transform.T)</span><br><span class="line">            total_cur2ref_lidar_transform.append(cur_lidar_to_ref_lidar)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute reference to future matrix.</span></span><br><span class="line">            ref_lidar_to_cur_lidar = (ref_l2e_transform.T @</span><br><span class="line">                                      ref_e2g_transform.T @</span><br><span class="line">                                      curr_g2e_transform.T @</span><br><span class="line">                                      curr_e2l_transform.T)</span><br><span class="line">            total_ref2cur_lidar_transform.append(ref_lidar_to_cur_lidar)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. Parse previous and future can_bus information.</span></span><br><span class="line">        imgs_list = [each[<span class="string">&#x27;img&#x27;</span>].data <span class="keyword">for</span> each <span class="keyword">in</span> previous_queue]</span><br><span class="line">        metas_map = &#123;&#125;</span><br><span class="line">        prev_scene_token = <span class="literal">None</span></span><br><span class="line">        prev_pos = <span class="literal">None</span></span><br><span class="line">        prev_angle = <span class="literal">None</span></span><br><span class="line">        ref_meta = previous_queue[-<span class="number">1</span>][<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.2. Previous</span></span><br><span class="line">        <span class="keyword">for</span> i, each <span class="keyword">in</span> <span class="built_in">enumerate</span>(previous_queue):</span><br><span class="line">            metas_map[i] = each[<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="string">&#x27;aug_param&#x27;</span> <span class="keyword">in</span> each:</span><br><span class="line">                metas_map[i][<span class="string">&#x27;aug_param&#x27;</span>] = each[<span class="string">&#x27;aug_param&#x27;</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> metas_map[i][<span class="string">&#x27;scene_token&#x27;</span>] != prev_scene_token:</span><br><span class="line">                metas_map[i][<span class="string">&#x27;prev_bev_exists&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">                prev_scene_token = metas_map[i][<span class="string">&#x27;scene_token&#x27;</span>]</span><br><span class="line">                prev_pos = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][:<span class="number">3</span>])</span><br><span class="line">                prev_angle = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][-<span class="number">1</span>])</span><br><span class="line">                <span class="comment"># Set the original point of this motion.</span></span><br><span class="line">                new_can_bus = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = <span class="number">0</span></span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">                metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>] = new_can_bus</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                metas_map[i][<span class="string">&#x27;prev_bev_exists&#x27;</span>] = <span class="literal">True</span></span><br><span class="line">                tmp_pos = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][:<span class="number">3</span>])</span><br><span class="line">                tmp_angle = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>][-<span class="number">1</span>])</span><br><span class="line">                <span class="comment"># Compute the later waypoint.</span></span><br><span class="line">                <span class="comment"># To align the shift and rotate difference due to the BEV.</span></span><br><span class="line">                new_can_bus = copy.deepcopy(metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = tmp_pos - prev_pos</span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = tmp_angle - prev_angle</span><br><span class="line">                metas_map[i][<span class="string">&#x27;can_bus&#x27;</span>] = new_can_bus</span><br><span class="line">                prev_pos = copy.deepcopy(tmp_pos)</span><br><span class="line">                prev_angle = copy.deepcopy(tmp_angle)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute cur_lidar_to_ref_lidar transformation matrix for quickly align generated</span></span><br><span class="line">            <span class="comment">#  bev features to the reference frame.</span></span><br><span class="line">            metas_map[i][<span class="string">&#x27;ref_lidar_to_cur_lidar&#x27;</span>] = total_ref2cur_lidar_transform[i]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2.3. Future</span></span><br><span class="line">        current_scene_token = ref_meta[<span class="string">&#x27;scene_token&#x27;</span>]</span><br><span class="line">        ref_can_bus = <span class="literal">None</span></span><br><span class="line">        future_can_bus = []</span><br><span class="line">        future2ref_lidar_transform = []</span><br><span class="line">        ref2future_lidar_transform = []</span><br><span class="line">        <span class="keyword">for</span> i, each <span class="keyword">in</span> <span class="built_in">enumerate</span>(future_queue):</span><br><span class="line">            future_meta = each[<span class="string">&#x27;img_metas&#x27;</span>].data</span><br><span class="line">            <span class="keyword">if</span> future_meta[<span class="string">&#x27;scene_token&#x27;</span>] != current_scene_token:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># store the transformation:</span></span><br><span class="line">            future2ref_lidar_transform.append(</span><br><span class="line">                total_cur2ref_lidar_transform[i + <span class="built_in">len</span>(previous_queue) - <span class="number">1</span>]</span><br><span class="line">            )  <span class="comment"># current -&gt; reference.</span></span><br><span class="line">            ref2future_lidar_transform.append(</span><br><span class="line">                total_ref2cur_lidar_transform[i + <span class="built_in">len</span>(previous_queue) - <span class="number">1</span>]</span><br><span class="line">            )  <span class="comment"># reference -&gt; current.</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># can_bus information.</span></span><br><span class="line">            <span class="keyword">if</span> i == <span class="number">0</span>:</span><br><span class="line">                new_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = <span class="number">0</span></span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = <span class="number">0</span></span><br><span class="line">                future_can_bus.append(new_can_bus)</span><br><span class="line">                ref_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                new_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line"></span><br><span class="line">                new_can_bus_pos = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]).reshape(<span class="number">1</span>, <span class="number">4</span>)</span><br><span class="line">                ref2prev_lidar_transform = ref2future_lidar_transform[-<span class="number">2</span>]</span><br><span class="line">                cur2ref_lidar_transform = future2ref_lidar_transform[-<span class="number">1</span>]</span><br><span class="line">                new_can_bus_pos = new_can_bus_pos @ cur2ref_lidar_transform @ ref2prev_lidar_transform</span><br><span class="line"></span><br><span class="line">                new_can_bus_angle = new_can_bus[-<span class="number">1</span>] - ref_can_bus[-<span class="number">1</span>]</span><br><span class="line">                new_can_bus[:<span class="number">3</span>] = new_can_bus_pos[:, :<span class="number">3</span>]</span><br><span class="line">                new_can_bus[-<span class="number">1</span>] = new_can_bus_angle</span><br><span class="line">                future_can_bus.append(new_can_bus)</span><br><span class="line">                ref_can_bus = copy.deepcopy(future_meta[<span class="string">&#x27;can_bus&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        ret_queue = previous_queue[-<span class="number">1</span>]</span><br><span class="line">        ret_queue[<span class="string">&#x27;img&#x27;</span>] = DC(torch.stack(imgs_list), cpu_only=<span class="literal">False</span>, stack=<span class="literal">True</span>)</span><br><span class="line">        ret_queue.pop(<span class="string">&#x27;aug_param&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;future_can_bus&#x27;</span>] = np.array(future_can_bus)</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;future2ref_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(future2ref_lidar_transform))</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;ref2future_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(ref2future_lidar_transform))</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;total_cur2ref_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(total_cur2ref_lidar_transform))</span><br><span class="line">        metas_map[<span class="built_in">len</span>(previous_queue) - <span class="number">1</span>][<span class="string">&#x27;total_ref2cur_lidar_transform&#x27;</span>] = (</span><br><span class="line">            np.array(total_ref2cur_lidar_transform))</span><br><span class="line"></span><br><span class="line">        ret_queue[<span class="string">&#x27;img_metas&#x27;</span>] = DC(metas_map, cpu_only=<span class="literal">True</span>)</span><br><span class="line">        ret_queue.pop(<span class="string">&#x27;points&#x27;</span>)</span><br><span class="line">        ret_queue[<span class="string">&#x27;gt_points&#x27;</span>] = DC(</span><br><span class="line">            torch.from_numpy(np.concatenate(total_pts_list, <span class="number">0</span>)), cpu_only=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(future_can_bus) &lt; <span class="number">1</span> + <span class="variable language_">self</span>.future_length:</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">return</span> ret_queue</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_load_nstp_data</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载nSTP数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>.nstp_data = &#123;&#125;</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="variable language_">self</span>.nstp_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;警告: nSTP数据路径 <span class="subst">&#123;self.nstp_path&#125;</span> 不存在&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nstp = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">            </span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">import</span> torch</span><br><span class="line">            <span class="keyword">import</span> glob</span><br><span class="line">            <span class="keyword">import</span> os.path <span class="keyword">as</span> osp</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 获取目录中所有的.pt文件</span></span><br><span class="line">            pt_files = glob.glob(osp.join(<span class="variable language_">self</span>.nstp_path, <span class="string">&quot;*.pt&quot;</span>))</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> pt_files:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;警告: 在 <span class="subst">&#123;self.nstp_path&#125;</span> 中未找到.pt文件&quot;</span>)</span><br><span class="line">                <span class="variable language_">self</span>.use_nstp = <span class="literal">False</span></span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">                </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;找到 <span class="subst">&#123;<span class="built_in">len</span>(pt_files)&#125;</span> 个nSTP数据文件&quot;</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 加载每个.pt文件</span></span><br><span class="line">            <span class="keyword">for</span> pt_file <span class="keyword">in</span> pt_files:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    <span class="comment"># 从文件名获取样本ID</span></span><br><span class="line">                    sample_id = osp.splitext(osp.basename(pt_file))[<span class="number">0</span>]</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 加载PyTorch张量</span></span><br><span class="line">                    graph_data = torch.load(pt_file)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 将数据添加到字典中</span></span><br><span class="line">                    <span class="variable language_">self</span>.nstp_data[sample_id] = graph_data</span><br><span class="line">                    </span><br><span class="line">                <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">f&quot;加载文件 <span class="subst">&#123;pt_file&#125;</span> 失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">                    </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;成功加载 <span class="subst">&#123;<span class="built_in">len</span>(self.nstp_data)&#125;</span> 个nSTP样本&quot;</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;加载nSTP数据失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;继续训练，但不使用nSTP数据&quot;</span>)</span><br><span class="line">            <span class="variable language_">self</span>.use_nstp = <span class="literal">False</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2-1-2-NuPlan数据集"><a href="#2-1-2-NuPlan数据集" class="headerlink" title="2.1.2 NuPlan数据集"></a>2.1.2 NuPlan数据集</h4><p><strong>文件路径</strong>: <code>d:\git_clone\ViDAR\projects\mmdet3d_plugin\datasets\nuplan_vidar_dataset_v1.py</code></p>
<p><strong>主要修改</strong>:</p>
<ul>
<li>与NuScenes数据集类似，添加了nSTP支持</li>
<li>实现了特定于NuPlan数据集的nSTP数据加载和处理逻辑</li>
</ul>
<h3 id="2-2-模型头部修改"><a href="#2-2-模型头部修改" class="headerlink" title="2.2 模型头部修改"></a>2.2 模型头部修改</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\bevformer\dense_heads\vidar_head_v1.py</code></p>
<p><strong>主要修改</strong>:</p>
<ul>
<li>添加了nSTP相关参数：<code>use_nstp</code>, <code>nstp_encoder_cfg</code>, <code>nstp_enhancer_cfg</code></li>
<li>集成了nSTP编码器和增强器到模型头部</li>
<li>修改了前向传播逻辑，处理nSTP特征</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"><span class="comment"># Visual Point Cloud Forecasting enables Scalable Autonomous Driving              #</span></span><br><span class="line"><span class="comment"># Copyright (c) OpenDriveLab. All rights reserved.                                #</span></span><br><span class="line"><span class="comment">#---------------------------------------------------------------------------------#</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;V1.multiframe&gt; of ViDAR future prediction head:</span></span><br><span class="line"><span class="string">    * Predict future &amp; history frames simultaneously.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mmdet.models <span class="keyword">import</span> HEADS, build_loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> mmcv.runner <span class="keyword">import</span> force_fp32, auto_fp16</span><br><span class="line"><span class="keyword">from</span> .vidar_head_base <span class="keyword">import</span> ViDARHeadBase</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@HEADS.register_module()</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ViDARHeadV1</span>(<span class="title class_ inherited__">ViDARHeadBase</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 history_queue_length,</span></span><br><span class="line"><span class="params">                 pred_history_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 pred_future_frame_num=<span class="number">0</span>,</span></span><br><span class="line"><span class="params">                 per_frame_loss_weight=(<span class="params"><span class="number">1.0</span>,</span>),</span></span><br><span class="line"><span class="params">                 use_nskg=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 nskg_encoder_cfg=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 nskg_enhancer_cfg=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 use_nstp=<span class="literal">False</span>,  <span class="comment"># 添加nSTP支持参数</span></span></span><br><span class="line"><span class="params">                 nstp_encoder_cfg=<span class="literal">None</span>,  <span class="comment"># 添加nSTP编码器配置</span></span></span><br><span class="line"><span class="params">                 nstp_enhancer_cfg=<span class="literal">None</span>,  <span class="comment"># 添加nSTP增强器配置</span></span></span><br><span class="line"><span class="params">                 *args,</span></span><br><span class="line"><span class="params">                 **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(*args, **kwargs)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.history_queue_length = history_queue_length</span><br><span class="line">        <span class="variable language_">self</span>.pred_history_frame_num = pred_history_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.pred_future_frame_num = pred_future_frame_num</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>.pred_frame_num = <span class="number">1</span> + <span class="variable language_">self</span>.pred_history_frame_num + <span class="variable language_">self</span>.pred_future_frame_num</span><br><span class="line">        <span class="variable language_">self</span>.per_frame_loss_weight = per_frame_loss_weight</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.per_frame_loss_weight) == <span class="variable language_">self</span>.pred_frame_num</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._init_bev_pred_layers()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># nSKG支持</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nskg = use_nskg</span><br><span class="line">        <span class="comment"># nSTP支持</span></span><br><span class="line">        <span class="variable language_">self</span>.use_nstp = use_nstp</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg:</span><br><span class="line">            <span class="keyword">from</span> ..modules.nskg_gnn <span class="keyword">import</span> NSKGEncoder</span><br><span class="line">            <span class="keyword">from</span> ..modules.nskg_bev_enhancer <span class="keyword">import</span> NSKGBEVEnhancer</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 创建nSKG编码器</span></span><br><span class="line">            <span class="keyword">if</span> nskg_encoder_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_encoder = NSKGEncoder(**nskg_encoder_cfg)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_encoder = NSKGEncoder(</span><br><span class="line">                    in_channels=<span class="number">8</span>,</span><br><span class="line">                    hidden_channels=<span class="number">64</span>,</span><br><span class="line">                    out_channels=<span class="number">256</span>,</span><br><span class="line">                    num_layers=<span class="number">2</span>,</span><br><span class="line">                    gnn_type=<span class="string">&#x27;gat&#x27;</span>,</span><br><span class="line">                    use_hetero=<span class="literal">True</span></span><br><span class="line">                )</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 创建BEV特征增强器</span></span><br><span class="line">            <span class="keyword">if</span> nskg_enhancer_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_enhancer = NSKGBEVEnhancer(**nskg_enhancer_cfg)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nskg_enhancer = NSKGBEVEnhancer(</span><br><span class="line">                    bev_channels=<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                    nskg_channels=<span class="number">256</span>,</span><br><span class="line">                    hidden_channels=<span class="number">128</span>,</span><br><span class="line">                    bev_h=<span class="variable language_">self</span>.bev_h,</span><br><span class="line">                    bev_w=<span class="variable language_">self</span>.bev_w,</span><br><span class="line">                    use_attention=<span class="literal">True</span></span><br><span class="line">                )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>.nskg_encoder = <span class="literal">None</span></span><br><span class="line">            <span class="variable language_">self</span>.nskg_enhancer = <span class="literal">None</span></span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 添加nSTP支持</span></span><br><span class="line">            <span class="keyword">if</span> <span class="variable language_">self</span>.use_nstp:</span><br><span class="line">                <span class="keyword">from</span> ..modules.nstp_encoder <span class="keyword">import</span> NSTPEncoder, NSTPEnhancer</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 创建nSTP编码器</span></span><br><span class="line">                <span class="keyword">if</span> nstp_encoder_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_encoder = NSTPEncoder(**nstp_encoder_cfg)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_encoder = NSTPEncoder(</span><br><span class="line">                        in_channels=<span class="number">64</span>,</span><br><span class="line">                        hidden_channels=<span class="number">128</span>,</span><br><span class="line">                        out_channels=<span class="number">256</span>,</span><br><span class="line">                        num_layers=<span class="number">3</span>,</span><br><span class="line">                        gnn_type=<span class="string">&#x27;graphsage&#x27;</span>,</span><br><span class="line">                        dropout=<span class="number">0.1</span>,</span><br><span class="line">                        aggr=<span class="string">&#x27;mean&#x27;</span></span><br><span class="line">                    )</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 创建nSTP增强器</span></span><br><span class="line">                <span class="keyword">if</span> nstp_enhancer_cfg <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_enhancer = NSTPEnhancer(**nstp_enhancer_cfg)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="variable language_">self</span>.nstp_enhancer = NSTPEnhancer(</span><br><span class="line">                        bev_channels=<span class="variable language_">self</span>.embed_dims,</span><br><span class="line">                        nstp_channels=<span class="number">256</span>,</span><br><span class="line">                        hidden_channels=<span class="number">128</span>,</span><br><span class="line">                        bev_h=<span class="variable language_">self</span>.bev_h,</span><br><span class="line">                        bev_w=<span class="variable language_">self</span>.bev_w,</span><br><span class="line">                        use_attention=<span class="literal">True</span></span><br><span class="line">                    )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="variable language_">self</span>.nstp_encoder = <span class="literal">None</span></span><br><span class="line">                <span class="variable language_">self</span>.nstp_enhancer = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, mlvl_feats, img_metas, prev_bev=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Forward function.</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            mlvl_feats (list(Tensor)): 多尺度特征，每个元素形状为 [B, num_cam, C, H, W]</span></span><br><span class="line"><span class="string">            img_metas (list(dict)): 图像元信息</span></span><br><span class="line"><span class="string">            prev_bev: 历史BEV特征</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            tuple: bev_embed, history_states, future_states</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 调用父类的forward方法获取原始结果</span></span><br><span class="line">        bev_embed, history_states, future_states = <span class="built_in">super</span>().forward(</span><br><span class="line">            mlvl_feats, img_metas, prev_bev, **kwargs)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果启用nSKG，处理图数据增强BEV特征</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nskg <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_encoder <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.nskg_enhancer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            bs = bev_embed.shape[<span class="number">0</span>]</span><br><span class="line">            bev_h, bev_w = <span class="variable language_">self</span>.bev_h, <span class="variable language_">self</span>.bev_w</span><br><span class="line">            </span><br><span class="line">            nskg_graphs = []</span><br><span class="line">            <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas:</span><br><span class="line">                nskg_graph = img_meta.get(<span class="string">&#x27;nskg_graph&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">                nskg_graphs.append(nskg_graph)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 处理每个样本的nSKG数据</span></span><br><span class="line">            enhanced_bevs = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">                <span class="comment"># 获取当前样本的BEV特征</span></span><br><span class="line">                curr_bev = bev_embed[i:i+<span class="number">1</span>].view(<span class="number">1</span>, bev_h, bev_w, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 获取当前样本的nSKG图</span></span><br><span class="line">                curr_graph = nskg_graphs[i] <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(nskg_graphs) <span class="keyword">and</span> nskg_graphs[i] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> curr_graph <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="comment"># 使用GNN编码器处理图数据</span></span><br><span class="line">                    node_features, global_features = <span class="variable language_">self</span>.nskg_encoder(curr_graph)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 获取节点位置信息</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">hasattr</span>(curr_graph, <span class="string">&#x27;pos&#x27;</span>):</span><br><span class="line">                        node_pos = curr_graph.pos</span><br><span class="line">                    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(curr_graph, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&#x27;pos&#x27;</span> <span class="keyword">in</span> curr_graph:</span><br><span class="line">                        node_pos = curr_graph[<span class="string">&#x27;pos&#x27;</span>]</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        node_pos = <span class="literal">None</span></span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 增强BEV特征</span></span><br><span class="line">                    enhanced_bev = <span class="variable language_">self</span>.nskg_enhancer(</span><br><span class="line">                        curr_bev, node_features, global_features, node_pos)</span><br><span class="line">                        </span><br><span class="line">                    enhanced_bevs.append(enhanced_bev)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 如果没有nSKG数据，保持原始BEV特征不变</span></span><br><span class="line">                    enhanced_bevs.append(curr_bev)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 合并增强后的BEV特征</span></span><br><span class="line">            <span class="keyword">if</span> enhanced_bevs:</span><br><span class="line">                enhanced_bev = torch.cat(enhanced_bevs, dim=<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># 转回原始格式</span></span><br><span class="line">                bev_embed = enhanced_bev.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(bs, bev_h * bev_w, -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 添加nSTP支持</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.use_nstp <span class="keyword">and</span> <span class="variable language_">self</span>.nstp_encoder <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> <span class="variable language_">self</span>.nstp_enhancer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            bs = bev_embed.shape[<span class="number">0</span>]</span><br><span class="line">            bev_h, bev_w = <span class="variable language_">self</span>.bev_h, <span class="variable language_">self</span>.bev_w</span><br><span class="line">            </span><br><span class="line">            nstp_graphs = []</span><br><span class="line">            <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas:</span><br><span class="line">                nstp_graph = img_meta.get(<span class="string">&#x27;nstp_graph&#x27;</span>, <span class="literal">None</span>)</span><br><span class="line">                nstp_graphs.append(nstp_graph)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 处理每个样本的nSTP数据</span></span><br><span class="line">            enhanced_bevs = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">                <span class="comment"># 获取当前样本的BEV特征</span></span><br><span class="line">                curr_bev = bev_embed[i:i+<span class="number">1</span>].view(<span class="number">1</span>, bev_h, bev_w, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">                </span><br><span class="line">                <span class="comment"># 获取当前样本的nSTP图</span></span><br><span class="line">                curr_graph = nstp_graphs[i] <span class="keyword">if</span> i &lt; <span class="built_in">len</span>(nstp_graphs) <span class="keyword">and</span> nstp_graphs[i] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">else</span> <span class="literal">None</span></span><br><span class="line">                </span><br><span class="line">                <span class="keyword">if</span> curr_graph <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    <span class="comment"># 使用GNN编码器处理图数据</span></span><br><span class="line">                    node_features = <span class="variable language_">self</span>.nstp_encoder(curr_graph)</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 获取节点位置信息（如果有）</span></span><br><span class="line">                    node_pos = <span class="literal">None</span></span><br><span class="line">                    <span class="keyword">if</span> <span class="built_in">hasattr</span>(curr_graph, <span class="string">&#x27;pos&#x27;</span>):</span><br><span class="line">                        node_pos = curr_graph.pos</span><br><span class="line">                    <span class="keyword">elif</span> <span class="built_in">isinstance</span>(curr_graph, <span class="built_in">dict</span>) <span class="keyword">and</span> <span class="string">&#x27;pos&#x27;</span> <span class="keyword">in</span> curr_graph:</span><br><span class="line">                        node_pos = curr_graph[<span class="string">&#x27;pos&#x27;</span>]</span><br><span class="line">                    </span><br><span class="line">                    <span class="comment"># 增强BEV特征</span></span><br><span class="line">                    enhanced_bev = <span class="variable language_">self</span>.nstp_enhancer(curr_bev, node_features, node_pos)</span><br><span class="line">                    enhanced_bevs.append(enhanced_bev)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 如果没有nSTP数据，保持原始BEV特征不变</span></span><br><span class="line">                    enhanced_bevs.append(curr_bev)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 合并增强后的BEV特征</span></span><br><span class="line">            <span class="keyword">if</span> enhanced_bevs:</span><br><span class="line">                enhanced_bev = torch.cat(enhanced_bevs, dim=<span class="number">0</span>)</span><br><span class="line">                <span class="comment"># 转回原始格式</span></span><br><span class="line">                bev_embed = enhanced_bev.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).reshape(bs, bev_h * bev_w, -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> bev_embed, history_states, future_states</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_init_bev_pred_layers</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Overwrite the &#123;self.bev_pred_head&#125; of super()._init_layers()</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        bev_pred_branch = []</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="variable language_">self</span>.num_pred_fcs):</span><br><span class="line">            bev_pred_branch.append(nn.Linear(<span class="variable language_">self</span>.embed_dims, <span class="variable language_">self</span>.embed_dims))</span><br><span class="line">            bev_pred_branch.append(nn.LayerNorm(<span class="variable language_">self</span>.embed_dims))</span><br><span class="line">            bev_pred_branch.append(nn.ReLU(inplace=<span class="literal">True</span>))</span><br><span class="line">        bev_pred_branch.append(nn.Linear(</span><br><span class="line">            <span class="variable language_">self</span>.embed_dims, <span class="variable language_">self</span>.pred_frame_num * <span class="variable language_">self</span>.num_pred_height))</span><br><span class="line">        bev_pred_head = nn.Sequential(*bev_pred_branch)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_get_clones</span>(<span class="params">module, N</span>):</span><br><span class="line">            <span class="keyword">return</span> nn.ModuleList([copy.deepcopy(module) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N)])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Auxiliary supervision for all intermediate results.</span></span><br><span class="line">        num_pred = <span class="variable language_">self</span>.transformer.decoder.num_layers</span><br><span class="line">        <span class="variable language_">self</span>.bev_pred_head = _get_clones(bev_pred_head, num_pred)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward_head</span>(<span class="params">self, next_bev_feats</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get freespace estimation from multi-frame BEV feature maps.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            next_bev_feats (torch.Tensor): with shape as</span></span><br><span class="line"><span class="string">                [pred_frame_num, inter_num, bs, bev_h * bev_w, dims]</span></span><br><span class="line"><span class="string">                pred_frame_num: history frames + current frame + future frames.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        next_bev_preds = []</span><br><span class="line">        <span class="keyword">for</span> lvl <span class="keyword">in</span> <span class="built_in">range</span>(next_bev_feats.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="comment"># pred_frame_num, bs, bev_h * bev_w, num_height_pred * num_frame</span></span><br><span class="line">            <span class="comment">#  ===&gt; pred_frame_num, bs, bev_h * bev_w, num_height_pred, num_frame</span></span><br><span class="line">            <span class="comment">#  ===&gt; pred_frame_num, num_frame, bs, bev_h * bev_w, num_height_pred.</span></span><br><span class="line">            next_bev_pred = <span class="variable language_">self</span>.bev_pred_head[lvl](next_bev_feats[:, lvl])</span><br><span class="line">            next_bev_pred = next_bev_pred.view(</span><br><span class="line">                *next_bev_pred.shape[:-<span class="number">1</span>], <span class="variable language_">self</span>.num_pred_height, <span class="variable language_">self</span>.pred_frame_num)</span><br><span class="line"></span><br><span class="line">            base_bev_pred = next_bev_pred[..., <span class="variable language_">self</span>.pred_history_frame_num][..., <span class="literal">None</span>]</span><br><span class="line">            next_bev_pred = torch.cat([</span><br><span class="line">                next_bev_pred[..., :<span class="variable language_">self</span>.pred_history_frame_num] + base_bev_pred,</span><br><span class="line">                base_bev_pred,</span><br><span class="line">                next_bev_pred[..., <span class="variable language_">self</span>.pred_history_frame_num + <span class="number">1</span>:] + base_bev_pred</span><br><span class="line">            ], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            next_bev_pred = next_bev_pred.permute(<span class="number">0</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>).contiguous()</span><br><span class="line">            next_bev_preds.append(next_bev_pred)</span><br><span class="line">        <span class="comment"># pred_frame_num, inter_num, num_frame, bs, bev_h*bev_w, num_height_pred</span></span><br><span class="line">        next_bev_preds = torch.stack(next_bev_preds, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> next_bev_preds</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_reference_gt_points</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                                 gt_points,</span></span><br><span class="line"><span class="params">                                 src_frame_idx_list,</span></span><br><span class="line"><span class="params">                                 tgt_frame_idx_list,</span></span><br><span class="line"><span class="params">                                 img_metas</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Transform gt_points at src_frame_idx in &#123;src_frame_idx_list&#125; to the coordinate space</span></span><br><span class="line"><span class="string">        of each tgt_frame_idx in &#123;tgt_frame_idx_list&#125;.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        bs = <span class="built_in">len</span>(gt_points)</span><br><span class="line">        aligned_gt_points = []</span><br><span class="line">        batched_origin_points = []</span><br><span class="line">        <span class="keyword">for</span> frame_idx, src_frame_idx, tgt_frame_idx <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">                <span class="built_in">range</span>(<span class="built_in">len</span>(src_frame_idx_list)), src_frame_idx_list, tgt_frame_idx_list):</span><br><span class="line">            <span class="comment"># 1. get gt_points belongs to src_frame_idx.</span></span><br><span class="line">            src_frame_gt_points = [p[p[:, -<span class="number">1</span>] == src_frame_idx] <span class="keyword">for</span> p <span class="keyword">in</span> gt_points]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2. get transformation matrix..</span></span><br><span class="line">            src_to_ref = [img_meta[<span class="string">&#x27;total_cur2ref_lidar_transform&#x27;</span>][src_frame_idx] <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas]</span><br><span class="line">            src_to_ref = gt_points[<span class="number">0</span>].new_tensor(np.array(src_to_ref))  <span class="comment"># bs, 4, 4</span></span><br><span class="line">            ref_to_tgt = [img_meta[<span class="string">&#x27;total_ref2cur_lidar_transform&#x27;</span>][tgt_frame_idx] <span class="keyword">for</span> img_meta <span class="keyword">in</span> img_metas]</span><br><span class="line">            ref_to_tgt = gt_points[<span class="number">0</span>].new_tensor(np.array(ref_to_tgt))  <span class="comment"># bs, 4, 4</span></span><br><span class="line">            src_to_tgt = torch.matmul(src_to_ref, ref_to_tgt)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3. transfer src_frame_gt_points to src_to_tgt.</span></span><br><span class="line">            aligned_gt_points_per_frame = []</span><br><span class="line">            <span class="keyword">for</span> batch_idx, points <span class="keyword">in</span> <span class="built_in">enumerate</span>(src_frame_gt_points):</span><br><span class="line">                new_points = points.clone()  <span class="comment"># -1, 4</span></span><br><span class="line">                new_points = torch.cat([</span><br><span class="line">                    new_points[:, :<span class="number">3</span>], new_points.new_ones(new_points.shape[<span class="number">0</span>], <span class="number">1</span>)</span><br><span class="line">                ], <span class="number">1</span>)</span><br><span class="line">                new_points = torch.matmul(new_points, src_to_tgt[batch_idx])</span><br><span class="line">                new_points[..., -<span class="number">1</span>] = frame_idx</span><br><span class="line">                aligned_gt_points_per_frame.append(new_points)</span><br><span class="line">            aligned_gt_points.append(aligned_gt_points_per_frame)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4. obtain the aligned origin points.</span></span><br><span class="line">            aligned_origin_points = torch.from_numpy(</span><br><span class="line">                np.zeros((bs, <span class="number">1</span>, <span class="number">3</span>))).to(src_to_tgt.dtype).to(src_to_tgt.device)</span><br><span class="line">            aligned_origin_points = torch.cat([</span><br><span class="line">                aligned_origin_points[..., :<span class="number">3</span>], torch.ones_like(aligned_origin_points)[..., <span class="number">0</span>:<span class="number">1</span>]</span><br><span class="line">            ], -<span class="number">1</span>)</span><br><span class="line">            aligned_origin_points = torch.matmul(aligned_origin_points, src_to_tgt)</span><br><span class="line">            batched_origin_points.append(aligned_origin_points[..., :<span class="number">3</span>].contiguous())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># stack points from different timestamps, and transfer to occupancy representation.</span></span><br><span class="line">        batched_gt_points = []</span><br><span class="line">        <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(bs):</span><br><span class="line">            cur_gt_points = [</span><br><span class="line">                aligned_gt_points[frame_idx][b]</span><br><span class="line">                <span class="keyword">for</span> frame_idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(src_frame_idx_list))]</span><br><span class="line">            cur_gt_points = torch.cat(cur_gt_points, <span class="number">0</span>)</span><br><span class="line">            batched_gt_points.append(cur_gt_points)</span><br><span class="line"></span><br><span class="line">        batched_origin_points = torch.cat(batched_origin_points, <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> batched_gt_points, batched_origin_points</span><br><span class="line"></span><br><span class="line"><span class="meta">    @force_fp32(<span class="params">apply_to=(<span class="params"><span class="string">&#x27;pred_dict&#x27;</span></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">             pred_dict,</span></span><br><span class="line"><span class="params">             gt_points,</span></span><br><span class="line"><span class="params">             start_idx,</span></span><br><span class="line"><span class="params">             tgt_bev_h,</span></span><br><span class="line"><span class="params">             tgt_bev_w,</span></span><br><span class="line"><span class="params">             tgt_pc_range,</span></span><br><span class="line"><span class="params">             pred_frame_num,</span></span><br><span class="line"><span class="params">             img_metas=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">             batched_origin_points=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;Compute loss for all history according to gt_points.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        gt_points: ground-truth point cloud in each frame.</span></span><br><span class="line"><span class="string">            list of tensor with shape [-1, 5], indicating ground-truth point cloud in</span></span><br><span class="line"><span class="string">            each frame.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        bev_preds = pred_dict[<span class="string">&#x27;next_bev_preds&#x27;</span>]</span><br><span class="line">        valid_frames = np.array(pred_dict[<span class="string">&#x27;valid_frames&#x27;</span>])</span><br><span class="line">        start_frames = (valid_frames + <span class="variable language_">self</span>.history_queue_length - <span class="variable language_">self</span>.pred_history_frame_num)</span><br><span class="line">        tgt_frames = valid_frames + <span class="variable language_">self</span>.history_queue_length</span><br><span class="line"></span><br><span class="line">        full_prev_bev_exists = pred_dict.get(<span class="string">&#x27;full_prev_bev_exists&#x27;</span>, <span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> full_prev_bev_exists:</span><br><span class="line">            frame_idx_for_loss = [<span class="variable language_">self</span>.pred_history_frame_num] * <span class="variable language_">self</span>.pred_frame_num</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            frame_idx_for_loss = np.arange(<span class="number">0</span>, <span class="variable language_">self</span>.pred_frame_num)</span><br><span class="line"></span><br><span class="line">        loss_dict = <span class="built_in">dict</span>()</span><br><span class="line">        <span class="keyword">for</span> idx, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(frame_idx_for_loss):</span><br><span class="line">            <span class="comment"># 1. get the predicted occupancy of frame-i.</span></span><br><span class="line">            cur_bev_preds = bev_preds[:, :, i, ...].contiguous()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 2. get the frame index of current frame.</span></span><br><span class="line">            src_frames = start_frames + i</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 3. get gt_points belonging to cur_valid_frames.</span></span><br><span class="line">            cur_gt_points, cur_origin_points = <span class="variable language_">self</span>._get_reference_gt_points(</span><br><span class="line">                gt_points,</span><br><span class="line">                src_frame_idx_list=src_frames,</span><br><span class="line">                tgt_frame_idx_list=tgt_frames,</span><br><span class="line">                img_metas=img_metas)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 4. compute loss.</span></span><br><span class="line">            <span class="keyword">if</span> i != <span class="variable language_">self</span>.pred_history_frame_num:</span><br><span class="line">                <span class="comment"># For aux history-future supervision:</span></span><br><span class="line">                <span class="comment">#  only compute loss for cur_frame prediction.</span></span><br><span class="line">                loss_weight = np.array([[<span class="number">1</span>]] + [[<span class="number">0</span>]] * (<span class="built_in">len</span>(<span class="variable language_">self</span>.loss_weight) - <span class="number">1</span>))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                loss_weight = <span class="variable language_">self</span>.loss_weight</span><br><span class="line"></span><br><span class="line">            cur_loss_dict = <span class="built_in">super</span>().loss(</span><br><span class="line">                <span class="built_in">dict</span>(next_bev_preds=cur_bev_preds,</span><br><span class="line">                     valid_frames=np.arange(<span class="number">0</span>, <span class="built_in">len</span>(src_frames))),</span><br><span class="line">                cur_gt_points,</span><br><span class="line">                start_idx=start_idx,</span><br><span class="line">                tgt_bev_h=tgt_bev_h,</span><br><span class="line">                tgt_bev_w=tgt_bev_w,</span><br><span class="line">                tgt_pc_range=tgt_pc_range,</span><br><span class="line">                pred_frame_num=<span class="built_in">len</span>(<span class="variable language_">self</span>.loss_weight)-<span class="number">1</span>,</span><br><span class="line">                img_metas=img_metas,</span><br><span class="line">                batched_origin_points=cur_origin_points,</span><br><span class="line">                loss_weight=loss_weight)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 5. merge dict.</span></span><br><span class="line">            cur_frame_loss_weight = <span class="variable language_">self</span>.per_frame_loss_weight[i]</span><br><span class="line">            cur_frame_loss_weight = cur_frame_loss_weight * (idx == i)</span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> cur_loss_dict.items():</span><br><span class="line">                loss_dict.update(&#123;<span class="string">f&#x27;frame.<span class="subst">&#123;idx&#125;</span>.<span class="subst">&#123;k&#125;</span>.loss&#x27;</span>: v * cur_frame_loss_weight&#125;)</span><br><span class="line">        <span class="keyword">return</span> loss_dict</span><br><span class="line"></span><br><span class="line"><span class="meta">    @force_fp32(<span class="params">apply_to=(<span class="params"><span class="string">&#x27;pred_dict&#x27;</span></span>)</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_point_cloud_prediction</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                                   pred_dict,</span></span><br><span class="line"><span class="params">                                   gt_points,</span></span><br><span class="line"><span class="params">                                   start_idx,</span></span><br><span class="line"><span class="params">                                   tgt_bev_h,</span></span><br><span class="line"><span class="params">                                   tgt_bev_w,</span></span><br><span class="line"><span class="params">                                   tgt_pc_range,</span></span><br><span class="line"><span class="params">                                   img_metas=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                                   batched_origin_points=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;&quot;Generate point cloud prediction.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># pred_frame_num, inter_num, num_frame, bs, bev_h * bev_w, num_height_pred</span></span><br><span class="line">        pred_dict[<span class="string">&#x27;next_bev_preds&#x27;</span>] = pred_dict[<span class="string">&#x27;next_bev_preds&#x27;</span>][:, :, <span class="variable language_">self</span>.pred_history_frame_num, ...].contiguous()</span><br><span class="line"></span><br><span class="line">        valid_frames = np.array(pred_dict[<span class="string">&#x27;valid_frames&#x27;</span>])</span><br><span class="line">        valid_gt_points, cur_origin_points = <span class="variable language_">self</span>._get_reference_gt_points(</span><br><span class="line">            gt_points,</span><br><span class="line">            src_frame_idx_list=valid_frames + <span class="variable language_">self</span>.history_queue_length,</span><br><span class="line">            tgt_frame_idx_list=valid_frames + <span class="variable language_">self</span>.history_queue_length,</span><br><span class="line">            img_metas=img_metas)</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().get_point_cloud_prediction(</span><br><span class="line">            pred_dict=pred_dict,</span><br><span class="line">            gt_points=valid_gt_points,</span><br><span class="line">            start_idx=start_idx,</span><br><span class="line">            tgt_bev_h=tgt_bev_h,</span><br><span class="line">            tgt_bev_w=tgt_bev_w,</span><br><span class="line">            tgt_pc_range=tgt_pc_range,</span><br><span class="line">            img_metas=img_metas,</span><br><span class="line">            batched_origin_points=cur_origin_points)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="2-3-ViDAR检测器修改"><a href="#2-3-ViDAR检测器修改" class="headerlink" title="2.3 ViDAR检测器修改"></a>2.3 ViDAR检测器修改</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\mmdet3d_plugin\bevformer\detectors\vidar.py</code></p>
<p><strong>主要修改</strong>:</p>
<ul>
<li>修改了<code>forward_train</code>方法：处理nSTP特征，并解决了元组类型问题</li>
<li>修改了<code>forward_test</code>方法：支持测试时使用nSTP特征</li>
</ul>
<p>关键修改部分：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward_train</span>(<span class="params">self, **kwargs</span>):</span><br><span class="line">    <span class="comment"># ...现有代码...</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 修改部分：处理next_bev_feats中可能的元组类型</span></span><br><span class="line">    processed_next_bev_feats = []</span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> next_bev_feats:</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(feat, <span class="built_in">tuple</span>):</span><br><span class="line">            <span class="comment"># 如果是元组，取第一个元素（主要特征）</span></span><br><span class="line">            processed_next_bev_feats.append(feat[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            processed_next_bev_feats.append(feat)</span><br><span class="line">    </span><br><span class="line">    next_bev_feats = torch.stack(processed_next_bev_feats, <span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># ...继续现有代码...</span></span><br></pre></td></tr></table></figure>

<h2 id="3-配置文件修改"><a href="#3-配置文件修改" class="headerlink" title="3. 配置文件修改"></a>3. 配置文件修改</h2><h3 id="3-1-OpenScene配置"><a href="#3-1-OpenScene配置" class="headerlink" title="3.1 OpenScene配置"></a>3.1 OpenScene配置</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\configs\vidar_pretrain\OpenScene\vidar_OpenScene_mini_1_8_3future_nstp.py</code></p>
<p><strong>主要修改</strong>:</p>
<ul>
<li>添加了nSTP相关配置：启用nSTP，设置数据路径</li>
<li>修改了数据处理流程，添加了nSTP数据处理组件</li>
<li>配置了nSTP编码器和增强器参数</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># nSTP配置</span></span><br><span class="line">use_nskg = <span class="literal">False</span>  <span class="comment"># 禁用nSKG</span></span><br><span class="line">use_nstp = <span class="literal">True</span>  <span class="comment"># 启用nSTP</span></span><br><span class="line">nstp_path = <span class="string">&#x27;data/nuscenes/nstp/train/raw&#x27;</span>  <span class="comment"># nSTP数据目录路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加nSTP数据处理组件</span></span><br><span class="line">train_pipeline.insert(-<span class="number">2</span>, <span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;ProcessNSTPGraph&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改数据集配置</span></span><br><span class="line">data = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    train=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">        use_nstp=use_nstp,</span><br><span class="line">        nstp_path=nstp_path,</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    ),</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="3-2-NuScenes全集配置"><a href="#3-2-NuScenes全集配置" class="headerlink" title="3.2 NuScenes全集配置"></a>3.2 NuScenes全集配置</h3><p><strong>文件路径</strong>: <code>ViDAR\projects\configs\vidar_pretrain\nusc_fullset\vidar_nstp_nusc.py</code></p>
<p><strong>主要修改</strong>:</p>
<ul>
<li>基于基础配置，添加了nSTP支持</li>
<li>配置了nSTP数据路径和处理逻辑</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">_base_ = [<span class="string">&#x27;./vidar_full_nusc_1future.py&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># nSTP配置</span></span><br><span class="line">use_nskg = <span class="literal">False</span></span><br><span class="line">use_nstp = <span class="literal">True</span></span><br><span class="line">nstp_path = <span class="string">&#x27;data/nuscenes/nstp/nstp.pkl&#x27;</span>  <span class="comment"># nSTP数据路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改数据集配置</span></span><br><span class="line">data = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    train=<span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">type</span>=<span class="string">&#x27;NuScenesViDARDatasetV1&#x27;</span>,</span><br><span class="line">        use_nskg=use_nskg,</span><br><span class="line">        use_nstp=use_nstp,</span><br><span class="line">        nstp_path=nstp_path,</span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    ),</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h2 id="4-其他辅助修改"><a href="#4-其他辅助修改" class="headerlink" title="4. 其他辅助修改"></a>4. 其他辅助修改</h2><h3 id="4-1-数据集注册"><a href="#4-1-数据集注册" class="headerlink" title="4.1 数据集注册"></a>4.1 数据集注册</h3><p><strong>文件路径</strong>: <code>d:\git_clone\ViDAR\projects\mmdet3d_plugin\datasets\__init__.py</code></p>
<p><strong>主要修改</strong>:</p>
<ul>
<li>导入并注册了nSTP相关模块：<code>NSTPEncoder</code>, <code>NSTPEnhancer</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> .nstp_encoder <span class="keyword">import</span> NSTPEncoder, NSTPEnhancer</span><br><span class="line"></span><br><span class="line">__all__ = [</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="string">&#x27;NSTPEncoder&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;NSTPEnhancer&#x27;</span>,</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">]</span><br></pre></td></tr></table></figure>



<h2 id="5-过程中的好多错误"><a href="#5-过程中的好多错误" class="headerlink" title="5. 过程中的好多错误"></a>5. 过程中的好多错误</h2><p><img src="/article/8257d2b5/bb0c0e4dfe0861b863c951950326904.png" alt="bb0c0e4dfe0861b863c951950326904"></p>
<p>首先是数据集nSKG不能用，用了会出现这个问题：</p>
<p><img src="/article/8257d2b5/c5f86c19470657dbb32886c2a1ecc09.png" alt="c5f86c19470657dbb32886c2a1ecc09"></p>
<p><img src="/article/8257d2b5/592bd326d2dfd419178041902a18105.png" alt="592bd326d2dfd419178041902a18105"></p>
<p>然后进而导致：</p>
<p><img src="/article/8257d2b5/baa821cdf2653096e4ff3d91e0adb78-174584491940213.png" alt="baa821cdf2653096e4ff3d91e0adb78"></p>
<p><img src="/article/8257d2b5/46aa267f5409cd333b793036e91f475.png" alt="46aa267f5409cd333b793036e91f475"></p>
<p>然后对他做细致处理的话，其实也可以，但是我写的代码处理不了：</p>
<p><img src="/article/8257d2b5/919ca81a4064679c687412f83fcacbf.png" alt="919ca81a4064679c687412f83fcacbf"></p>
<p>所以最后选择使用nSTP，因为在<a target="_blank" rel="noopener" href="https://zenodo.org/records/10074393">nuScenes Knowledge Graph</a>发现了nSTP是对nSKG的拓展，而且可以直接拿来训练，因此修改代码适配：</p>
<p><img src="/article/8257d2b5/image-20250428205817288.png" alt="image-20250428205817288"></p>
<p><img src="/article/8257d2b5/94c305fa70e234b826ba190de87e104.png" alt="94c305fa70e234b826ba190de87e104"></p>
<p>最后结果，可以正常读取nSTP数据文件：</p>
<p><img src="/article/8257d2b5/f4d05a563eb5ef922c95d96436bf1d2.png" alt="f4d05a563eb5ef922c95d96436bf1d2"></p>
<p>但是……爆内存了：</p>
<p><img src="/article/8257d2b5/64c1d3c75e8a169d3bffaf3d1b7f692.png" alt="64c1d3c75e8a169d3bffaf3d1b7f692"></p>
<p>写到这里的时候刚修复了一小点bug，目前仍然在服务器上跑着……</p>
<p>然后最后贴一张饱受折损的服务器合照（感谢罗勇老师）</p>
<p><img src="/article/8257d2b5/926d4f6ee558907674f7927728597bc.png" alt="926d4f6ee558907674f7927728597bc"></p>
<p><img src="/article/8257d2b5/b83a187f7c801ef796584bdd84e832b.png" alt="b83a187f7c801ef796584bdd84e832b"></p>
<h2 id="6-最后总结"><a href="#6-最后总结" class="headerlink" title="6. 最后总结"></a>6. 最后总结</h2><p>nSTP集成工作主要包括以下几个方面：</p>
<ol>
<li><strong>数据处理</strong>：创建了nSTP图数据的加载和处理逻辑，支持从.pt文件中读取图结构数据</li>
<li><strong>特征提取</strong>：实现了基于图神经网络的nSTP编码器，提取图结构中的时空特征</li>
<li><strong>特征融合</strong>：实现了nSTP特征与BEV特征的融合机制，通过注意力机制增强BEV特征</li>
<li><strong>模型集成</strong>：将nSTP模块集成到ViDAR模型中，修改了前向传播逻辑</li>
<li><strong>配置支持</strong>：添加了nSTP相关配置，支持灵活开启&#x2F;关闭nSTP功能</li>
</ol>
<p>这些修改使ViDAR模型能够利用nSTP提供的场景结构和时间演化信息，增强了模型对动态场景的理解能力，特别是在预测未来帧方面。</p>
<p>然后我们完成的工作：</p>
<ol>
<li>完成环境配置，解决冲突依赖问题</li>
<li>完成数据集的读取与训练问题</li>
<li>完成对vidar的修改以加入nSTP数据集来调优</li>
<li>修复原本的pytouch问题</li>
<li>目前仍然在服务器上跑着，估计还有不少后续的训练问题需要修改……但是没时间了</li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://aplainjane.github.io">APlainJane</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://aplainjane.github.io/article/8257d2b5.html">https://aplainjane.github.io/article/8257d2b5.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://aplainjane.github.io" target="_blank">去远方</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/cv/">cv</a><a class="post-meta__tags" href="/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/">自动驾驶</a><a class="post-meta__tags" href="/tags/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/">课程学习</a></div><div class="post-share"><div class="social-share" data-image="http://aplainjane.github.io/article/8257d2b5/wallhaven-9oxme1_1920x1080.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/article/dba7e729.html" title="[长期更新]算法总结"><img class="cover" src="http://aplainjane.github.io/article/dba7e729/wallhaven-5g22q5_1920x1080.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">[长期更新]算法总结</div></div><div class="info-2"><div class="info-item-1">前言从力扣100题开始的算法总结，决定真正走科班的代码之路后，果然还是得彻底从头开始总结一些算法代码了，感觉会是一个长期的总结过程，而且还要保持长期热情，只能加油吧。之前技能点全点在做游戏上了，但如果真的决定要改变世界，那就不能止步不前了。 这个总结目前来说还比较简单片面，后续可能考虑针对各个算法进行单一深入应用总结。  哈希这一部分其实主要是利用哈希表来辅助解决问题。 可能困难比较大的是记住哈希表的使用方式（呃呃这就是记性差的坏处了） 记住之后很多问题在考虑到查找、拼接就可以直接从哈希表入手了： unordered_map&lt;string, vector&lt;string&gt;&gt; groups;for(auto it = groups.begin(); it != groups.end(); it++)&#123;    ans.emplace_back(it-&gt;second);           // 每一组键值对的值加入结果中&#125;unordered_set&lt;int&gt; st(nums.begin(), nums.end()); //...</div></div></div></a><a class="pagination-related" href="/article/9185230b.html" title="山海不过壶酒间"><img class="cover" src="/img/cover.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">山海不过壶酒间</div></div><div class="info-2"><div class="info-item-1">前言我的天哪，4月就写了一篇博客，然后一堆作品集和项目记录还没准备！我在干什么！ 算了，事已至此，先把一些之前想保存的word都陆陆续续搬上来，撑一下…… 这个是最长的一篇，慢慢更新但是疑似太监了的一篇长篇…… 所有杂谈就用默认封面了……究极懒鬼 正文  连片雪花如飘飞的柳絮，在这灯火通明的小镇上空飘得十分温馨。  ...</div></div></div></a></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/me.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">APlainJane</div><div class="author-info-description">愿你历经千帆，归来仍是少年</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">26</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/aplainjane"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E8%BF%87%E7%A8%8B"><span class="toc-number">2.</span> <span class="toc-text">过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8model-art%E5%B9%B3%E5%8F%B0"><span class="toc-number">2.1.</span> <span class="toc-text">使用model art平台</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="toc-number">2.2.</span> <span class="toc-text">遇到的问题以及解决方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ViDAR%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90"><span class="toc-number">2.3.</span> <span class="toc-text">ViDAR模型实现分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%A6%82%E8%BF%B0"><span class="toc-number">2.3.1.</span> <span class="toc-text">模型架构概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6"><span class="toc-number">2.3.2.</span> <span class="toc-text">核心组件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E7%BB%93%E6%9E%84"><span class="toc-number">2.3.3.</span> <span class="toc-text">项目结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8EBEVFormer%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">2.3.4.</span> <span class="toc-text">与BEVFormer的关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B0%83%E4%BC%98%E6%80%9D%E8%B7%AF"><span class="toc-number">2.4.</span> <span class="toc-text">调优思路</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%9E%8D%E5%90%88Nskg"><span class="toc-number">2.4.1.</span> <span class="toc-text">融合Nskg</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ViDAR%E9%A1%B9%E7%9B%AE%E9%9B%86%E6%88%90nSTP%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">ViDAR项目集成nSTP的工作总结</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%A0%B8%E5%BF%83%E6%96%87%E4%BB%B6%E5%88%9B%E5%BB%BA"><span class="toc-number">3.1.</span> <span class="toc-text">1. 核心文件创建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-nSTP%E7%BC%96%E7%A0%81%E5%99%A8%E6%A8%A1%E5%9D%97"><span class="toc-number">3.1.1.</span> <span class="toc-text">1.1 nSTP编码器模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-nSTP%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E7%BB%84%E4%BB%B6"><span class="toc-number">3.1.2.</span> <span class="toc-text">1.2 nSTP数据处理组件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%8E%B0%E6%9C%89%E6%96%87%E4%BB%B6%E4%BF%AE%E6%94%B9"><span class="toc-number">3.2.</span> <span class="toc-text">2. 现有文件修改</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB%E4%BF%AE%E6%94%B9"><span class="toc-number">3.2.1.</span> <span class="toc-text">2.1 数据集类修改</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-1-NuScenes%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.2.1.1.</span> <span class="toc-text">2.1.1 NuScenes数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-2-NuPlan%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.2.1.2.</span> <span class="toc-text">2.1.2 NuPlan数据集</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%A8%A1%E5%9E%8B%E5%A4%B4%E9%83%A8%E4%BF%AE%E6%94%B9"><span class="toc-number">3.2.2.</span> <span class="toc-text">2.2 模型头部修改</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-ViDAR%E6%A3%80%E6%B5%8B%E5%99%A8%E4%BF%AE%E6%94%B9"><span class="toc-number">3.2.3.</span> <span class="toc-text">2.3 ViDAR检测器修改</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%BF%AE%E6%94%B9"><span class="toc-number">3.3.</span> <span class="toc-text">3. 配置文件修改</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-OpenScene%E9%85%8D%E7%BD%AE"><span class="toc-number">3.3.1.</span> <span class="toc-text">3.1 OpenScene配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-NuScenes%E5%85%A8%E9%9B%86%E9%85%8D%E7%BD%AE"><span class="toc-number">3.3.2.</span> <span class="toc-text">3.2 NuScenes全集配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%85%B6%E4%BB%96%E8%BE%85%E5%8A%A9%E4%BF%AE%E6%94%B9"><span class="toc-number">3.4.</span> <span class="toc-text">4. 其他辅助修改</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E6%95%B0%E6%8D%AE%E9%9B%86%E6%B3%A8%E5%86%8C"><span class="toc-number">3.4.1.</span> <span class="toc-text">4.1 数据集注册</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E5%A5%BD%E5%A4%9A%E9%94%99%E8%AF%AF"><span class="toc-number">3.5.</span> <span class="toc-text">5. 过程中的好多错误</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E6%9C%80%E5%90%8E%E6%80%BB%E7%BB%93"><span class="toc-number">3.6.</span> <span class="toc-text">6. 最后总结</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/article/1e622eac.html" title="mvcc的初步学习"><img src="http://aplainjane.github.io/article" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mvcc的初步学习"/></a><div class="content"><a class="title" href="/article/1e622eac.html" title="mvcc的初步学习">mvcc的初步学习</a><time datetime="2025-06-01T06:58:52.000Z" title="发表于 2025-06-01 14:58:52">2025-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/article/51cf0114.html" title="一些杂七杂八的想法"><img src="/img/cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="一些杂七杂八的想法"/></a><div class="content"><a class="title" href="/article/51cf0114.html" title="一些杂七杂八的想法">一些杂七杂八的想法</a><time datetime="2025-04-28T13:47:18.000Z" title="发表于 2025-04-28 21:47:18">2025-04-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/article/8832a5b7.html" title="在雨天坐公交车到世界尽头"><img src="/img/cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="在雨天坐公交车到世界尽头"/></a><div class="content"><a class="title" href="/article/8832a5b7.html" title="在雨天坐公交车到世界尽头">在雨天坐公交车到世界尽头</a><time datetime="2025-04-28T13:46:28.000Z" title="发表于 2025-04-28 21:46:28">2025-04-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/article/9185230b.html" title="山海不过壶酒间"><img src="/img/cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="山海不过壶酒间"/></a><div class="content"><a class="title" href="/article/9185230b.html" title="山海不过壶酒间">山海不过壶酒间</a><time datetime="2025-04-28T13:34:58.000Z" title="发表于 2025-04-28 21:34:58">2025-04-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/article/8257d2b5.html" title="自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试"><img src="http://aplainjane.github.io/article/8257d2b5/wallhaven-9oxme1_1920x1080.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试"/></a><div class="content"><a class="title" href="/article/8257d2b5.html" title="自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试">自动驾驶点云预测模型ViDAR融合知识图谱的初步尝试</a><time datetime="2025-04-28T11:17:51.000Z" title="发表于 2025-04-28 19:17:51">2025-04-28</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/foot.png);"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;2025 By APlainJane</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.0-b1</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><div class="js-pjax"><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'aplainjane/Commit',
      'data-repo-id': 'R_kgDOOPtarg',
      'data-category-id': 'DIC_kwDOOPtars4Cog9G',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme)
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script async src="https://npm.elemecdn.com/tzy-blog/lib/js/other/sakura.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="true" data-text="I,LOVE,YOU" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/tororo.model.json"},"display":{"position":"right","width":150,"height":300,"hOffset":20,"vOffset":-20},"mobile":{"show":true},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/"});</script></body></html>